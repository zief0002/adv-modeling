<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>6&nbsp; Likelihood: A Framework for Evidence – Advanced Modeling and Reproducibility for Educational Scientists</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./02-04-likelihood-framework-for-estimation.html" rel="next">
<link href="./02-01-mathematical-foundations-probability-density.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed04999718f06b735b1f8009dce43b94.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7c121de436c7c20b050f1da4c0bef0bb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="assets/sticky-notes.css">
<link rel="stylesheet" href="assets/table-styles.css">
</head>

<body class="nav-sidebar floating fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-00-likelihood.html">Likelihood</a></li><li class="breadcrumb-item"><a href="./02-03-likelihood-framework-for-evidence.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Evidence</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Advanced Modeling and Reproducibility for Educational Scientists</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Front Matter</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./01-00-reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Statistical Reproducibility</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-02-project-organization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Project Organization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-03-introduction-to-quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-04-more-quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">More Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-05-creating-tables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Creating Tables with gt</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./02-00-likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Likelihood</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-01-mathematical-foundations-probability-density.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Mathematical Foundations: Probability Density</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-03-likelihood-framework-for-evidence.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Evidence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-04-likelihood-framework-for-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Estimation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./03-00-modeling-nonlinearity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling Nonlinearity</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-01-polynomial-effects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Polynomial Effects</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-02-information-criteria-and-model-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Information Criteria and Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-03-logarithmic-transformations-outcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Log-Transforming the Outcome</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">05-00-modeling-nonindependece.qmd</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-01-introduction-to-mixed-effects-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Introduction to Mixed-Effects Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-02-lmer-average-change-over-time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">LMER: Average Change Over Time</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-03-lmer-other-random-effects-and-covariates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">LMER: Other Random-Effects and Covariates</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-04-lmer-alt-representations-and-assumptions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Linear Mixed-Effects Models: Alternative Representations and Assumptions</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-00-likelihood.html">Likelihood</a></li><li class="breadcrumb-item"><a href="./02-03-likelihood-framework-for-evidence.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Evidence</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Evidence</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Quarto Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="preparation" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="preparation"><span class="header-section-number">6.1</span> Preparation</h2>
<p>In this set of notes, you will learn about the law of likelihood, and the use of likelihood ratios as statistical evidence for model selection. To do so, we will use the <a href="https://raw.githubusercontent.com/zief0002/fluffy-ants/main/data/pew.csv">pew.csv</a> dataset (see the <a href="http://zief0002.github.io/fluffy-ants/codebooks/pew.html">data codebook</a>) to fit a set of models that explain variation in American’s political knowledge.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(educate)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Import data</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>pew <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="at">file =</span> <span class="st">"https://raw.githubusercontent.com/zief0002/fluffy-ants/main/data/pew.csv"</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>pew</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 100 × 9
      id knowledge  news   age education  male ideology party       engagement
   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;
 1     1        10    60  31.1        16     0     65.1 Democrat          19.8
 2     2        18    20  44.4        12     1     41   Independent       71.4
 3     3        88    59  53.7        16     1      3.4 Democrat          97.2
 4     4        75    89  62.5        13     1     50.6 Independent       61.5
 5     5        93    43  48.3        16     0     35.3 Democrat          53.4
 6     6        13    61  24.3         9     0      0.1 Independent       41.1
 7     7        37    45  59.2        12     0     13.7 Independent       96.3
 8     8        66    59  93.9        16     1     27.1 Democrat          86.8
 9     9        49    68  37          16     0     67.4 Independent       58.2
10    10        50    44  37.1        14     1     54.8 Democrat          45.2
# ℹ 90 more rows</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="research-questions-and-modeling-strategy" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="research-questions-and-modeling-strategy"><span class="header-section-number">6.2</span> Research Questions and Modeling Strategy</h2>
<p>Recall that we had three research questions for these data:</p>
<ol type="1">
<li>Is there an effect of news exposure on political knowledge?</li>
<li>Is there an effect of news exposure on political knowledge after controlling for demographic and political covariates?</li>
<li>Does education level <em>moderate</em> the effect of news exposure on political knowledge after controlling for demographic and political covariates?</li>
</ol>
<p>Any analysis should begin with looking at plots and computing summary statistics of the sample data. (We already did this in a previous set of notes.) After the data exploration, we can begin to think about fitting one or more models to the data. It is good science to consider the modeling strategy you will be using before you begin fitting models. There are many modeling strategies that educational scientists use in practice (e.g., forward-selection, backward-elimination) and there is no one “right” method. As you consider a modeling strategy, think about how this strategy helps provide a narrative structure for answering your research question; sometimes this leads to one strategy being more productive than others.</p>
<p>In the previous set of notes we began by fitting a model that only included the main-effect of news exposure. Evaluating the effect of news exposure in this model helped us answer RQ 1. We then fitted a model that included news exposure along with the set of demographic and political covariates. Evaluating the effect of news exposure in this model helped us answer RQ 2. Finally, we fitted a model that included an interaction effect of news exposure and education in along with the demographic and political covariates. Evaluating the interaction effect allowed us to answer RQ 3. These three models are:</p>
<p><span class="math display">\[
\begin{split}
\mathbf{Model~1:~} \quad \mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{News~Exposure}_i) + \epsilon_i \\[2ex]
\mathbf{Model~2:~} \quad \mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{Age}_i) + \beta_2(\mathrm{Education}_i) + \beta_3(\mathrm{Male}_i) + \\
&amp;\beta_4(\mathrm{Engagement}_i) + \beta_5(\mathrm{Ideology}_i)+ \\
&amp;\beta_6(\mathrm{Democrat}_i) + \beta_7(\mathrm{Republican}_i) + \\
&amp;\beta_8(\mathrm{News~Exposure}_i) + \epsilon_i \\[2ex]
\mathbf{Model~3:~} \quad \mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{Age}_i) + \beta_2(\mathrm{Education}_i) + \beta_3(\mathrm{Male}_i) + \\
&amp;\beta_4(\mathrm{Engagement}_i) + \beta_5(\mathrm{Ideology}_i)+ \\
&amp;\beta_6(\mathrm{Democrat}_i) + \beta_7(\mathrm{Republican}_i) + \\
&amp;\beta_8(\mathrm{News~Exposure}_i) + \beta_9(\mathrm{News~Exposure}_i)(\mathrm{Education}_i) + \epsilon_i \\[2ex]
\end{split}
\]</span></p>
<p>where <span class="math inline">\(\epsilon_i \overset{i.i.d.}{\sim}\mathcal{N}(0,\sigma^2_{\epsilon})\)</span> for each of the models.</p>
<p><br></p>
</section>
<section id="classical-framework-of-evidence" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="classical-framework-of-evidence"><span class="header-section-number">6.3</span> Classical Framework of Evidence</h2>
<p>When we have looked at statistical evidence to this point, it has been from a hypothesis testing point of view. The primary piece of evidence we use in this paradigm is the <em>p</em>-value. For example, if we fit Model 1 and examine the evidence for the effect of news exposure on news knoledge, we find:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Model 1</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> news, <span class="at">data =</span> pew)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficient-level output</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(lm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)   39.7      5.20        7.63 1.56e-11
2 news           0.327    0.0899      3.64 4.42e- 4</code></pre>
</div>
</div>
<p>The <em>p</em>-value associated with the effect of news exposure (<span class="math inline">\(p&lt;.001\)</span>), which suggests that the size of this effect is more than we would expect because of chance if the population effect was 0.</p>
<p>Interpreting this <em>p</em>-values, we would say that the probability of seeing the empirical evidence we observed (or evidence that is more extreme) if the null hypothesis that there is no effect of news exposure on news knowledge is true, is 0.000442. This implies that our observed data are inconsistent with the hypothesized model that there is no effect of news exposure. In an applied setting, we might use such evidence to decide that the level of news exposure does indeed predict variation in American’s news knowledge.</p>
<p>Despite being the predominant evidential paradigm used in the education and social sciences, hypothesis testing has many criticisms <span class="citation" data-cites="Johansson:2011 Weakliem:2016">(e.g., <a href="#ref-Johansson:2011" role="doc-biblioref">Johansson, 2011</a>; <a href="#ref-Weakliem:2016" role="doc-biblioref">Weakliem, 2016</a>)</span>. Among some of the stronger criticisms,</p>
<ul>
<li>The <em>p</em>-value only measures evidence against the hypothesized model; not the evidence FOR a particular model.</li>
<li>The model we specify in the null hypothesis is often substantively untenable (how often is the effect 0? Generally as applied scientists the reason we include predictors is because we believe there is an effect.)</li>
<li>The <em>p</em>-value is based on data we haven’t observed (it is based on the observed data AND evidence that is more extreme).</li>
</ul>
<p>If we write the <em>p</em>-value as a probability statement, it would be:</p>
<p><span class="math display">\[
p\mbox{-}\mathrm{value} = P(\mathrm{Data~or~more~extreme~unobserved~data} \mid \mathrm{Model})
\]</span></p>
<p>While hypothesis tests have filled a need in the educational and social science to have some standard for evaluating statistical evidence, it is unclear whether this is the approach we should be using. As statistician David Lindley so aptly states, “[significance tests] are widely used, yet are logically indefensible” <span class="citation" data-cites="Johnstone:1986">(comment in <a href="#ref-Johnstone:1986" role="doc-biblioref">Johnstone, 1986, p. 502</a>)</span>. Psychologist Jacob Cohen was more pointed, saying “[hypothesis testing] has not only failed to support the advance of psychology as a science but also has seriously impeded it” <span class="citation" data-cites="Cohen:1994">(<a href="#ref-Cohen:1994" role="doc-biblioref">Cohen, 1994, p. 997</a>)</span>.</p>
<div class="todo">
<p>“The main purpose of a significance test is to inhibit the natural enthusiasm of the investigator” <span class="citation" data-cites="Mosteller:1954">(<a href="#ref-Mosteller:1954" role="doc-biblioref">Mosteller &amp; Bush, 1954, pp. 331–332</a>)</span>.</p>
</div>
<p><br></p>
</section>
<section id="likelihood-paradigm-to-statistical-evidence" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="likelihood-paradigm-to-statistical-evidence"><span class="header-section-number">6.4</span> Likelihood Paradigm to Statistical Evidence</h2>
<p>In applied science, we ideally would like to collect some evidence (data) and use that to say something about how likely a particular model (or hypothesis) is based on that evidence. Symbolically we want to know,</p>
<p><span class="math display">\[
P(\mathrm{Model} \mid \mathrm{Observed~data})
\]</span></p>
<p>This probability is known as the <em>likelihood</em> and is very different than the probability given by the <em>p</em>-value. In the likelihood paradigm, the likelihood is the key piece of statistical evidence used to evaluate models. For example if you were comparing Model A and Model B, you could compute the likelihood for each model and compare them. Whichever model has the higher likelihood has more empirical support. This is, in a nutshell what the <em>Law of Likelihood</em> states. What is even more attractive is that another axiom, the <em>Likelihood Principle</em>, tells us that if the goal is to compare the empirical support of competing models, all of the information in the data that can be used to do so, is contained in the ratio of the model likelihoods. That is, we can’t learn more about which model is more supported unless we collect additional data.</p>
<p><br></p>
</section>
<section id="joint-probability-density-a-roadstop-to-computing-likelihood" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="joint-probability-density-a-roadstop-to-computing-likelihood"><span class="header-section-number">6.5</span> Joint Probability Density: A Roadstop to Computing Likelihood</h2>
<p>In the preparation reading, you learned about the probability density of an observation <span class="math inline">\(x_i\)</span>. Now we will extend this idea to the probability density of a set of observations, say <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, AND <span class="math inline">\(x_k\)</span>. The probability density of a set of observations is referred to as the <em>joint probability density</em>, or simply <em>joint density</em>.</p>
<p>If we can make an assumption about INDEPENDENCE, then the joint probability density would be the product of the individual densities:</p>
<p><span class="math display">\[
p(x_1, x_2, x_3, \ldots, x_k) = p(x_1) \times p(x_2) \times p(x_3) \times \ldots \times p(x_k)
\]</span></p>
<p>Say we had three independent observations, <span class="math inline">\(x =\{60, 65, 67\}\)</span>, from a <span class="math inline">\(\sim\mathcal{N}(50,10)\)</span> distribution. The joint density would be:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute joint density</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="at">x =</span> <span class="dv">60</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>) <span class="sc">*</span> <span class="fu">dnorm</span>(<span class="at">x =</span> <span class="dv">65</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>) <span class="sc">*</span> <span class="fu">dnorm</span>(<span class="at">x =</span> <span class="dv">67</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.000002947448</code></pre>
</div>
</div>
<p>We could also shortcut this computation,</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute joint density</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">60</span>, <span class="dv">65</span>, <span class="dv">67</span>), <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.000002947448</code></pre>
</div>
</div>
<p>This value is the joint probability density. The joint probability density indicates the probability of observing the data (<span class="math inline">\(x =\{60, 65, 67\}\)</span>) GIVEN (1) they are drawn from a normal distribution and (2) the normal distribution has a mean of 50 and a standard deviation of 10. In other words, the joint probability density is the probability of the data given a model and parameters of the model.</p>
<p>Symbolically,</p>
<p><span class="math display">\[
\mathrm{Joint~Density} = P(\mathrm{Data} \mid \mathrm{Model~and~Parameters})
\]</span></p>
<p><br></p>
</section>
<section id="computing-likelihood" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="computing-likelihood"><span class="header-section-number">6.6</span> Computing Likelihood</h2>
<p>Likelihood is the probability of a particular set of parameters GIVEN (1) the data, and (2) the data are generated from a particular model (e.g., normal distribution). Symbolically,</p>
<p><span class="math display">\[
\mathrm{Likelihood} = P(\mathrm{Parameters} \mid \mathrm{Model~and~Data})
\]</span></p>
<p>Symbolically we denote likelihood with a scripted letter “L” (<span class="math inline">\(\mathcal{L}\)</span>). For example, we might ask the question, given the observed data <span class="math inline">\(x = \{30, 20, 24, 27\}\)</span> come from a normal distribution, what is the likelihood (probability) that the mean is 20 and the standard deviation is 4? We might denote this as,</p>
<p><span class="math display">\[
\mathcal{L}(\mu = 20, \sigma = 4 \mid x)
\]</span></p>
<div class="fyi">
<p><strong>FYI</strong></p>
<p>Although we need to specify the model this is typically not included in the symbolic notation; instead it is often a part of the assumptions.</p>
</div>
<p><br></p>
<section id="an-example-of-computing-and-evaluating-likelihood" class="level3" data-number="6.6.1">
<h3 data-number="6.6.1" class="anchored" data-anchor-id="an-example-of-computing-and-evaluating-likelihood"><span class="header-section-number">6.6.1</span> An Example of Computing and Evaluating Likelihood</h3>
<p>The likelihood allows us to answer probability questions about a set of parameters. For example, what is the likelihood (probability) that the data (<span class="math inline">\(x = \{30, 20, 24, 27\}\)</span>) were generated from a normal distribution with a mean of 20 and standard deviation of 4? To compute the likelihood we compute the joint probability density of the data under that particular set of parameters.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">20</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0000005702554</code></pre>
</div>
</div>
<p>What is the likelihood (probability) that the same set of data (<span class="math inline">\(x = \{30, 20, 24, 27\}\)</span>) were generated from a normal distribution with a mean of 25 and standard deviation of 4?</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">25</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.00001774012</code></pre>
</div>
</div>
<p>Given the data and the model, there is more empirical support that the parameters are <span class="math inline">\(\mathcal{N}(25,4^2)\)</span> rather than <span class="math inline">\(\mathcal{N}(20, 4^2)\)</span>, because the likelihood is higher for the former set of parameters. We can compute a ratio of the two likelihoods to quantify the amount of additional support for the <span class="math inline">\(\mathcal{N}(25,4^2)\)</span>.</p>
<p><span class="math display">\[
\begin{split}
\mathrm{Likelihood~Ratio} &amp;= \frac{0.00001774012}{0.0000005702554} \\[1ex]
&amp;= 31.11
\end{split}
\]</span></p>
<p>The empirical support for the <span class="math inline">\(\mathcal{N}(25,4^2)\)</span> parameterization is 31 times that of the <span class="math inline">\(\mathcal{N}(20, 4^2)\)</span> parameterization! In a practical setting, this would lead us to adopt a mean of 25 over a mean of 20.</p>
<p><br></p>
</section>
</section>
<section id="some-notes-and-caveats" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="some-notes-and-caveats"><span class="header-section-number">6.7</span> Some Notes and Caveats</h2>
<p>It is important to note that although we use the joint probability under a set of parameters to compute the likelihood of those parameters, theoretically joint density and likelihood are very different. Likelihood takes the data and model as given and computes the probability of a set of parameters. Whereas joint density assumes that the model and parameters are given and gives us the probability of the data.</p>
<div class="fyi">
<p><strong>FYI</strong></p>
<p>Likelihood refers to the probability of the parameters and joint probability density refers to the probability of the data.</p>
</div>
<p>Once we collect the data, the probability of observing that set of data is 1; it is no longer unknown. The likelihood method treats our data as known and offers us a way of making probabilistic statements about the unknown parameters. This is more aligned with our scientific process than making some assumption about the parameter (e.g., <span class="math inline">\(\beta_1=0\)</span>) and then trying to determine the probability of the data under that assumption. Moreover, likelihood does not use unobserved data (e.g., data more extreme than what we observed) in the computation.</p>
<p>It is also important to acknowledge what likelihood and the likelihood ratio don’t tell us. First, they only tell us the probability of a set of parameters for the data we have. Future collections of data might change the amount of support or which set of parameters is supported. Since changing the data, changes the likelihood, this also means we cannot make cross study comparisons of the likelihood (unless the studies used the exact same data). Secondly, the model assumed is important. If a different model is assumed, the likelihood will be different, and again could change the amount of support or which set of parameters is supported.</p>
<p>The likelihood ratio (LR), while useful for comparing the relative support between parameterizations, does not tell you that a particular parameterization is correct. For example, the LR of 31.11 tells us that there is more empirical support for the <span class="math inline">\(\mathcal{N}(25,4^2)\)</span> parameterization than <span class="math inline">\(\mathcal{N}(20, 4^2)\)</span>. But, there might be even more support for a parameterization we haven’t considered.</p>
<p>These shortcomings are not unique to the likelihood paradigm The also exist in the classical hypothesis testing paradigm for statistical evidence. All in all, the added advantages to the likelihood paradigm make it more useful to applied work than hypothesis testing.</p>
<p><br></p>
</section>
<section id="likelihood-in-regression-back-to-our-example" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="likelihood-in-regression-back-to-our-example"><span class="header-section-number">6.8</span> Likelihood in Regression: Back to Our Example</h2>
<p>When fitting a regression model, we make certain assumptions about the relationship between a set of predictors and the outcome. For example, in Model 1 from our earlier example, we assume that the relationship between news exposure and news knowledge can be described by the following model:</p>
<p><span class="math display">\[
\begin{split}
\mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{News~Exposure}_i) + \epsilon_i \\[1ex]
&amp;\mathrm{where~}\epsilon_i \overset{i.i.d.}{\sim}\mathcal{N}(0,\sigma^2_{\epsilon})
\end{split}
\]</span></p>
<p>Here we use OLS to estimate the regression coefficients. Then we can use those, along with the observed data to obtain the residuals and the estimate for the residual standard error. The residuals are the GIVEN data and the set up distributional assumptions for the model (e.g., normal, mean of 0, constant variance) allow us to compute the likelihood for the entire set of parameters in this model (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\sigma^2_{\epsilon}\)</span>).</p>
<p>Below is a set of syntax to compute the likelihood, based on fitting <code>lm.1</code>. We use the <code>resid()</code> function to compute the residuals. (It is the same as grabbing the column called <code>.resid</code> from the <code>augment()</code> output.) We also use the estimated value of the residual standard error (<span class="math inline">\(\hat{\sigma}_{\epsilon} = 20.3\)</span>) from the <code>glance()</code> output.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get RSE for use in likelihood</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(lm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 12
  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC
      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1     0.119         0.110  20.3      13.2 0.000442     1  -442.  890.  897.
# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for lm.1</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">resid</span>(lm<span class="fl">.1</span>), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">20.3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.382925e-192</code></pre>
</div>
</div>
<p>This value by itself is somewhat meaningless. It is only worthwhile when we compare it to the likelihood from another model. For example, let’s compute the likelihood for an intercept-only model (Model 0) and compare this to the likelihood for <code>lm.1</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Model 0</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.0</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> pew)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get RSE for use in likelihood</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(lm<span class="fl">.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 12
  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1         0             0  21.5        NA      NA    NA  -448.  900.  905.
# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for lm.2</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">resid</span>(lm<span class="fl">.0</span>), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">21.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.489266e-195</code></pre>
</div>
</div>
<p>The likelihood value for <code>lm.1</code> is higher than the likelihood value for <code>lm.0</code>. Computing the likelihood ratio:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fl">1.382925e-192</span> <span class="sc">/</span> <span class="fl">2.489266e-195</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 555.5553</code></pre>
</div>
</div>
<p>This suggests that given the data, Model 1 is 555.6 times more likely than Model 0. In practice, we would adopt Model 1 over Model 0 because it is more likely given the empirical evidence (data) we have.</p>
<section id="mathematics-of-likelihood" class="level3 mathnote" data-number="6.8.1">
<h3 data-number="6.8.1" class="anchored" data-anchor-id="mathematics-of-likelihood"><span class="header-section-number">6.8.1</span> Mathematics of Likelihood</h3>
<p>Being able to express the likelihood mathematically is important for quantitative methodologists as it allows us to manipulate and study the likelihood function and its properties. It also gives us insight into how the individual components of the likelihood affect its value.</p>
<p>Remember, we can express the likelihood of the regression residuals mathematically as:</p>
<p><span class="math display">\[
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) = p(\epsilon_1) \times p(\epsilon_2) \times \ldots \times p(\epsilon_n)
\]</span></p>
<p>where the probability density of each residual (assuming normality) is:</p>
<p><span class="math display">\[
p(\epsilon_i) = \frac{1}{\sigma\sqrt{2\pi}}\exp\left[-\frac{(\epsilon_i-\mu)^2}{2\sigma^2}\right]
\]</span></p>
<p>In addition to normality, which gives us the equation to compute the PDF for each residual, the regression assumptions also specify that each conditional error distribution has a mean of 0 and some variance (that is the same for all conditional error distributions). We can call it <span class="math inline">\(\sigma^2_{\epsilon}\)</span>. Substituting these values into the density function, we get,</p>
<p><span class="math display">\[
\begin{split}
p(\epsilon_i) &amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{(\epsilon_i-0)^2}{2\sigma^2_{\epsilon}}\right] \\[1em]
&amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{(\epsilon_i)^2}{2\sigma^2_{\epsilon}}\right]
\end{split}
\]</span></p>
<p>Now we use this expression for each of the <span class="math inline">\(p(\epsilon_i)\)</span> values in the likelihood computation.</p>
<p><span class="math display">\[
\begin{split}
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) &amp;= p(\epsilon_1) \times p(\epsilon_2) \times \ldots \times p(\epsilon_n) \\[1em]
&amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_1
^2}{2\sigma^2_{\epsilon}}\right] \times \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right] \times \\
&amp;~~~~~~\ldots \times \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right]
\end{split}
\]</span></p>
<p>We can simplify this:</p>
<p><span class="math display">\[
\begin{split}
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) &amp;=\left[ \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right]^n \times \exp\left[-\frac{\epsilon_1^2}{2\sigma^2_{\epsilon}}\right] \times \exp\left[-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right] \times \ldots \\
&amp;~~~~~~ \times \exp\left[-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right]
\end{split}
\]</span> We can also simplify this by using the product notation:</p>
<p><span class="math display">\[
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) =\left[ \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right]^n \times \prod_{i=1}^n \exp\left[-\frac{\epsilon_i^2}{2\sigma^2_{\epsilon}}\right]
\]</span> We can also write the residuals (<span class="math inline">\(\epsilon_i\)</span>) as a function of the regression parameters we are trying to find the likelihood for.</p>
<p><span class="math display">\[
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) =\left[ \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right]^n \times \prod_{i=1}^n \exp\left[-\frac{\big[Y_i - \beta_0 - \beta_1(X_i)\big]^2}{2\sigma^2_{\epsilon}}\right]
\]</span></p>
<p>where <span class="math inline">\(\sigma^2_{\epsilon} = \frac{\sum \epsilon_i^2}{n}\)</span>. Because the numerator of <span class="math inline">\(\sigma^2_{\epsilon}\)</span> can be written as <span class="math inline">\(\sum_i^n\big(Y_i - \beta_0 - \beta_1(X_i)\big)^2\)</span>, we see that the likelihood is a function of <span class="math inline">\(n\)</span>, and the regression coefficients, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. Moreover, <span class="math inline">\(n\)</span> is based on the data (which is given) and is thus is a constant. Mathematically, this implies that the only variables (values that can vary) in the likelihood function are the regression coefficients.</p>
</section>
<p><br></p>
</section>
<section id="log-likelihood" class="level2" data-number="6.9">
<h2 data-number="6.9" class="anchored" data-anchor-id="log-likelihood"><span class="header-section-number">6.9</span> Log-Likelihood</h2>
<p>The likelihood values are quite small since we are multiplying several probability densities (values between 0 and 1) together. Since it is hard to work with these smaller values, in practice, we often compute and work with the natural logarithm of the likelihood. So in our example, Model 0 (<span class="math inline">\(\mathcal{L}_0 = 2.489266 \times 10^{-195}\)</span>) has a log-likelihood of:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-likelihood for Model 0</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fl">2.489266e-195</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -448.0921</code></pre>
</div>
</div>
<p>Similarly, we can compute the log-likelihood for Model 1 as:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-likelihood for Model 1</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fl">1.382925e-192</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -441.7721</code></pre>
</div>
</div>
<p>We typically denote log-likelihood using a scripted lower-case “l” (<span class="math inline">\(\mathcal{l}\)</span>). Here,</p>
<p><span class="math display">\[
\begin{split}
\mathcal{l}_0 &amp;= -448.0921 \\[1ex]
\mathcal{l}_1 &amp;= -441.7721 \\[1ex]
\end{split}
\]</span></p>
<p>Note that the logarithm of a decimal will be negative, so the log-likelihood will be a negative value. Less negative log-likelihood values correspond to higher likelihood values, which indicate more empirical support. Here Model 1 has a log-likelihood value (<span class="math inline">\(-441.8\)</span>) that is less negative than Model 0’s log-likelihood value (<span class="math inline">\(-448.1\)</span>), which indicates there is more empirical support for Model 1 than Model 0.</p>
<div class="fyi">
<p><strong>FYI</strong></p>
<p>While it is possible using algebra to express the likelihood ratio using log-likelihoods, it does not have the same interpretational value as the LR does. Because of this, the likelihood ratio is not often expresseds using log-likelihoods.</p>
</div>
<!-- We can also express the likelihood ratio using log-likelihoods. To do so we take the natural logarithm of the likelihood ratio. We also re-write it using the rules of logarithms (from algebra). -->
<!-- $$ -->
<!-- \begin{split} -->
<!-- \ln(\mathrm{LR}) &= \ln \bigg(\frac{\mathcal{L}_2}{\mathcal{L}_1}\bigg) \\[2ex] -->
<!-- &= \ln \big(\mathcal{L}_2\big) - \ln \big(\mathcal{L}_1\big) -->
<!-- \end{split} -->
<!-- $$ -->
<!-- That is, we can find an equivalent relative support metric to the LR based on the log-likelihoods by computing the difference between them. For our example: -->
<!-- ```{r} -->
<!-- # Difference in log-likelihoods -->
<!-- log(2.910762e-196) - log(2.089334e-199) -->
<!-- # Equivalent to ln(LR) -->
<!-- log(2.910762e-196 / 2.089334e-199) -->
<!-- ``` -->
<!-- Unfortunately, this difference doesn't have the same interpretational value as the LR does, bcause this difference is in log-units. In order to get that interpretation back, we need to exponentiate (the reverse function of the logarithm) the difference: -->
<!-- ```{r} -->
<!-- # Exponentiate the difference in log-likelihoods -->
<!-- exp(7.239325) -->
<!-- ``` -->
<!-- Again, Model 1 has 308244.9 times the empirical support than Model 0. -->
<section id="mathematics-of-log-likelihood" class="level3 mathnote" data-number="6.9.1">
<h3 data-number="6.9.1" class="anchored" data-anchor-id="mathematics-of-log-likelihood"><span class="header-section-number">6.9.1</span> Mathematics of Log-Likelihood</h3>
<p>We can express the log-likelihood of the regression residuals mathematically by taking the natural logarithm of the likelihood we computed earlier:</p>
<p><span class="math display">\[
\begin{split}
\ln \Bigl(\mathcal{L}(\beta_0, \beta_1 | \mathrm{data})\Bigr) &amp;= \ln \Biggl( \left[ \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right]^n \times \exp\left[-\frac{\epsilon_1^2}{2\sigma^2_{\epsilon}}\right] \times  \\
&amp;~~~~~~ \exp\left[-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right] \times \ldots \times \exp\left[-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right] \Biggr) \\
\end{split}
\]</span></p>
<p>Using our rules for logarithms and re-arranging gives,</p>
<p><span class="math display">\[
\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = -\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \epsilon_i^2
\]</span></p>
<p>Examining this equation, we see that the log-likelihood is a function of <span class="math inline">\(n\)</span>, <span class="math inline">\(\sigma^2_{\epsilon}\)</span> and the sum of squared residuals (SSR)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. We can of course, re-express this using the the regression parameters:</p>
<p><span class="math display">\[
\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = -\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \big[Y_i - \beta_0 - \beta_1(X_i)\big]^2
\]</span></p>
<p>And, again, since <span class="math inline">\(\sigma^2_{\epsilon}\)</span> is a function of the regression coefficients and <span class="math inline">\(n\)</span>, this means that the only variables in the log-likelihood function are the coefficients.</p>
</section>
<p><br></p>
<section id="shortcut-the-loglik-function" class="level3" data-number="6.9.2">
<h3 data-number="6.9.2" class="anchored" data-anchor-id="shortcut-the-loglik-function"><span class="header-section-number">6.9.2</span> Shortcut: The <code>logLik()</code> Function</h3>
<p>The <code>logLik()</code> function can be used to obtain the log-likelihood directly from a fitted model object. For example, to find the log-likelihood for Model 1, we can use:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-likelihood for Model 1</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(lm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' -441.7579 (df=3)</code></pre>
</div>
</div>
<p>The <code>df</code> output tells us how many <strong>total parameters</strong> are being estimated in the model. In our case the number of total parameters in Model 0 is three (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_{\mathrm{News~Exposure}}\)</span>, and <span class="math inline">\(\sigma^2_{\epsilon}\)</span>). What is more important to us currently, is the log-likelihood value; <span class="math inline">\(\mathcal{l}_1=-450.2233\)</span>.</p>
<p>This value is slightly different than the log-likelihood we just computed of <span class="math inline">\(-441.7721\)</span>. This is not because of rounding in this case. It has to do with how the model is being estimated; the <code>logLik()</code> function assumes the parameters are being estimated using maximum likelihood (ML) rather than ordinary least squares (OLS). You can learn more about ML estimation in the optional set of notes, but for now, we will just use <code>logLik()</code> to compute the log-likelihood.</p>
<p>Here we compute the log-likelihood for Model 0 using the <code>logLik()</code> function. We also use the output to compute the likelihood for Model 0. To compute the likelihood from the log-likelihood we need to exponentiate (the reverse function of the logarithm) the the log-likelihood value using the <code>exp()</code> function. We also compute the log-likelihood and likelihood value for Model 1.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-likelihood for Model 0</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(lm<span class="fl">.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' -448.0884 (df=2)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for Model 0</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">logLik</span>(lm<span class="fl">.0</span>)[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.498531e-195</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-likelihood for Model 1</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(lm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' -441.7579 (df=3)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for Model 1</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">logLik</span>(lm<span class="fl">.1</span>)[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.402758e-192</code></pre>
</div>
</div>
<p>Because the output from <code>logLik()</code> includes extraneous information (e.g., <code>df</code>), we use indexing (square brackets) to extract only the part of the output we want. In this case, the <code>[1]</code> extracts the log-likelihood value from the <code>logLik()</code> output (ignoring the <code>df</code> part).</p>
<p><br></p>
</section>
</section>
<section id="model-complexity" class="level2" data-number="6.10">
<h2 data-number="6.10" class="anchored" data-anchor-id="model-complexity"><span class="header-section-number">6.10</span> Model Complexity</h2>
<p>One aspect that we need to consider is that more complex models tend to have higher likelihoods and log-likelihoods. Therefore when we compare likelihoods (or log-likelihoods) we need to consider the complexity in addition to the likelihoods. One way to quantify a model’s complexity is to consider the number of parameters that are being estimated. The more parameters that we need to estimate, the more complex the model. Recall that the number of parameters for a model are given in the <code>df</code> value from the <code>logLik()</code> function’s output.</p>
<p>In our example, the <code>df</code> value for Model 0 is two, indicating that this model is estimating two parameters (<span class="math inline">\(\beta_0\)</span>, and <span class="math inline">\(\sigma^2_{\epsilon}\)</span>). For Model 1, the <code>df</code> value was three. This indicates that Model 1 is more complex than Model 0.</p>
<p>As we consider using the likelihood ratio (LR) or the difference in log-likelihoods for model selection, we also need to consider the model complexity. In our example, the likelihood ratio of 555.6 indicates that Model 1 has approximately 555.6 times the empirical support than Model 0. But, Model 1 is more complex than Model 0, so we would expect that it would be more empirically supported.</p>
<p>In this case, with a likelihood ratio of 555.6, it seems like the empirical data certainly support adopting Model 1 over Model 0. despite the added complexity of Model 1. But what if the LR was 10? Would that be enough additional support to warrant adopting Model 1 over Model 0? What about a LR of 5?</p>
<p><br></p>
</section>
<section id="likelihood-ratio-test-for-nested-models" class="level2" data-number="6.11">
<h2 data-number="6.11" class="anchored" data-anchor-id="likelihood-ratio-test-for-nested-models"><span class="header-section-number">6.11</span> Likelihood Ratio Test for Nested Models</h2>
<p>One key question that arises is, if the likelihood for a more complex model is higher than the likelihood for a simpler model, how large does the likelihood ratio have to be before we adopt the more complex model? In general, there is no perfect answer for this.</p>
<p>If the models being compared are nested, then we can carry out a hypothesis test<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> to see if the LR is more than we would expect because of chance. Models are nested when the parameters in the simpler model are a subset of the parameters in the more complex model. For example, in our example, the parameters in Model 0 are a subset of the parameters in Model 1:</p>
<p><span class="math display">\[
\begin{split}
\mathbf{Model~1~Parameters:}&amp;\quad\{\beta_0,~\beta_{\mathrm{News~Exposure}},~\sigma^2_{\epsilon}\} \\[1ex]
\mathbf{Model~0~Parameters:}&amp;\quad\{\beta_0,~\sigma^2_{\epsilon}\} \\[1ex]
\end{split}
\]</span></p>
<p>The parameters for Model 0 all appear in the list of parameters for Model 1. Because of this we can say that Model 0 is <em>nested</em> in Model 1.</p>
<p><br></p>
<section id="hypothesis-test-of-the-lrt" class="level3" data-number="6.11.1">
<h3 data-number="6.11.1" class="anchored" data-anchor-id="hypothesis-test-of-the-lrt"><span class="header-section-number">6.11.1</span> Hypothesis Test of the LRT</h3>
<p>When we have nested models we can carry out a hypothesis test to decide between the following competing hypotheses:</p>
<p><span class="math display">\[
\begin{split}
H_0:&amp; ~\theta_0 = \{\beta_0,~\sigma^2_{\epsilon}\}\\[1ex]
H_A:&amp; \theta_1 = \{\beta_0,~\beta_{\mathrm{News~Exposure}},~\sigma^2_{\epsilon}\}
\end{split}
\]</span></p>
<p>where <span class="math inline">\(\theta_0\)</span> refers to the simpler model and <span class="math inline">\(\theta_1\)</span> refers to the more complex model. This translates to adopting either the simpler model (fail to reject <span class="math inline">\(H_0\)</span>) or the more complex model (reject <span class="math inline">\(H_0\)</span>). To carry out this test, we translate our likelihood ratio to a test statistic called <span class="math inline">\(\chi^2\)</span> (pronounced chi-squared):</p>
<p><span class="math display">\[
\chi^2 = -2 \ln \bigg(\frac{\mathcal{L}({\theta_0})}{\mathcal{L}({\theta_1})}\bigg)
\]</span></p>
<p>That is we compute <span class="math inline">\(-2\)</span> times the log of the likelihood ratio where the likelihood for the simpler model is in the numerator. (Note this is the inverse of how we have been computing the likelihood ratio!) Equivalently, we can compute this as:</p>
<p><span class="math display">\[
\chi^2 = -2 \bigg(\ln \bigg[\mathcal{L}({\theta_0})\bigg] - \ln \bigg[\mathcal{L}({\theta_1})\bigg]\bigg)
\]</span></p>
<p>For our example, we compute this using the following syntax:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute chi-squared</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> (<span class="fu">logLik</span>(lm<span class="fl">.0</span>)[<span class="dv">1</span>] <span class="sc">-</span> <span class="fu">logLik</span>(lm<span class="fl">.1</span>)[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 12.66099</code></pre>
</div>
</div>
<p><br></p>
</section>
</section>
<section id="deviance-a-measure-of-the-modeldata-error" class="level2" data-number="6.12">
<h2 data-number="6.12" class="anchored" data-anchor-id="deviance-a-measure-of-the-modeldata-error"><span class="header-section-number">6.12</span> Deviance: A Measure of the Model–Data Error</h2>
<p>If we re-write the formula for the <span class="math inline">\(\chi^2\)</span>-statistic by distributing the <span class="math inline">\(-2\)</span>, we get a better glimpse of what this statistic is measuring.</p>
<p><span class="math display">\[
\chi^2 = -2 \ln \bigg[\mathcal{L}({\theta_0})\bigg] - \bigg(-2\ln \bigg[\mathcal{L}({\theta_1})\bigg]\bigg)
\]</span></p>
<p>The quantity <span class="math inline">\(-2\ln\big[\mathcal{L}(\theta_k)\big]\)</span> is referred to as the <em>residual deviance</em><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> of Model K. It measures the amount of misfit between the model and the data. (As such, when evaluating deviance values, lower is better.) For linear models, with the classic assumptions (<span class="math inline">\(\overset{i.i.d.}{\sim}\mathcal{N}(0,\sigma^2_{\epsilon})\)</span>), the deviance is a function of the residual sum of squares (RSS):</p>
<p><span class="math display">\[
\mathrm{Deviance} = n \ln\big(2\pi\sigma^2_{\epsilon}\big) + \frac{\mathrm{RSS}}{\sigma^2_{\epsilon}}
\]</span></p>
<p>where <span class="math inline">\(\mathrm{RSS}=\sum\epsilon_i^2\)</span> and <span class="math inline">\(\sigma^2_{\epsilon} = \frac{\mathrm{RSS}}{n}\)</span>. This formula illustrates that the residual deviance is a generalization of the residual sum of squares (RSS), and measures the model–data misfit.</p>
<section id="mathematics-of-deviance" class="level3 mathnote" data-number="6.12.1">
<h3 data-number="6.12.1" class="anchored" data-anchor-id="mathematics-of-deviance"><span class="header-section-number">6.12.1</span> Mathematics of Deviance</h3>
<p>We can express the deviance mathematically by multiplying the log-likelihood by <span class="math inline">\(-2\)</span>.</p>
<p><span class="math display">\[
\begin{split}
\mathrm{Deviance} &amp;= -2 \times\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) \\[1ex]
&amp;= -2 \bigg(-\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \epsilon_i^2\bigg) \\[1ex]
&amp;= -n\ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{\sigma^2_{\epsilon}}\sum \epsilon_i^2 \\[1ex]
&amp;= -n\ln (2\pi\sigma^2_{\epsilon}) + \frac{\mathrm{RSS}}{\sigma^2_{\epsilon}}
\end{split}
\]</span></p>
<p>Rewriting this using the parameters from the likelihood:</p>
<p><span class="math display">\[
\mathrm{Deviance} = -n\ln (2\pi\sigma^2_{\epsilon}) + \frac{\sum_{i=1}^n \big[Y_i-\beta_0-\beta_1(X_i)\big]^2}{\sigma^2_{\epsilon}}
\]</span></p>
<p>Once again, we find that the only variables in the deviance function are the regression coefficients.</p>
</section>
<p>In practice, we will use the <code>logLik()</code> function to compute the deviance.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the deviance for Model 0</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.0</span>)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 896.1768</code></pre>
</div>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the deviance for Model 1</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.1</span>)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 883.5158</code></pre>
</div>
</div>
<p>Here the deviance for Model 1 (883.5) is less than the deviance for Model 0 (896.2). This indicates that the data have better fit to Model 1 than Model 0. How much better is the model–data fit for Model 1?</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute difference in deviances</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fl">896.2</span> <span class="sc">-</span> <span class="fl">883.5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 12.7</code></pre>
</div>
</div>
<p>Model 1 improves the fit (reduces the misfit) by 12.7 over Model 0. This is the value of our <span class="math inline">\(\chi^2\)</span>-statistic. That is, the <span class="math inline">\(\chi^2\)</span>-statistic is the difference in residual deviance values and measures the amount of improvement in the model–data misfit.</p>
<p><br></p>
<section id="modeling-the-variation-in-the-test-statistic" class="level3" data-number="6.12.2">
<h3 data-number="6.12.2" class="anchored" data-anchor-id="modeling-the-variation-in-the-test-statistic"><span class="header-section-number">6.12.2</span> Modeling the Variation in the Test Statistic</h3>
<p>If the null hypothesis is true, the difference in deviances can be modeled using a <span class="math inline">\(\chi^2\)</span>-distribution. The degrees-of-freedom for this <span class="math inline">\(\chi^2\)</span>-distribution is based on the difference in the number of parameters between the complex and simpler model. In our case this difference is four (<span class="math inline">\(3-2=1\)</span>):</p>
<p><span class="math display">\[
\chi^2(1) = 12.66
\]</span></p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dataset</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>fig_01 <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">X =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">20</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> <span class="fu">dchisq</span>(<span class="at">x =</span> X, <span class="at">df =</span> <span class="dv">1</span>)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out X&lt;=65</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>shaded <span class="ot">=</span> fig_01 <span class="sc">%&gt;%</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(X <span class="sc">&gt;=</span><span class="fl">12.66</span>)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create plot</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> fig_01, <span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y)) <span class="sc">+</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Chi-squared"</span>) <span class="sc">+</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Probability density"</span>) <span class="sc">+</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> shaded, <span class="at">ymin =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="fu">aes</span>(<span class="at">ymax =</span> Y), <span class="at">color =</span> <span class="st">"#bbbbbb"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-01" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Plot of the probability density function (PDF) for a $\chi^2(1)$ distribution. The grey shaded area represents the *p*-value based on $\chi^2=12.66$.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-03-likelihood-framework-for-evidence_files/figure-html/fig-01-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%" alt="Plot of the probability density function (PDF) for a $\chi^2(1)$ distribution. The grey shaded area represents the *p*-value based on $\chi^2=12.66$.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6.1: Plot of the probability density function (PDF) for a <span class="math inline">\(\chi^2(1)\)</span> distribution. The grey shaded area represents the <em>p</em>-value based on <span class="math inline">\(\chi^2=12.66\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>To compute the <em>p</em>-value we use the <code>pchisq()</code> function.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute p-value for X^2(1) = 14.50</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fl">12.66</span>, <span class="at">df =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0003735622</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative method</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fl">12.66</span>, <span class="at">df =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0003735622</code></pre>
</div>
</div>
<p>Based on the <em>p</em>-value, we would reject the null hypothesis for the likelihood ratio test, which suggests that we should adopt the more complex model (Model 1). This means that the model that includes the effect of news exposure is more empirically supported than a model that includes no predictors. Note that we are making a holistic evaluation about the model rather than about individual predictors.</p>
<!-- To determine how much more variation Model 1 explains in news knowledge than Model 0 does, we look at the $R^2$ values from the `glance()` output. -->
<!-- ```{r} -->
<!-- # Model-level output Model 0 -->
<!-- glance(lm.0) -->
<!-- # Model-level output Model 1 -->
<!-- glance(lm.1) -->
<!-- ``` -->
<!-- Model 1 explains 26.4% of the variation in peer ratings compared to Model 0, which explains 0% of the variation in peer ratings. This difference is statistically significant based on the *p*-value obtained from the likelihood ratio test ($p=0.000041$).  -->
<p><br></p>
</section>
</section>
<section id="using-the-lrtest-function" class="level2" data-number="6.13">
<h2 data-number="6.13" class="anchored" data-anchor-id="using-the-lrtest-function"><span class="header-section-number">6.13</span> Using the <code>lrtest()</code> Function</h2>
<p>In practice, we can also use the <code>lrtest()</code> function from the <code>{lmtest}</code> package to carry out a likelihood ratio test. We provide this function the name of the model object for the simpler model, followed by the name of the model object for the more complex model.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co"># LRT to compare Model 0 and Model 1</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.0</span>, lm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Likelihood ratio test

Model 1: knowledge ~ 1
Model 2: knowledge ~ 1 + news
  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    
1   2 -448.09                         
2   3 -441.76  1 12.661  0.0003734 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="evaluating-the-effect-of-news-exposure-in-research-question-2" class="level2" data-number="6.14">
<h2 data-number="6.14" class="anchored" data-anchor-id="evaluating-the-effect-of-news-exposure-in-research-question-2"><span class="header-section-number">6.14</span> Evaluating the Effect of News Exposure in Research Question 2</h2>
<p>In RQ 2, we are evaluating the effect of news exposure on news knowledge after controlling for the set of political and demographic covariates. To do this using a likelihood ratio test, we need to compare a baseline model that includes all of the covariates to a model that includes the covariates AND the effect of news exposure. That is, the only thing that is different between the two models is that the second model includes the effect of news exposure on top of the covariates. That is we will be comparing the following two models:</p>
<p><span class="math display">\[
\begin{split}
\mathbf{Simple~Model:~} \quad \mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{Education}_i) + \beta_2(\mathrm{Male}_i) + \\
&amp;\beta_3(\mathrm{Engagement}_i) + \epsilon_i \\[2ex]
\mathbf{Complex~Model:~} \quad \mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{Education}_i) + \beta_2(\mathrm{Male}_i) + \\
&amp;\beta_3(\mathrm{Engagement}_i) + \beta_8(\mathrm{News~Exposure}_i) + \epsilon_i \\[2ex]
\end{split}
\]</span></p>
<p>By comparing the parameters of the two models, we can see that the simpler model is nested in the more complex model.</p>
<p><span class="math display">\[
\begin{split}
\mathbf{Simple~Model~Parameters:}&amp;\quad\{\beta_0,~\beta_{\mathrm{Education}},~\beta_{\mathrm{Male}},~\beta_{\mathrm{Engagement}},~\sigma^2_{\epsilon}\} \\[1ex]
\mathbf{Complex~Model~Parameters:}&amp;\quad\{\beta_0, ~\beta_{\mathrm{Education}},~\beta_{\mathrm{Male}},~\beta_{\mathrm{Engagement}},~\beta_{\mathrm{News~Exposure}},~\sigma^2_{\epsilon}\} \\[1ex]
\end{split}
\]</span></p>
<p>To carry out the LRT we fit the two models, compute the difference in model deviances, and evaluate that difference in a <span class="math inline">\(\chi^2\)</span>-distribution with degrees-of-freedom equal to the difference in model complexity (based on the number of parameters being estimated).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple model</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.2</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement, <span class="at">data =</span> pew)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Complex model</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.3</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news, <span class="at">data =</span> pew)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the difference in deviances between Model 1 and Model 2</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.2</span>)[<span class="dv">1</span>] <span class="sc">-</span> (<span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.3</span>)[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 8.924345</code></pre>
</div>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the difference in model complexity</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span> <span class="sc">-</span> <span class="dv">5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute p-value for X^2(1) = 7.960401</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fl">8.924345</span>, <span class="at">df =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.002813943</code></pre>
</div>
</div>
<p>The <em>p</em>-value is 0.002813943, suggesting that there is an effect of news exposure on news knowledge, after controlling for the set of political and demographic covariates. Again, we could also obtain this same result via using the <code>lrtest()</code> function.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># LRT to compare Model 2 and Model 3</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.2</span>, lm<span class="fl">.3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Likelihood ratio test

Model 1: knowledge ~ 1 + education + male + engagement
Model 2: knowledge ~ 1 + education + male + engagement + news
  #Df  LogLik Df  Chisq Pr(&gt;Chisq)   
1   5 -420.78                        
2   6 -416.32  1 8.9243   0.002814 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="evaluating-the-interaction-effect-in-research-question-3" class="level2" data-number="6.15">
<h2 data-number="6.15" class="anchored" data-anchor-id="evaluating-the-interaction-effect-in-research-question-3"><span class="header-section-number">6.15</span> Evaluating the Interaction Effect in Research Question 3</h2>
<p>To evaluate the potential interaction effect between news exposure and education on news knowledge, after controlling for demographic and political covariates, we need to fit the interaction model and then compare it to a model that includes all the same predictors EXCEPT the interaction effect.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit interaction model</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that Model 3 (fitted earlier) is the baseline comparison model to evaluate the interaction effect. Here we will use the <code>lrtest()</code> function to compare Models 3 and 4 to evaluate the interaction effect.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># LRT to compare Model 1 and Model 2</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.3</span>, lm<span class="fl">.4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Likelihood ratio test

Model 1: knowledge ~ 1 + education + male + engagement + news
Model 2: knowledge ~ 1 + education + male + engagement + news + news:education
  #Df  LogLik Df  Chisq Pr(&gt;Chisq)  
1   6 -416.32                       
2   7 -413.74  1 5.1506    0.02324 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The <em>p</em>-value is 0.02324, suggesting that there is an interaction effect between news exposure and education level after controlling for differences in the set of political and demographic covariates.</p>
<p><br></p>
</section>
<section id="evaluating-assumptions" class="level2" data-number="6.16">
<h2 data-number="6.16" class="anchored" data-anchor-id="evaluating-assumptions"><span class="header-section-number">6.16</span> Evaluating Assumptions</h2>
<p>If we were adopting a “final model”, the empirical evidence would support adopting Model 4. It is always important to evaluate any adopted final models’ assumptions.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create residual plots</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="fu">residual_plots</span>(lm<span class="fl">.4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-residuals-linear" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Two residual plots for Model 4.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-residuals-linear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-03-likelihood-framework-for-evidence_files/figure-html/fig-residuals-linear-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%" alt="Two residual plots for Model 4.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-residuals-linear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6.2: Two residual plots for Model 4.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Based on the density plot, the assumption of normality looks reasonably met. The scatterplot suggests the assumption that the average residual is 0 is generally met—the loess smoother suggests the average residual is close to 0 at all fitted values. The homoscadasticity assumption also seems reasonable with the range of residuals generally being constant across the different fitted values. Lastly, since the sample is a random sample of Americans, the independence assumption also seems tenable.</p>
</section>
<section id="presenting-the-results-from-the-lrts" class="level2" data-number="6.17">
<h2 data-number="6.17" class="anchored" data-anchor-id="presenting-the-results-from-the-lrts"><span class="header-section-number">6.17</span> Presenting the Results from the LRTs</h2>
<p>Below we present a table summarizing the results of the likelihood ratio tests.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up data</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">comparison =</span> <span class="fu">c</span>(<span class="st">"Model 0 vs. Model 1"</span>, <span class="st">"Model 2 vs. Model 3"</span>, <span class="st">"Model 3 vs. Model 4"</span>),</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">chi =</span> <span class="fu">c</span>(<span class="st">"$$</span><span class="sc">\\</span><span class="st">chi^2(1) = 12.66$$"</span>, <span class="st">"$$</span><span class="sc">\\</span><span class="st">chi^2(1) = 8.92$$"</span>, <span class="st">"$$</span><span class="sc">\\</span><span class="st">chi^2(1) = 5.15$$"</span>),</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="fu">c</span>(<span class="st">"&lt;.001"</span>, <span class="st">".003"</span>, <span class="st">".023"</span>)</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create table</span></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>d <span class="sc">|&gt;</span></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>() <span class="sc">|&gt;</span></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_label</span>(</span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">comparison =</span> <span class="fu">md</span>(<span class="st">"*Model Comparison*"</span>),</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">chi =</span> <span class="st">"LRT Result"</span>,</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">p =</span> <span class="fu">md</span>(<span class="st">"*p*"</span>)</span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(comparison),</span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"left"</span></span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(chi, p),</span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"center"</span></span>
<span id="cb64-26"><a href="#cb64-26" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb64-27"><a href="#cb64-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_options</span>(</span>
<span id="cb64-28"><a href="#cb64-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">table.width =</span> <span class="fu">pct</span>(<span class="dv">60</span>),</span>
<span id="cb64-29"><a href="#cb64-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">quarto.disable_processing =</span> <span class="cn">TRUE</span></span>
<span id="cb64-30"><a href="#cb64-30" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="tbl-model-likelihood" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-model-likelihood-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;6.1: Results from a set of likelihood ratio tests (LRT) to compare sets of nested candidate models.
</figcaption>
<div aria-describedby="tbl-model-likelihood-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="yptomzfoyn" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#yptomzfoyn table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#yptomzfoyn thead, #yptomzfoyn tbody, #yptomzfoyn tfoot, #yptomzfoyn tr, #yptomzfoyn td, #yptomzfoyn th {
  border-style: none;
}

#yptomzfoyn p {
  margin: 0;
  padding: 0;
}

#yptomzfoyn .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: 60%;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#yptomzfoyn .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#yptomzfoyn .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#yptomzfoyn .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#yptomzfoyn .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#yptomzfoyn .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#yptomzfoyn .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#yptomzfoyn .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#yptomzfoyn .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#yptomzfoyn .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#yptomzfoyn .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#yptomzfoyn .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#yptomzfoyn .gt_spanner_row {
  border-bottom-style: hidden;
}

#yptomzfoyn .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#yptomzfoyn .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#yptomzfoyn .gt_from_md > :first-child {
  margin-top: 0;
}

#yptomzfoyn .gt_from_md > :last-child {
  margin-bottom: 0;
}

#yptomzfoyn .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#yptomzfoyn .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#yptomzfoyn .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#yptomzfoyn .gt_row_group_first td {
  border-top-width: 2px;
}

#yptomzfoyn .gt_row_group_first th {
  border-top-width: 2px;
}

#yptomzfoyn .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#yptomzfoyn .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#yptomzfoyn .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#yptomzfoyn .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#yptomzfoyn .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#yptomzfoyn .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#yptomzfoyn .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#yptomzfoyn .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#yptomzfoyn .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#yptomzfoyn .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#yptomzfoyn .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#yptomzfoyn .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#yptomzfoyn .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#yptomzfoyn .gt_left {
  text-align: left;
}

#yptomzfoyn .gt_center {
  text-align: center;
}

#yptomzfoyn .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#yptomzfoyn .gt_font_normal {
  font-weight: normal;
}

#yptomzfoyn .gt_font_bold {
  font-weight: bold;
}

#yptomzfoyn .gt_font_italic {
  font-style: italic;
}

#yptomzfoyn .gt_super {
  font-size: 65%;
}

#yptomzfoyn .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#yptomzfoyn .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#yptomzfoyn .gt_indent_1 {
  text-indent: 5px;
}

#yptomzfoyn .gt_indent_2 {
  text-indent: 10px;
}

#yptomzfoyn .gt_indent_3 {
  text-indent: 15px;
}

#yptomzfoyn .gt_indent_4 {
  text-indent: 20px;
}

#yptomzfoyn .gt_indent_5 {
  text-indent: 25px;
}

#yptomzfoyn .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#yptomzfoyn div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
<table class="gt_table" data-quarto-disable-processing="true" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="comparison"><span data-qmd-base64="PGVtPk1vZGVsIENvbXBhcmlzb248L2VtPg=="><span class="gt_from_md"><em>Model Comparison</em></span></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="chi">LRT Result</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="p"><span data-qmd-base64="PGVtPnA8L2VtPg=="><span class="gt_from_md"><em>p</em></span></span></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="comparison" class="gt_row gt_left">Model 0 vs. Model 1</td>
<td headers="chi" class="gt_row gt_center">$$\chi^2(1) = 12.66$$</td>
<td headers="p" class="gt_row gt_center">&lt;.001</td></tr>
    <tr><td headers="comparison" class="gt_row gt_left">Model 2 vs. Model 3</td>
<td headers="chi" class="gt_row gt_center">$$\chi^2(1) = 8.92$$</td>
<td headers="p" class="gt_row gt_center">.003</td></tr>
    <tr><td headers="comparison" class="gt_row gt_left">Model 3 vs. Model 4</td>
<td headers="chi" class="gt_row gt_center">$$\chi^2(1) = 5.15$$</td>
<td headers="p" class="gt_row gt_center">.023</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</figure>
</div>
</div>
<!-- ```{r} -->
<!-- #| results: asis -->
<!-- #| code-fold: true -->
<!-- # Load library -->
<!-- library(texreg) -->
<!-- # Create the table -->
<!-- htmlreg( -->
<!--   l = list(lm.0, lm.1, lm.2, lm.3, lm.4), -->
<!--   stars = numeric(0),    #No p-value stars -->
<!--   digits = 3, -->
<!--   padding = 20,          #Add space around columns (you may need to adjust this via trial-and-error) -->
<!--   include.adjrs = FALSE, #Omit Adjusted R^2 -->
<!--   include.nobs = FALSE,  #Omit sample size -->
<!--   include.rmse = TRUE,   #Include RMSE -->
<!--   custom.model.names = c("Model 0", "Model 1", "Model 2", "Model 3", "Model 4"), -->
<!--   custom.coef.names = c("Intercept", "News Exposure", -->
<!--                         "Education (in years)", "Male", -->
<!--                         "Political Engagement", -->
<!--                         "Education x News Exposure"), -->
<!--   custom.note = "Note. Male, is a dummy-coded predictors. The reference group is non-males.", -->
<!--   reorder.coef = c(2:6, 1), #Put intercept at bottom of table -->
<!--   custom.gof.rows = list( -->
<!--     `ln(Likelihood)` = c(-448.09, -441.76, -417.93, -413.92, -411.33) -->
<!--   ), -->
<!--   reorder.gof = c(3, 2, 1), -->
<!--   caption.above = TRUE, #Move caption above table -->
<!--   inner.rules = 1, #Include line rule before model-level output -->
<!--   outer.rules = 1,  #Include line rules around table -->
<!--   caption = "Table 2: Coefficients (and standard errors) for five models evaluating predictors of news knowledge." -->
<!--   ) -->
<!-- ``` -->
<p><br></p>
</section>
<section id="reporting-individual-predictors-from-a-model" class="level2" data-number="6.18">
<h2 data-number="6.18" class="anchored" data-anchor-id="reporting-individual-predictors-from-a-model"><span class="header-section-number">6.18</span> Reporting Individual Predictors From a Model</h2>
<p>It is also good practice to report the coefficient-level and model-level estimates from any adopted models in a regression table. We will report results from Model 4. At the coefficient-level, the coefficients and standard errors can be reported from the <code>tidy()</code> output. However, since we are using a likelihood framework, the <em>p</em>-values from the <code>tidy()</code> output are incorrect! We need to compute and report likelihood-based <em>p</em>-values.</p>
<p>For example, to evaluate the effect of education on news knowledge we would essentially want to test the hypothesis that:</p>
<p><span class="math display">\[
H_0: \beta_{\mathrm{Education}} = 0
\]</span></p>
<p>To do this with a LRT, we need to compare two models:</p>
<ul>
<li>One model that includes all of the predictors from Model 4;</li>
<li>One model that includes everything from Model 4 <em>except</em> the effect of education.</li>
</ul>
<p>The only difference between these two models is the inclusion of the effect of education in the second model. That means any additional empirical support for the second model over the first is completely due to the effect of education. And, because the second model is nested in the first, we can evaluate this via a LRT.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit full model 4</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model without education</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_education <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Carry out LRT</span></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_education, lm<span class="fl">.4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Likelihood ratio test

Model 1: knowledge ~ 1 + male + engagement + news + news:education
Model 2: knowledge ~ 1 + education + male + engagement + news + news:education
  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    
1   6 -421.05                         
2   7 -413.74  1 14.621  0.0001314 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The <em>p</em>-value associated with the test of whether or not there is an effect of education (at least for the main effect) is 0.0001314. We will need to obtain the likelihood-based <em>p</em>-value for all of the other effects in a similar way. We will</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Effect of male</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_male <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_male, lm<span class="fl">.4</span>) <span class="co"># Carry out LRT</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Likelihood ratio test

Model 1: knowledge ~ 1 + education + engagement + news + news:education
Model 2: knowledge ~ 1 + education + male + engagement + news + news:education
  #Df  LogLik Df Chisq Pr(&gt;Chisq)    
1   6 -420.14                        
2   7 -413.74  1  12.8  0.0003466 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Effect of engagement</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_engage <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_engage, lm<span class="fl">.4</span>) <span class="co"># Carry out LRT</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Likelihood ratio test

Model 1: knowledge ~ 1 + education + male + news + news:education
Model 2: knowledge ~ 1 + education + male + engagement + news + news:education
  #Df  LogLik Df Chisq Pr(&gt;Chisq)    
1   6 -422.71                        
2   7 -413.74  1 17.94  0.0000228 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Effect of new exposure (main-effect)</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_news <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_news, lm<span class="fl">.4</span>) <span class="co"># Carry out LRT</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Likelihood ratio test

Model 1: knowledge ~ 1 + education + male + engagement + news:education
Model 2: knowledge ~ 1 + education + male + engagement + news + news:education
  #Df  LogLik Df  Chisq Pr(&gt;Chisq)   
1   6 -417.46                        
2   7 -413.74  1 7.4479   0.006351 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Effect of interaction</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_interaction <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news, <span class="at">data =</span> pew)</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_interaction, lm<span class="fl">.4</span>) <span class="co"># Carry out LRT</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Likelihood ratio test

Model 1: knowledge ~ 1 + education + male + engagement + news
Model 2: knowledge ~ 1 + education + male + engagement + news + news:education
  #Df  LogLik Df  Chisq Pr(&gt;Chisq)  
1   6 -416.32                       
2   7 -413.74  1 5.1506    0.02324 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Intercept</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_intercept <span class="ot">=</span> <span class="fu">lm</span>(knowledge<span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_intercept, lm<span class="fl">.4</span>) <span class="co"># Carry out LRT</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Likelihood ratio test

Model 1: knowledge ~ 0 + education + male + engagement + news + news:education
Model 2: knowledge ~ 1 + education + male + engagement + news + news:education
  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    
1   6 -419.43                         
2   7 -413.74  1 11.382  0.0007417 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>We can then replace the <em>p</em>-values from the <code>tidy()</code> output with these likelihood-based <em>p</em>-values. Also, since these <em>p</em>-values are based on chi-squared (not a <em>t</em>-value), we should replace the <em>t</em>-values from the <code>tidy()</code> output with the <span class="math inline">\(\chi^2\)</span>-values from the LRTs.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(lm<span class="fl">.4</span>) <span class="sc">|&gt;</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">statistic =</span> <span class="fu">c</span>(<span class="fl">11.38</span>, <span class="fl">14.62</span>, <span class="fl">12.80</span>, <span class="fl">17.94</span>, <span class="fl">7.45</span>, <span class="fl">5.15</span>),</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">p.value =</span> <span class="fu">c</span>(<span class="fl">0.0007417</span>, <span class="fl">0.0001314</span>, <span class="fl">0.0003466</span>, <span class="fl">0.0000228</span>, <span class="fl">0.006351</span>, <span class="fl">0.02324</span>)</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>  ) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 5
  term           estimate std.error statistic   p.value
  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept)    -80.8      24.0        11.4  0.000742 
2 education        6.44      1.68       14.6  0.000131 
3 male            11.3       3.15       12.8  0.000347 
4 engagement       0.391     0.0910     17.9  0.0000228
5 news             1.17      0.436       7.45 0.00635  
6 education:news  -0.0663    0.0298      5.15 0.0232   </code></pre>
</div>
</div>
<p>If we were reporting this for publication, we could round the <em>p</em>-values to three decimal places. We would also want to indicate that these are likelihood-based <em>p</em>-values, and that the LRT is based on 1 <em>df</em>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gtsummary) <span class="co"># for formatting p-values</span></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create table</span></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(lm<span class="fl">.4</span>) <span class="sc">|&gt;</span></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">term =</span> <span class="fu">c</span>(<span class="st">"Intercept"</span>, <span class="st">"Education-level"</span>, <span class="st">"Male"</span>, <span class="st">"Political engagement"</span>, <span class="st">"News exposure"</span>, <span class="st">"Education-level x News exposure"</span>),</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">statistic =</span> <span class="fu">c</span>(<span class="fl">11.38</span>, <span class="fl">14.62</span>, <span class="fl">12.80</span>, <span class="fl">17.94</span>, <span class="fl">7.45</span>, <span class="fl">5.15</span>),</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">p.value =</span> <span class="fu">style_pvalue</span>(<span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.0001314</span>, <span class="fl">0.0003466</span>, <span class="fl">0.0000228</span>, <span class="fl">0.006351</span>, <span class="fl">0.02324</span>), <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>  )  <span class="sc">|&gt;</span></span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>() <span class="sc">|&gt;</span></span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_label</span>(</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">term =</span> <span class="fu">md</span>(<span class="st">"*Predictor*"</span>),</span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">estimate =</span> <span class="fu">md</span>(<span class="st">"*B*"</span>),</span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">std.error =</span> <span class="fu">md</span>(<span class="st">"*SE*"</span>),</span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">statistic =</span> <span class="st">"$$</span><span class="sc">\\</span><span class="st">chi^2$$"</span>,</span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">p.value =</span> <span class="fu">md</span>(<span class="st">"*p*"</span>)</span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(term),</span>
<span id="cb79-22"><a href="#cb79-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"left"</span></span>
<span id="cb79-23"><a href="#cb79-23" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb79-24"><a href="#cb79-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb79-25"><a href="#cb79-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(estimate, std.error, statistic, p.value),</span>
<span id="cb79-26"><a href="#cb79-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"center"</span></span>
<span id="cb79-27"><a href="#cb79-27" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb79-28"><a href="#cb79-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fmt_number</span>(</span>
<span id="cb79-29"><a href="#cb79-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(estimate, std.error),</span>
<span id="cb79-30"><a href="#cb79-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">decimals =</span> <span class="dv">2</span>,</span>
<span id="cb79-31"><a href="#cb79-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">use_seps =</span> <span class="cn">FALSE</span></span>
<span id="cb79-32"><a href="#cb79-32" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb79-33"><a href="#cb79-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_options</span>(</span>
<span id="cb79-34"><a href="#cb79-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">table.width =</span> <span class="fu">pct</span>(<span class="dv">70</span>)</span>
<span id="cb79-35"><a href="#cb79-35" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb79-36"><a href="#cb79-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_footnote</span>(</span>
<span id="cb79-37"><a href="#cb79-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">footnote =</span> <span class="fu">md</span>(<span class="st">"Male is a dummy-coded predictor with non-male as the reference group."</span>),</span>
<span id="cb79-38"><a href="#cb79-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">locations =</span>  <span class="fu">cells_body</span>(<span class="at">columns =</span> term, <span class="at">rows =</span> <span class="dv">3</span>)</span>
<span id="cb79-39"><a href="#cb79-39" aria-hidden="true" tabindex="-1"></a>  ) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="tbl-model-4" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-model-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;6.2: Coefficients and standard errors for Model 4. The <span class="math inline">\(\chi^2\)</span> values and <em>p</em>-values are based on likelihood ratio tests (LRT) with 1 degree-of-freedom to evaluate each predictor.
</figcaption>
<div aria-describedby="tbl-model-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="bjsmzprbif" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#bjsmzprbif table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#bjsmzprbif thead, #bjsmzprbif tbody, #bjsmzprbif tfoot, #bjsmzprbif tr, #bjsmzprbif td, #bjsmzprbif th {
  border-style: none;
}

#bjsmzprbif p {
  margin: 0;
  padding: 0;
}

#bjsmzprbif .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: 70%;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#bjsmzprbif .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#bjsmzprbif .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#bjsmzprbif .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#bjsmzprbif .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#bjsmzprbif .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#bjsmzprbif .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#bjsmzprbif .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#bjsmzprbif .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#bjsmzprbif .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#bjsmzprbif .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#bjsmzprbif .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#bjsmzprbif .gt_spanner_row {
  border-bottom-style: hidden;
}

#bjsmzprbif .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#bjsmzprbif .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#bjsmzprbif .gt_from_md > :first-child {
  margin-top: 0;
}

#bjsmzprbif .gt_from_md > :last-child {
  margin-bottom: 0;
}

#bjsmzprbif .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#bjsmzprbif .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#bjsmzprbif .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#bjsmzprbif .gt_row_group_first td {
  border-top-width: 2px;
}

#bjsmzprbif .gt_row_group_first th {
  border-top-width: 2px;
}

#bjsmzprbif .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#bjsmzprbif .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#bjsmzprbif .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#bjsmzprbif .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#bjsmzprbif .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#bjsmzprbif .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#bjsmzprbif .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#bjsmzprbif .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#bjsmzprbif .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#bjsmzprbif .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#bjsmzprbif .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#bjsmzprbif .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#bjsmzprbif .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#bjsmzprbif .gt_left {
  text-align: left;
}

#bjsmzprbif .gt_center {
  text-align: center;
}

#bjsmzprbif .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#bjsmzprbif .gt_font_normal {
  font-weight: normal;
}

#bjsmzprbif .gt_font_bold {
  font-weight: bold;
}

#bjsmzprbif .gt_font_italic {
  font-style: italic;
}

#bjsmzprbif .gt_super {
  font-size: 65%;
}

#bjsmzprbif .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#bjsmzprbif .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#bjsmzprbif .gt_indent_1 {
  text-indent: 5px;
}

#bjsmzprbif .gt_indent_2 {
  text-indent: 10px;
}

#bjsmzprbif .gt_indent_3 {
  text-indent: 15px;
}

#bjsmzprbif .gt_indent_4 {
  text-indent: 20px;
}

#bjsmzprbif .gt_indent_5 {
  text-indent: 25px;
}

#bjsmzprbif .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#bjsmzprbif div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_col_headings header">
<th id="term" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col"><em>Predictor</em></th>
<th id="estimate" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col"><em>B</em></th>
<th id="std.error" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col"><em>SE</em></th>
<th id="statistic" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col">$$\chi^2$$</th>
<th id="p.value" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col"><em>p</em></th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left" headers="term">Intercept</td>
<td class="gt_row gt_center" headers="estimate">−80.79</td>
<td class="gt_row gt_center" headers="std.error">24.00</td>
<td class="gt_row gt_center" headers="statistic">11.38</td>
<td class="gt_row gt_center" headers="p.value">0.001</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="term">Education-level</td>
<td class="gt_row gt_center" headers="estimate">6.44</td>
<td class="gt_row gt_center" headers="std.error">1.68</td>
<td class="gt_row gt_center" headers="statistic">14.62</td>
<td class="gt_row gt_center" headers="p.value">&lt;0.001</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="term">Male<span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;"><sup>1</sup></span></td>
<td class="gt_row gt_center" headers="estimate">11.30</td>
<td class="gt_row gt_center" headers="std.error">3.15</td>
<td class="gt_row gt_center" headers="statistic">12.80</td>
<td class="gt_row gt_center" headers="p.value">&lt;0.001</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="term">Political engagement</td>
<td class="gt_row gt_center" headers="estimate">0.39</td>
<td class="gt_row gt_center" headers="std.error">0.09</td>
<td class="gt_row gt_center" headers="statistic">17.94</td>
<td class="gt_row gt_center" headers="p.value">&lt;0.001</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="term">News exposure</td>
<td class="gt_row gt_center" headers="estimate">1.17</td>
<td class="gt_row gt_center" headers="std.error">0.44</td>
<td class="gt_row gt_center" headers="statistic">7.45</td>
<td class="gt_row gt_center" headers="p.value">0.006</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="term">Education-level x News exposure</td>
<td class="gt_row gt_center" headers="estimate">−0.07</td>
<td class="gt_row gt_center" headers="std.error">0.03</td>
<td class="gt_row gt_center" headers="statistic">5.15</td>
<td class="gt_row gt_center" headers="p.value">0.023</td>
</tr>
</tbody><tfoot class="gt_footnotes">
<tr class="odd">
<td colspan="5" class="gt_footnote"><span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;"><sup>1</sup></span> Male is a dummy-coded predictor with non-male as the reference group.</td>
</tr>
</tfoot>

</table>

</div>
</div>
</div>
</figure>
</div>
</div>
<p><br></p>
</section>
<section id="references" class="level2" data-number="6.19">
<h2 data-number="6.19" class="anchored" data-anchor-id="references"><span class="header-section-number">6.19</span> References</h2>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-Cohen:1994" class="csl-entry" role="listitem">
Cohen, J. (1994). The earth is round (<span class="math inline">\(p &lt; .05\)</span>). <em>American Psychologist</em>, <em>49</em>(12), 997–1003.
</div>
<div id="ref-Johansson:2011" class="csl-entry" role="listitem">
Johansson, T. (2011). Hail the impossible: P-values, evidence, and likelihood. <em>Scandinavian Journal of Psychology</em>, <em>52</em>, 113–125. <a href="https://doi.org/10.1111/j.1467-9450.2010.00852.x">https://doi.org/10.1111/j.1467-9450.2010.00852.x</a>
</div>
<div id="ref-Johnstone:1986" class="csl-entry" role="listitem">
Johnstone, D. J. (1986). Tests of significance in theory and practice. <em>The Statistician</em>, <em>35</em>, 491–504.
</div>
<div id="ref-Mosteller:1954" class="csl-entry" role="listitem">
Mosteller, F., &amp; Bush, R. B. (1954). Selected quantitative techniques. In G. Lindzey (Ed.), <em>Handbook of social psychology</em> (pp. 289–334). Addison-Wesley.
</div>
<div id="ref-Weakliem:2016" class="csl-entry" role="listitem">
Weakliem, D. L. (2016). <em>Hypothesis testing and model selection in the social sciences</em>. The Guilford Press.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Sometimes this is also referred to a the sum of squared errors (SSE).<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>This is in some sense mixing the paradigms of likelihood-based evidence and classical hypothesis test-based evidence. In a future set of notes we will learn about information criteria which eliminate the need to mix these two paradigms.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The use of the term “residual deviance” is not universal. Some textbooks omit the “residual” part and just refer to it as the “deviance”. Others use the term “model deviance”.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-01-mathematical-foundations-probability-density.html" class="pagination-link" aria-label="Mathematical Foundations: Probability Density">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Mathematical Foundations: Probability Density</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./02-04-likelihood-framework-for-estimation.html" class="pagination-link" aria-label="Likelihood: A Framework for Estimation">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Estimation</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb80" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Likelihood: A Framework for Evidence</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"scripts/_common.R"</span>)</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a><span class="fu">## Preparation</span></span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a>In this set of notes, you will learn about the law of likelihood, and the use of likelihood ratios as statistical evidence for model selection. To do so, we will use the <span class="co">[</span><span class="ot">pew.csv</span><span class="co">](https://raw.githubusercontent.com/zief0002/fluffy-ants/main/data/pew.csv)</span> dataset (see the <span class="co">[</span><span class="ot">data codebook</span><span class="co">](http://zief0002.github.io/fluffy-ants/codebooks/pew.html)</span>) to fit a set of models that explain variation in American's political knowledge. </span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-17"><a href="#cb80-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-20"><a href="#cb80-20" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-21"><a href="#cb80-21" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb80-22"><a href="#cb80-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Load libraries</span></span>
<span id="cb80-23"><a href="#cb80-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb80-24"><a href="#cb80-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(educate)</span>
<span id="cb80-25"><a href="#cb80-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb80-26"><a href="#cb80-26" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb80-27"><a href="#cb80-27" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb80-28"><a href="#cb80-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-29"><a href="#cb80-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Import data</span></span>
<span id="cb80-30"><a href="#cb80-30" aria-hidden="true" tabindex="-1"></a>pew <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="at">file =</span> <span class="st">"https://raw.githubusercontent.com/zief0002/fluffy-ants/main/data/pew.csv"</span>)</span>
<span id="cb80-31"><a href="#cb80-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-32"><a href="#cb80-32" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb80-33"><a href="#cb80-33" aria-hidden="true" tabindex="-1"></a>pew</span>
<span id="cb80-34"><a href="#cb80-34" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-35"><a href="#cb80-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-36"><a href="#cb80-36" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-37"><a href="#cb80-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-38"><a href="#cb80-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-39"><a href="#cb80-39" aria-hidden="true" tabindex="-1"></a><span class="fu">## Research Questions and Modeling Strategy</span></span>
<span id="cb80-40"><a href="#cb80-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-41"><a href="#cb80-41" aria-hidden="true" tabindex="-1"></a>Recall that we had three research questions for these data:</span>
<span id="cb80-42"><a href="#cb80-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-43"><a href="#cb80-43" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Is there an effect of news exposure on political knowledge?</span>
<span id="cb80-44"><a href="#cb80-44" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Is there an effect of news exposure on political knowledge after controlling for demographic and political covariates?</span>
<span id="cb80-45"><a href="#cb80-45" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Does education level *moderate* the effect of news exposure on political knowledge after controlling for demographic and political covariates?</span>
<span id="cb80-46"><a href="#cb80-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-47"><a href="#cb80-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-48"><a href="#cb80-48" aria-hidden="true" tabindex="-1"></a>Any analysis should begin with looking at plots and computing summary statistics of the sample data. (We already did this in a previous set of notes.) After the data exploration, we can begin to think about fitting one or more models to the data. It is good science to consider the modeling strategy you will be using before you begin fitting models. There are many modeling strategies that educational scientists use in practice (e.g., forward-selection, backward-elimination) and there is no one "right" method. As you consider a modeling strategy, think about how this strategy helps provide a narrative structure for answering your research question; sometimes this leads to one strategy being more productive than others.</span>
<span id="cb80-49"><a href="#cb80-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-50"><a href="#cb80-50" aria-hidden="true" tabindex="-1"></a>In the previous set of notes we began by fitting a model that only included the main-effect of news exposure. Evaluating the effect of news exposure in this model helped us answer RQ 1. We then fitted a model that included news exposure along with the set of demographic and political covariates. Evaluating the effect of news exposure in this model helped us answer RQ 2. Finally, we fitted a model that included an interaction effect of news exposure and education in along with the demographic and political covariates. Evaluating the interaction effect allowed us to answer RQ 3. These three models are:</span>
<span id="cb80-51"><a href="#cb80-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-52"><a href="#cb80-52" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-53"><a href="#cb80-53" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-54"><a href="#cb80-54" aria-hidden="true" tabindex="-1"></a>\mathbf{Model~1:~} \quad \mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{News~Exposure}_i) + \epsilon_i <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb80-55"><a href="#cb80-55" aria-hidden="true" tabindex="-1"></a>\mathbf{Model~2:~} \quad \mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{Age}_i) + \beta_2(\mathrm{Education}_i) + \beta_3(\mathrm{Male}_i) + <span class="sc">\\</span> </span>
<span id="cb80-56"><a href="#cb80-56" aria-hidden="true" tabindex="-1"></a>&amp;\beta_4(\mathrm{Engagement}_i) + \beta_5(\mathrm{Ideology}_i)+ <span class="sc">\\</span></span>
<span id="cb80-57"><a href="#cb80-57" aria-hidden="true" tabindex="-1"></a>&amp;\beta_6(\mathrm{Democrat}_i) + \beta_7(\mathrm{Republican}_i) + <span class="sc">\\</span></span>
<span id="cb80-58"><a href="#cb80-58" aria-hidden="true" tabindex="-1"></a>&amp;\beta_8(\mathrm{News~Exposure}_i) + \epsilon_i <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb80-59"><a href="#cb80-59" aria-hidden="true" tabindex="-1"></a>\mathbf{Model~3:~} \quad \mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{Age}_i) + \beta_2(\mathrm{Education}_i) + \beta_3(\mathrm{Male}_i) + <span class="sc">\\</span></span>
<span id="cb80-60"><a href="#cb80-60" aria-hidden="true" tabindex="-1"></a>&amp;\beta_4(\mathrm{Engagement}_i) + \beta_5(\mathrm{Ideology}_i)+ <span class="sc">\\</span></span>
<span id="cb80-61"><a href="#cb80-61" aria-hidden="true" tabindex="-1"></a>&amp;\beta_6(\mathrm{Democrat}_i) + \beta_7(\mathrm{Republican}_i) + <span class="sc">\\</span> </span>
<span id="cb80-62"><a href="#cb80-62" aria-hidden="true" tabindex="-1"></a>&amp;\beta_8(\mathrm{News~Exposure}_i) + \beta_9(\mathrm{News~Exposure}_i)(\mathrm{Education}_i) + \epsilon_i <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb80-63"><a href="#cb80-63" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-64"><a href="#cb80-64" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-65"><a href="#cb80-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-66"><a href="#cb80-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-67"><a href="#cb80-67" aria-hidden="true" tabindex="-1"></a>where $\epsilon_i \overset{i.i.d.}{\sim}\mathcal{N}(0,\sigma^2_{\epsilon})$ for each of the models. </span>
<span id="cb80-68"><a href="#cb80-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-69"><a href="#cb80-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-70"><a href="#cb80-70" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-71"><a href="#cb80-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-72"><a href="#cb80-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-73"><a href="#cb80-73" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classical Framework of Evidence</span></span>
<span id="cb80-74"><a href="#cb80-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-75"><a href="#cb80-75" aria-hidden="true" tabindex="-1"></a>When we have looked at statistical evidence to this point, it has been from a hypothesis testing point of view. The primary piece of evidence we use in this paradigm is the *p*-value. For example, if we fit Model 1 and examine the evidence for the effect of news exposure on news knoledge, we find:</span>
<span id="cb80-76"><a href="#cb80-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-77"><a href="#cb80-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-80"><a href="#cb80-80" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-81"><a href="#cb80-81" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Model 1</span></span>
<span id="cb80-82"><a href="#cb80-82" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> news, <span class="at">data =</span> pew)</span>
<span id="cb80-83"><a href="#cb80-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-84"><a href="#cb80-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficient-level output</span></span>
<span id="cb80-85"><a href="#cb80-85" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(lm<span class="fl">.1</span>)</span>
<span id="cb80-86"><a href="#cb80-86" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-87"><a href="#cb80-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-88"><a href="#cb80-88" aria-hidden="true" tabindex="-1"></a>The *p*-value associated with the effect of news exposure ($p&lt;.001$), which suggests that the size of this effect is more than we would expect because of chance if the population effect was 0.</span>
<span id="cb80-89"><a href="#cb80-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-90"><a href="#cb80-90" aria-hidden="true" tabindex="-1"></a>Interpreting this *p*-values, we would say that the probability of seeing the empirical evidence we observed (or evidence that is more extreme) if the null hypothesis that there is no effect of news exposure on news knowledge is true, is 0.000442. This implies that our observed data are inconsistent with the hypothesized model that there is no effect of news exposure. In an applied setting, we might use such evidence to decide that the level of news exposure does indeed predict variation in American's news knowledge.</span>
<span id="cb80-91"><a href="#cb80-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-92"><a href="#cb80-92" aria-hidden="true" tabindex="-1"></a>Despite being the predominant evidential paradigm used in the education and social sciences, hypothesis testing has many criticisms <span class="co">[</span><span class="ot">e.g., @Johansson:2011; @Weakliem:2016</span><span class="co">]</span>. Among some of the stronger criticisms,</span>
<span id="cb80-93"><a href="#cb80-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-94"><a href="#cb80-94" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The *p*-value only measures evidence against the hypothesized model; not the evidence FOR a particular model.</span>
<span id="cb80-95"><a href="#cb80-95" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The model we specify in the null hypothesis is often substantively untenable (how often is the effect 0? Generally as applied scientists the reason we include predictors is because we believe there is an effect.)</span>
<span id="cb80-96"><a href="#cb80-96" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The *p*-value is based on data we haven't observed (it is based on the observed data AND evidence that is more extreme).</span>
<span id="cb80-97"><a href="#cb80-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-98"><a href="#cb80-98" aria-hidden="true" tabindex="-1"></a>If we write the *p*-value as a probability statement, it would be:</span>
<span id="cb80-99"><a href="#cb80-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-100"><a href="#cb80-100" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-101"><a href="#cb80-101" aria-hidden="true" tabindex="-1"></a>p\mbox{-}\mathrm{value} = P(\mathrm{Data~or~more~extreme~unobserved~data} \mid \mathrm{Model})</span>
<span id="cb80-102"><a href="#cb80-102" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-103"><a href="#cb80-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-104"><a href="#cb80-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-105"><a href="#cb80-105" aria-hidden="true" tabindex="-1"></a>While hypothesis tests have filled a need in the educational and social science to have some standard for evaluating statistical evidence, it is unclear whether this is the approach we should be using. As statistician David Lindley so aptly states,  "<span class="co">[</span><span class="ot">significance tests</span><span class="co">]</span> are widely used, yet are logically indefensible" <span class="co">[</span><span class="ot">comment in @Johnstone:1986, p. 502</span><span class="co">]</span>. Psychologist Jacob Cohen was more pointed, saying "<span class="co">[</span><span class="ot">hypothesis testing</span><span class="co">]</span> has not only failed to support the advance of psychology as a science but also has seriously impeded it" <span class="co">[</span><span class="ot">@Cohen:1994, p. 997</span><span class="co">]</span>.</span>
<span id="cb80-106"><a href="#cb80-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-107"><a href="#cb80-107" aria-hidden="true" tabindex="-1"></a>:::todo</span>
<span id="cb80-108"><a href="#cb80-108" aria-hidden="true" tabindex="-1"></a>"The main purpose of a significance test is to inhibit the natural enthusiasm of the investigator" <span class="co">[</span><span class="ot">@Mosteller:1954, p. 331--332</span><span class="co">]</span>.</span>
<span id="cb80-109"><a href="#cb80-109" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb80-110"><a href="#cb80-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-111"><a href="#cb80-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-112"><a href="#cb80-112" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-113"><a href="#cb80-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-114"><a href="#cb80-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-115"><a href="#cb80-115" aria-hidden="true" tabindex="-1"></a><span class="fu">## Likelihood Paradigm to Statistical Evidence</span></span>
<span id="cb80-116"><a href="#cb80-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-117"><a href="#cb80-117" aria-hidden="true" tabindex="-1"></a>In applied science, we ideally would like to collect some evidence (data) and use that to say something about how likely a particular model (or hypothesis) is based on that evidence. Symbolically we want to know,</span>
<span id="cb80-118"><a href="#cb80-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-119"><a href="#cb80-119" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-120"><a href="#cb80-120" aria-hidden="true" tabindex="-1"></a>P(\mathrm{Model} \mid \mathrm{Observed~data})</span>
<span id="cb80-121"><a href="#cb80-121" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-122"><a href="#cb80-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-123"><a href="#cb80-123" aria-hidden="true" tabindex="-1"></a>This probability is known as the *likelihood* and is very different than the probability given by the *p*-value. In the likelihood paradigm, the likelihood is the key piece of statistical evidence used to evaluate models. For example if you were comparing Model A and Model B, you could compute the likelihood for each model and compare them. Whichever model has the higher likelihood has more empirical support. This is, in a nutshell what the *Law of Likelihood* states. What is even more attractive is that another axiom, the *Likelihood Principle*, tells us that if the goal is to compare the empirical support of competing models, all of the information in the data that can be used to do so, is contained in the ratio of the model likelihoods. That is, we can't learn more about which model is more supported unless we collect additional data.</span>
<span id="cb80-124"><a href="#cb80-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-125"><a href="#cb80-125" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-126"><a href="#cb80-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-127"><a href="#cb80-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-128"><a href="#cb80-128" aria-hidden="true" tabindex="-1"></a><span class="fu">## Joint Probability Density: A Roadstop to Computing Likelihood</span></span>
<span id="cb80-129"><a href="#cb80-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-130"><a href="#cb80-130" aria-hidden="true" tabindex="-1"></a>In the preparation reading, you learned about the probability density of an observation $x_i$. Now we will extend this idea to the probability density of a set of observations, say $x_1$, $x_2$, \ldots AND $x_k$. The probability density of a set of observations is referred to as the *joint probability density*, or simply *joint density*.</span>
<span id="cb80-131"><a href="#cb80-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-132"><a href="#cb80-132" aria-hidden="true" tabindex="-1"></a>If we can make an assumption about INDEPENDENCE, then the joint probability density would be the product of the individual densities:</span>
<span id="cb80-133"><a href="#cb80-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-134"><a href="#cb80-134" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-135"><a href="#cb80-135" aria-hidden="true" tabindex="-1"></a>p(x_1, x_2, x_3, \ldots, x_k) = p(x_1) \times p(x_2) \times p(x_3) \times \ldots \times p(x_k)</span>
<span id="cb80-136"><a href="#cb80-136" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-137"><a href="#cb80-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-138"><a href="#cb80-138" aria-hidden="true" tabindex="-1"></a>Say we had three independent observations, $x =<span class="sc">\{</span>60, 65, 67<span class="sc">\}</span>$, from a $\sim\mathcal{N}(50,10)$ distribution. The joint density would be:</span>
<span id="cb80-139"><a href="#cb80-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-142"><a href="#cb80-142" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-143"><a href="#cb80-143" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute joint density</span></span>
<span id="cb80-144"><a href="#cb80-144" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="at">x =</span> <span class="dv">60</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>) <span class="sc">*</span> <span class="fu">dnorm</span>(<span class="at">x =</span> <span class="dv">65</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>) <span class="sc">*</span> <span class="fu">dnorm</span>(<span class="at">x =</span> <span class="dv">67</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb80-145"><a href="#cb80-145" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-146"><a href="#cb80-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-147"><a href="#cb80-147" aria-hidden="true" tabindex="-1"></a>We could also shortcut this computation,</span>
<span id="cb80-148"><a href="#cb80-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-151"><a href="#cb80-151" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-152"><a href="#cb80-152" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute joint density</span></span>
<span id="cb80-153"><a href="#cb80-153" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">60</span>, <span class="dv">65</span>, <span class="dv">67</span>), <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>))</span>
<span id="cb80-154"><a href="#cb80-154" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-155"><a href="#cb80-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-156"><a href="#cb80-156" aria-hidden="true" tabindex="-1"></a>This value is the joint probability density. The joint probability density indicates the probability of observing the data ($x =<span class="sc">\{</span>60, 65, 67<span class="sc">\}</span>$) GIVEN (1) they are drawn from a normal distribution and (2) the normal distribution has a mean of 50 and a standard deviation of 10. In other words, the joint probability density is the probability of the data given a model and parameters of the model.</span>
<span id="cb80-157"><a href="#cb80-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-158"><a href="#cb80-158" aria-hidden="true" tabindex="-1"></a>Symbolically,</span>
<span id="cb80-159"><a href="#cb80-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-160"><a href="#cb80-160" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-161"><a href="#cb80-161" aria-hidden="true" tabindex="-1"></a>\mathrm{Joint~Density} = P(\mathrm{Data} \mid \mathrm{Model~and~Parameters})</span>
<span id="cb80-162"><a href="#cb80-162" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-163"><a href="#cb80-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-164"><a href="#cb80-164" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-165"><a href="#cb80-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-166"><a href="#cb80-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-167"><a href="#cb80-167" aria-hidden="true" tabindex="-1"></a><span class="fu">## Computing Likelihood</span></span>
<span id="cb80-168"><a href="#cb80-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-169"><a href="#cb80-169" aria-hidden="true" tabindex="-1"></a>Likelihood is the probability of a particular set of parameters GIVEN (1) the data, and (2) the data are generated from a particular model (e.g., normal distribution). Symbolically,</span>
<span id="cb80-170"><a href="#cb80-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-171"><a href="#cb80-171" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-172"><a href="#cb80-172" aria-hidden="true" tabindex="-1"></a>\mathrm{Likelihood} = P(\mathrm{Parameters} \mid \mathrm{Model~and~Data})</span>
<span id="cb80-173"><a href="#cb80-173" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-174"><a href="#cb80-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-175"><a href="#cb80-175" aria-hidden="true" tabindex="-1"></a>Symbolically we denote likelihood with a scripted letter "L" ($\mathcal{L}$). For example, we might ask the question, given the observed data $x = <span class="sc">\{</span>30, 20, 24, 27<span class="sc">\}</span>$ come from a normal distribution, what is the likelihood (probability) that the mean is 20 and the standard deviation is 4? We might denote this as,</span>
<span id="cb80-176"><a href="#cb80-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-177"><a href="#cb80-177" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-178"><a href="#cb80-178" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\mu = 20, \sigma = 4 \mid x)</span>
<span id="cb80-179"><a href="#cb80-179" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-180"><a href="#cb80-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-181"><a href="#cb80-181" aria-hidden="true" tabindex="-1"></a>:::fyi</span>
<span id="cb80-182"><a href="#cb80-182" aria-hidden="true" tabindex="-1"></a>**FYI**</span>
<span id="cb80-183"><a href="#cb80-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-184"><a href="#cb80-184" aria-hidden="true" tabindex="-1"></a>Although we need to specify the model this is typically not included in the symbolic notation; instead it is often a part of the assumptions.</span>
<span id="cb80-185"><a href="#cb80-185" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb80-186"><a href="#cb80-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-187"><a href="#cb80-187" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-188"><a href="#cb80-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-189"><a href="#cb80-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-190"><a href="#cb80-190" aria-hidden="true" tabindex="-1"></a><span class="fu">### An Example of Computing and Evaluating Likelihood</span></span>
<span id="cb80-191"><a href="#cb80-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-192"><a href="#cb80-192" aria-hidden="true" tabindex="-1"></a>The likelihood allows us to answer probability questions about a set of parameters. For example, what is the likelihood (probability) that the data ($x = <span class="sc">\{</span>30, 20, 24, 27<span class="sc">\}</span>$) were generated from a normal distribution with a mean of 20 and standard deviation of 4? To compute the likelihood we compute the joint probability density of the data under that particular set of parameters.</span>
<span id="cb80-193"><a href="#cb80-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-196"><a href="#cb80-196" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-197"><a href="#cb80-197" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">20</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span>
<span id="cb80-198"><a href="#cb80-198" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-199"><a href="#cb80-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-200"><a href="#cb80-200" aria-hidden="true" tabindex="-1"></a>What is the likelihood (probability) that the same set of data ($x = <span class="sc">\{</span>30, 20, 24, 27<span class="sc">\}</span>$) were generated from a normal distribution with a mean of 25 and standard deviation of 4?</span>
<span id="cb80-201"><a href="#cb80-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-204"><a href="#cb80-204" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-205"><a href="#cb80-205" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">25</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span>
<span id="cb80-206"><a href="#cb80-206" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-207"><a href="#cb80-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-208"><a href="#cb80-208" aria-hidden="true" tabindex="-1"></a>Given the data and the model, there is more empirical support that the parameters are $\mathcal{N}(25,4^2)$ rather than $\mathcal{N}(20, 4^2)$, because the likelihood is higher for the former set of parameters. We can compute a ratio of the two likelihoods to quantify the amount of additional support for the $\mathcal{N}(25,4^2)$.</span>
<span id="cb80-209"><a href="#cb80-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-210"><a href="#cb80-210" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-211"><a href="#cb80-211" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-212"><a href="#cb80-212" aria-hidden="true" tabindex="-1"></a>\mathrm{Likelihood~Ratio} &amp;= \frac{0.00001774012}{0.0000005702554} <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-213"><a href="#cb80-213" aria-hidden="true" tabindex="-1"></a>&amp;= 31.11</span>
<span id="cb80-214"><a href="#cb80-214" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-215"><a href="#cb80-215" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-216"><a href="#cb80-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-217"><a href="#cb80-217" aria-hidden="true" tabindex="-1"></a>The empirical support for the $\mathcal{N}(25,4^2)$ parameterization is 31 times that of the $\mathcal{N}(20, 4^2)$ parameterization! In a practical setting, this would lead us to adopt a mean of 25 over a mean of 20.</span>
<span id="cb80-218"><a href="#cb80-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-219"><a href="#cb80-219" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-220"><a href="#cb80-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-221"><a href="#cb80-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-222"><a href="#cb80-222" aria-hidden="true" tabindex="-1"></a><span class="fu">## Some Notes and Caveats</span></span>
<span id="cb80-223"><a href="#cb80-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-224"><a href="#cb80-224" aria-hidden="true" tabindex="-1"></a>It is important to note that although we use the joint probability under a set of parameters to compute the likelihood of those parameters, theoretically joint density and likelihood are very different. Likelihood takes the data and model as given and computes the probability of a set of parameters. Whereas joint density assumes that the model and parameters are given and gives us the probability of the data.</span>
<span id="cb80-225"><a href="#cb80-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-226"><a href="#cb80-226" aria-hidden="true" tabindex="-1"></a>:::fyi</span>
<span id="cb80-227"><a href="#cb80-227" aria-hidden="true" tabindex="-1"></a>**FYI**</span>
<span id="cb80-228"><a href="#cb80-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-229"><a href="#cb80-229" aria-hidden="true" tabindex="-1"></a>Likelihood refers to the probability of the parameters and joint probability density refers to the probability of the data.</span>
<span id="cb80-230"><a href="#cb80-230" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb80-231"><a href="#cb80-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-232"><a href="#cb80-232" aria-hidden="true" tabindex="-1"></a>Once we collect the data, the probability of observing that set of data is 1; it is no longer unknown. The likelihood method treats our data as known and offers us a way of making probabilistic statements about the unknown parameters. This is more aligned with our scientific process than making some assumption about the parameter (e.g., $\beta_1=0$) and then trying to determine the probability of the data under that assumption. Moreover, likelihood does not use unobserved data (e.g., data more extreme than what we observed) in the computation.</span>
<span id="cb80-233"><a href="#cb80-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-234"><a href="#cb80-234" aria-hidden="true" tabindex="-1"></a>It is also important to acknowledge what likelihood and the likelihood ratio don't tell us. First, they only tell us the probability of a set of parameters for the data we have. Future collections of data might change the amount of support or which set of parameters is supported. Since changing the data, changes the likelihood, this also means we cannot make cross study comparisons of the likelihood (unless the studies used the exact same data). Secondly, the model assumed is important. If a different model is assumed, the likelihood will be different, and again could change the amount of support or which set of parameters is supported.</span>
<span id="cb80-235"><a href="#cb80-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-236"><a href="#cb80-236" aria-hidden="true" tabindex="-1"></a>The likelihood ratio (LR), while useful for comparing the relative support between parameterizations, does not tell you that a particular parameterization is correct. For example, the LR of 31.11 tells us that there is more empirical support for the $\mathcal{N}(25,4^2)$ parameterization than $\mathcal{N}(20, 4^2)$. But, there might be even more support for a parameterization we haven't considered.</span>
<span id="cb80-237"><a href="#cb80-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-238"><a href="#cb80-238" aria-hidden="true" tabindex="-1"></a>These shortcomings are not unique to the likelihood paradigm The also exist in the classical hypothesis testing paradigm for statistical evidence. All in all, the added advantages to the likelihood paradigm make it more useful to applied work than hypothesis testing.</span>
<span id="cb80-239"><a href="#cb80-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-240"><a href="#cb80-240" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-241"><a href="#cb80-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-242"><a href="#cb80-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-243"><a href="#cb80-243" aria-hidden="true" tabindex="-1"></a><span class="fu">## Likelihood in Regression: Back to Our Example</span></span>
<span id="cb80-244"><a href="#cb80-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-245"><a href="#cb80-245" aria-hidden="true" tabindex="-1"></a>When fitting a regression model, we make certain assumptions about the relationship between a set of predictors and the outcome. For example, in Model 1 from our earlier example, we assume that the relationship between news exposure and news knowledge can be described by the following model:</span>
<span id="cb80-246"><a href="#cb80-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-247"><a href="#cb80-247" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-248"><a href="#cb80-248" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-249"><a href="#cb80-249" aria-hidden="true" tabindex="-1"></a>\mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{News~Exposure}_i) + \epsilon_i <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-250"><a href="#cb80-250" aria-hidden="true" tabindex="-1"></a>&amp;\mathrm{where~}\epsilon_i \overset{i.i.d.}{\sim}\mathcal{N}(0,\sigma^2_{\epsilon})</span>
<span id="cb80-251"><a href="#cb80-251" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-252"><a href="#cb80-252" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-253"><a href="#cb80-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-254"><a href="#cb80-254" aria-hidden="true" tabindex="-1"></a>Here we use OLS to estimate the regression coefficients. Then we can use those, along with the observed data to obtain the residuals and the estimate for the residual standard error. The residuals are the GIVEN data and the set up distributional assumptions for the model (e.g., normal, mean of 0, constant variance) allow us to compute the likelihood for the entire set of parameters in this model ($\beta_0$, $\beta_1$, $\sigma^2_{\epsilon}$).</span>
<span id="cb80-255"><a href="#cb80-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-256"><a href="#cb80-256" aria-hidden="true" tabindex="-1"></a>Below is a set of syntax to compute the likelihood, based on fitting <span class="in">`lm.1`</span>. We use the <span class="in">`resid()`</span> function to compute the residuals. (It is the same as grabbing the column called <span class="in">`.resid`</span> from the <span class="in">`augment()`</span> output.) We also use the estimated value of the residual standard error ($\hat{\sigma}_{\epsilon} = 20.3$) from the <span class="in">`glance()`</span> output.</span>
<span id="cb80-257"><a href="#cb80-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-260"><a href="#cb80-260" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-261"><a href="#cb80-261" aria-hidden="true" tabindex="-1"></a><span class="co"># Get RSE for use in likelihood</span></span>
<span id="cb80-262"><a href="#cb80-262" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(lm<span class="fl">.1</span>)</span>
<span id="cb80-263"><a href="#cb80-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-264"><a href="#cb80-264" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for lm.1</span></span>
<span id="cb80-265"><a href="#cb80-265" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">resid</span>(lm<span class="fl">.1</span>), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">20.3</span>))</span>
<span id="cb80-266"><a href="#cb80-266" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-267"><a href="#cb80-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-268"><a href="#cb80-268" aria-hidden="true" tabindex="-1"></a>This value by itself is somewhat meaningless. It is only worthwhile when we compare it to the likelihood from another model. For example, let's compute the likelihood for an intercept-only model (Model 0) and compare this to the likelihood for <span class="in">`lm.1`</span>. </span>
<span id="cb80-269"><a href="#cb80-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-272"><a href="#cb80-272" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-273"><a href="#cb80-273" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Model 0</span></span>
<span id="cb80-274"><a href="#cb80-274" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.0</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> pew)</span>
<span id="cb80-275"><a href="#cb80-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-276"><a href="#cb80-276" aria-hidden="true" tabindex="-1"></a><span class="co"># Get RSE for use in likelihood</span></span>
<span id="cb80-277"><a href="#cb80-277" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(lm<span class="fl">.0</span>)</span>
<span id="cb80-278"><a href="#cb80-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-279"><a href="#cb80-279" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for lm.2</span></span>
<span id="cb80-280"><a href="#cb80-280" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">resid</span>(lm<span class="fl">.0</span>), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">21.5</span>))</span>
<span id="cb80-281"><a href="#cb80-281" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-282"><a href="#cb80-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-283"><a href="#cb80-283" aria-hidden="true" tabindex="-1"></a>The likelihood value for <span class="in">`lm.1`</span> is higher than the likelihood value for <span class="in">`lm.0`</span>. Computing the likelihood ratio:</span>
<span id="cb80-284"><a href="#cb80-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-287"><a href="#cb80-287" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-288"><a href="#cb80-288" aria-hidden="true" tabindex="-1"></a><span class="fl">1.382925e-192</span> <span class="sc">/</span> <span class="fl">2.489266e-195</span></span>
<span id="cb80-289"><a href="#cb80-289" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-290"><a href="#cb80-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-291"><a href="#cb80-291" aria-hidden="true" tabindex="-1"></a>This suggests that given the data, Model 1 is 555.6 times more likely than Model 0. In practice, we would adopt Model 1 over Model 0 because it is more likely given the empirical evidence (data) we have.</span>
<span id="cb80-292"><a href="#cb80-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-293"><a href="#cb80-293" aria-hidden="true" tabindex="-1"></a>:::mathnote</span>
<span id="cb80-294"><a href="#cb80-294" aria-hidden="true" tabindex="-1"></a><span class="fu">### Mathematics of Likelihood</span></span>
<span id="cb80-295"><a href="#cb80-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-296"><a href="#cb80-296" aria-hidden="true" tabindex="-1"></a>Being able to express the likelihood mathematically is important for quantitative methodologists as it allows us to manipulate and study the likelihood function and its properties. It also gives us insight into how the individual components of the likelihood affect its value.</span>
<span id="cb80-297"><a href="#cb80-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-298"><a href="#cb80-298" aria-hidden="true" tabindex="-1"></a>Remember, we can express the likelihood of the regression residuals mathematically as:</span>
<span id="cb80-299"><a href="#cb80-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-300"><a href="#cb80-300" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-301"><a href="#cb80-301" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) = p(\epsilon_1) \times p(\epsilon_2) \times \ldots \times p(\epsilon_n)</span>
<span id="cb80-302"><a href="#cb80-302" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-303"><a href="#cb80-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-304"><a href="#cb80-304" aria-hidden="true" tabindex="-1"></a>where the probability density of each residual (assuming normality) is:</span>
<span id="cb80-305"><a href="#cb80-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-306"><a href="#cb80-306" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-307"><a href="#cb80-307" aria-hidden="true" tabindex="-1"></a>p(\epsilon_i) = \frac{1}{\sigma\sqrt{2\pi}}\exp\left<span class="co">[</span><span class="ot">-\frac{(\epsilon_i-\mu)^2}{2\sigma^2}\right</span><span class="co">]</span></span>
<span id="cb80-308"><a href="#cb80-308" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-309"><a href="#cb80-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-310"><a href="#cb80-310" aria-hidden="true" tabindex="-1"></a>In addition to normality, which gives us the equation to compute the PDF for each residual, the regression assumptions also specify that each conditional error distribution has a mean of 0 and some variance (that is the same for all conditional error distributions). We can call it $\sigma^2_{\epsilon}$. Substituting these values into the density function, we get,</span>
<span id="cb80-311"><a href="#cb80-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-312"><a href="#cb80-312" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-313"><a href="#cb80-313" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-314"><a href="#cb80-314" aria-hidden="true" tabindex="-1"></a>p(\epsilon_i) &amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left<span class="co">[</span><span class="ot">-\frac{(\epsilon_i-0)^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb80-315"><a href="#cb80-315" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left<span class="co">[</span><span class="ot">-\frac{(\epsilon_i)^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span></span>
<span id="cb80-316"><a href="#cb80-316" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-317"><a href="#cb80-317" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-318"><a href="#cb80-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-319"><a href="#cb80-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-320"><a href="#cb80-320" aria-hidden="true" tabindex="-1"></a>Now we use this expression for each of the $p(\epsilon_i)$ values in the likelihood computation.</span>
<span id="cb80-321"><a href="#cb80-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-322"><a href="#cb80-322" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-323"><a href="#cb80-323" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-324"><a href="#cb80-324" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) &amp;= p(\epsilon_1) \times p(\epsilon_2) \times \ldots \times p(\epsilon_n) <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb80-325"><a href="#cb80-325" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_1</span>
<span id="cb80-326"><a href="#cb80-326" aria-hidden="true" tabindex="-1"></a>^2}{2\sigma^2_{\epsilon}}\right] \times \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \times <span class="sc">\\</span></span>
<span id="cb80-327"><a href="#cb80-327" aria-hidden="true" tabindex="-1"></a>&amp;~~~~~~\ldots \times \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span></span>
<span id="cb80-328"><a href="#cb80-328" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-329"><a href="#cb80-329" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-330"><a href="#cb80-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-331"><a href="#cb80-331" aria-hidden="true" tabindex="-1"></a>We can simplify this:</span>
<span id="cb80-332"><a href="#cb80-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-333"><a href="#cb80-333" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-334"><a href="#cb80-334" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-335"><a href="#cb80-335" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) &amp;=\left<span class="co">[</span><span class="ot"> \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right</span><span class="co">]</span>^n \times \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_1^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \times \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \times \ldots <span class="sc">\\</span></span>
<span id="cb80-336"><a href="#cb80-336" aria-hidden="true" tabindex="-1"></a>&amp;~~~~~~ \times \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span></span>
<span id="cb80-337"><a href="#cb80-337" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-338"><a href="#cb80-338" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-339"><a href="#cb80-339" aria-hidden="true" tabindex="-1"></a>We can also simplify this by using the product notation:</span>
<span id="cb80-340"><a href="#cb80-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-341"><a href="#cb80-341" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-342"><a href="#cb80-342" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) =\left<span class="co">[</span><span class="ot"> \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right</span><span class="co">]</span>^n \times \prod_{i=1}^n \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_i^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span></span>
<span id="cb80-343"><a href="#cb80-343" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-344"><a href="#cb80-344" aria-hidden="true" tabindex="-1"></a>We can also write the residuals ($\epsilon_i$) as a function of the regression parameters we are  trying to find the likelihood for.</span>
<span id="cb80-345"><a href="#cb80-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-346"><a href="#cb80-346" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-347"><a href="#cb80-347" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) =\left<span class="co">[</span><span class="ot"> \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right</span><span class="co">]</span>^n \times \prod_{i=1}^n \exp\left<span class="co">[</span><span class="ot">-\frac{\big[Y_i - \beta_0 - \beta_1(X_i)\big]^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span></span>
<span id="cb80-348"><a href="#cb80-348" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-349"><a href="#cb80-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-350"><a href="#cb80-350" aria-hidden="true" tabindex="-1"></a>where $\sigma^2_{\epsilon} = \frac{\sum \epsilon_i^2}{n}$. Because the numerator of $\sigma^2_{\epsilon}$ can be written as $\sum_i^n\big(Y_i - \beta_0 - \beta_1(X_i)\big)^2$, we see that the likelihood is a function of $n$, and the regression coefficients, $\beta_0$ and $\beta_1$. Moreover, $n$ is based on the data (which is given) and is thus is a constant. Mathematically, this implies that the only variables (values that can vary) in the likelihood function are the regression coefficients.</span>
<span id="cb80-351"><a href="#cb80-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-352"><a href="#cb80-352" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb80-353"><a href="#cb80-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-354"><a href="#cb80-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-355"><a href="#cb80-355" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-356"><a href="#cb80-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-357"><a href="#cb80-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-358"><a href="#cb80-358" aria-hidden="true" tabindex="-1"></a><span class="fu">## Log-Likelihood</span></span>
<span id="cb80-359"><a href="#cb80-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-360"><a href="#cb80-360" aria-hidden="true" tabindex="-1"></a>The likelihood values are quite small since we are multiplying several probability densities (values between 0 and 1) together. Since it is hard to work with these smaller values, in practice, we often compute and work with the natural logarithm of the likelihood. So in our example, Model 0 ($\mathcal{L}_0 = 2.489266 \times 10^{-195}$) has a log-likelihood of:</span>
<span id="cb80-361"><a href="#cb80-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-364"><a href="#cb80-364" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-365"><a href="#cb80-365" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-likelihood for Model 0</span></span>
<span id="cb80-366"><a href="#cb80-366" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fl">2.489266e-195</span>)</span>
<span id="cb80-367"><a href="#cb80-367" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-368"><a href="#cb80-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-369"><a href="#cb80-369" aria-hidden="true" tabindex="-1"></a>Similarly, we can compute the log-likelihood for Model 1 as:</span>
<span id="cb80-370"><a href="#cb80-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-373"><a href="#cb80-373" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-374"><a href="#cb80-374" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-likelihood for Model 1</span></span>
<span id="cb80-375"><a href="#cb80-375" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fl">1.382925e-192</span>)</span>
<span id="cb80-376"><a href="#cb80-376" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-377"><a href="#cb80-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-378"><a href="#cb80-378" aria-hidden="true" tabindex="-1"></a>We typically denote log-likelihood using a scripted lower-case "l" ($\mathcal{l}$). Here,</span>
<span id="cb80-379"><a href="#cb80-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-380"><a href="#cb80-380" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-381"><a href="#cb80-381" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-382"><a href="#cb80-382" aria-hidden="true" tabindex="-1"></a>\mathcal{l}_0 &amp;= -448.0921 <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-383"><a href="#cb80-383" aria-hidden="true" tabindex="-1"></a>\mathcal{l}_1 &amp;= -441.7721 <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-384"><a href="#cb80-384" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-385"><a href="#cb80-385" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-386"><a href="#cb80-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-387"><a href="#cb80-387" aria-hidden="true" tabindex="-1"></a>Note that the logarithm of a decimal will be negative, so the log-likelihood will be a negative value. Less negative log-likelihood values correspond to higher likelihood values, which indicate more empirical support. Here Model 1 has a log-likelihood value ($-441.8$) that is less negative than Model 0's log-likelihood value ($-448.1$), which indicates there is more empirical support for Model 1 than Model 0.</span>
<span id="cb80-388"><a href="#cb80-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-389"><a href="#cb80-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-390"><a href="#cb80-390" aria-hidden="true" tabindex="-1"></a>:::fyi</span>
<span id="cb80-391"><a href="#cb80-391" aria-hidden="true" tabindex="-1"></a>**FYI**</span>
<span id="cb80-392"><a href="#cb80-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-393"><a href="#cb80-393" aria-hidden="true" tabindex="-1"></a>While it is possible using algebra to express the likelihood ratio using log-likelihoods, it does not have the same interpretational value as the LR does. Because of this, the likelihood ratio is not often expresseds using log-likelihoods.</span>
<span id="cb80-394"><a href="#cb80-394" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb80-395"><a href="#cb80-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-396"><a href="#cb80-396" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- We can also express the likelihood ratio using log-likelihoods. To do so we take the natural logarithm of the likelihood ratio. We also re-write it using the rules of logarithms (from algebra). --&gt;</span></span>
<span id="cb80-397"><a href="#cb80-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-398"><a href="#cb80-398" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb80-399"><a href="#cb80-399" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{split} --&gt;</span></span>
<span id="cb80-400"><a href="#cb80-400" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \ln(\mathrm{LR}) &amp;= \ln \bigg(\frac{\mathcal{L}_2}{\mathcal{L}_1}\bigg) \\[2ex] --&gt;</span></span>
<span id="cb80-401"><a href="#cb80-401" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &amp;= \ln \big(\mathcal{L}_2\big) - \ln \big(\mathcal{L}_1\big) --&gt;</span></span>
<span id="cb80-402"><a href="#cb80-402" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{split} --&gt;</span></span>
<span id="cb80-403"><a href="#cb80-403" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb80-404"><a href="#cb80-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-405"><a href="#cb80-405" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- That is, we can find an equivalent relative support metric to the LR based on the log-likelihoods by computing the difference between them. For our example: --&gt;</span></span>
<span id="cb80-406"><a href="#cb80-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-407"><a href="#cb80-407" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb80-408"><a href="#cb80-408" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Difference in log-likelihoods --&gt;</span></span>
<span id="cb80-409"><a href="#cb80-409" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- log(2.910762e-196) - log(2.089334e-199) --&gt;</span></span>
<span id="cb80-410"><a href="#cb80-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-411"><a href="#cb80-411" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Equivalent to ln(LR) --&gt;</span></span>
<span id="cb80-412"><a href="#cb80-412" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- log(2.910762e-196 / 2.089334e-199) --&gt;</span></span>
<span id="cb80-413"><a href="#cb80-413" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb80-414"><a href="#cb80-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-415"><a href="#cb80-415" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Unfortunately, this difference doesn't have the same interpretational value as the LR does, bcause this difference is in log-units. In order to get that interpretation back, we need to exponentiate (the reverse function of the logarithm) the difference: --&gt;</span></span>
<span id="cb80-416"><a href="#cb80-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-417"><a href="#cb80-417" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb80-418"><a href="#cb80-418" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Exponentiate the difference in log-likelihoods --&gt;</span></span>
<span id="cb80-419"><a href="#cb80-419" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- exp(7.239325) --&gt;</span></span>
<span id="cb80-420"><a href="#cb80-420" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb80-421"><a href="#cb80-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-422"><a href="#cb80-422" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Again, Model 1 has 308244.9 times the empirical support than Model 0. --&gt;</span></span>
<span id="cb80-423"><a href="#cb80-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-424"><a href="#cb80-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-425"><a href="#cb80-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-426"><a href="#cb80-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-427"><a href="#cb80-427" aria-hidden="true" tabindex="-1"></a>:::mathnote</span>
<span id="cb80-428"><a href="#cb80-428" aria-hidden="true" tabindex="-1"></a><span class="fu">### Mathematics of Log-Likelihood</span></span>
<span id="cb80-429"><a href="#cb80-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-430"><a href="#cb80-430" aria-hidden="true" tabindex="-1"></a>We can express the log-likelihood of the regression residuals mathematically by taking the natural logarithm of the likelihood we computed earlier:</span>
<span id="cb80-431"><a href="#cb80-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-432"><a href="#cb80-432" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-433"><a href="#cb80-433" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-434"><a href="#cb80-434" aria-hidden="true" tabindex="-1"></a>\ln \Bigl(\mathcal{L}(\beta_0, \beta_1 | \mathrm{data})\Bigr) &amp;= \ln \Biggl( \left<span class="co">[</span><span class="ot"> \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right</span><span class="co">]</span>^n \times \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_1^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \times  <span class="sc">\\</span></span>
<span id="cb80-435"><a href="#cb80-435" aria-hidden="true" tabindex="-1"></a>&amp;~~~~~~ \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \times \ldots \times \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \Biggr) <span class="sc">\\</span></span>
<span id="cb80-436"><a href="#cb80-436" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-437"><a href="#cb80-437" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-438"><a href="#cb80-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-439"><a href="#cb80-439" aria-hidden="true" tabindex="-1"></a>Using our rules for logarithms and re-arranging gives,</span>
<span id="cb80-440"><a href="#cb80-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-441"><a href="#cb80-441" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-442"><a href="#cb80-442" aria-hidden="true" tabindex="-1"></a>\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = -\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \epsilon_i^2</span>
<span id="cb80-443"><a href="#cb80-443" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-444"><a href="#cb80-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-445"><a href="#cb80-445" aria-hidden="true" tabindex="-1"></a>Examining this equation, we see that the log-likelihood is a function of $n$, $\sigma^2_{\epsilon}$ and the sum of squared residuals (SSR)^<span class="co">[</span><span class="ot">Sometimes this is also referred to a the sum of squared errors (SSE).</span><span class="co">]</span>. We can of course, re-express this using the the regression parameters:</span>
<span id="cb80-446"><a href="#cb80-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-447"><a href="#cb80-447" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-448"><a href="#cb80-448" aria-hidden="true" tabindex="-1"></a>\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = -\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \big<span class="co">[</span><span class="ot">Y_i - \beta_0 - \beta_1(X_i)\big</span><span class="co">]</span>^2</span>
<span id="cb80-449"><a href="#cb80-449" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-450"><a href="#cb80-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-451"><a href="#cb80-451" aria-hidden="true" tabindex="-1"></a>And, again, since $\sigma^2_{\epsilon}$ is a function of the regression coefficients and $n$, this means that the only variables in the log-likelihood function are the coefficients.</span>
<span id="cb80-452"><a href="#cb80-452" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb80-453"><a href="#cb80-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-454"><a href="#cb80-454" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-455"><a href="#cb80-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-456"><a href="#cb80-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-457"><a href="#cb80-457" aria-hidden="true" tabindex="-1"></a><span class="fu">### Shortcut: The `logLik()` Function</span></span>
<span id="cb80-458"><a href="#cb80-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-459"><a href="#cb80-459" aria-hidden="true" tabindex="-1"></a>The <span class="in">`logLik()`</span> function can be used to obtain the log-likelihood directly from a fitted model object. For example, to find the log-likelihood for Model 1, we can use:</span>
<span id="cb80-460"><a href="#cb80-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-463"><a href="#cb80-463" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-464"><a href="#cb80-464" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-likelihood for Model 1</span></span>
<span id="cb80-465"><a href="#cb80-465" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(lm<span class="fl">.1</span>)</span>
<span id="cb80-466"><a href="#cb80-466" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-467"><a href="#cb80-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-468"><a href="#cb80-468" aria-hidden="true" tabindex="-1"></a>The <span class="in">`df`</span> output tells us how many **total parameters** are being estimated in the model. In our case the number of total parameters in Model 0 is three ($\beta_0$, $\beta_{\mathrm{News~Exposure}}$, and $\sigma^2_{\epsilon}$). What is more important to us currently, is the log-likelihood value; $\mathcal{l}_1=-450.2233$.</span>
<span id="cb80-469"><a href="#cb80-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-470"><a href="#cb80-470" aria-hidden="true" tabindex="-1"></a>This value is slightly different than the log-likelihood we just computed of $-441.7721$. This is not because of rounding in this case. It has to do with how the model is being estimated; the <span class="in">`logLik()`</span> function assumes the parameters are being estimated using maximum likelihood (ML) rather than ordinary least squares (OLS). You can learn more about ML estimation in the optional set of notes, but for now, we will just use <span class="in">`logLik()`</span> to compute the log-likelihood.</span>
<span id="cb80-471"><a href="#cb80-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-472"><a href="#cb80-472" aria-hidden="true" tabindex="-1"></a>Here we compute the log-likelihood for Model 0 using the <span class="in">`logLik()`</span> function. We also use the output to compute the likelihood for Model 0. To compute the likelihood from the log-likelihood we need to exponentiate (the reverse function of the logarithm) the the log-likelihood value using the <span class="in">`exp()`</span> function. We also compute the log-likelihood and likelihood value for Model 1. </span>
<span id="cb80-473"><a href="#cb80-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-476"><a href="#cb80-476" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-477"><a href="#cb80-477" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-likelihood for Model 0</span></span>
<span id="cb80-478"><a href="#cb80-478" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(lm<span class="fl">.0</span>)</span>
<span id="cb80-479"><a href="#cb80-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-480"><a href="#cb80-480" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for Model 0</span></span>
<span id="cb80-481"><a href="#cb80-481" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">logLik</span>(lm<span class="fl">.0</span>)[<span class="dv">1</span>])</span>
<span id="cb80-482"><a href="#cb80-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-483"><a href="#cb80-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-484"><a href="#cb80-484" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-likelihood for Model 1</span></span>
<span id="cb80-485"><a href="#cb80-485" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(lm<span class="fl">.1</span>)</span>
<span id="cb80-486"><a href="#cb80-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-487"><a href="#cb80-487" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for Model 1</span></span>
<span id="cb80-488"><a href="#cb80-488" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">logLik</span>(lm<span class="fl">.1</span>)[<span class="dv">1</span>])</span>
<span id="cb80-489"><a href="#cb80-489" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-490"><a href="#cb80-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-491"><a href="#cb80-491" aria-hidden="true" tabindex="-1"></a>Because the output from <span class="in">`logLik()`</span> includes extraneous information (e.g., <span class="in">`df`</span>), we use indexing (square brackets) to extract only the part of the output we want. In this case, the <span class="in">`[1]`</span> extracts the log-likelihood value from the <span class="in">`logLik()`</span> output (ignoring the <span class="in">`df`</span> part).</span>
<span id="cb80-492"><a href="#cb80-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-493"><a href="#cb80-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-494"><a href="#cb80-494" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-495"><a href="#cb80-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-496"><a href="#cb80-496" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model Complexity</span></span>
<span id="cb80-497"><a href="#cb80-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-498"><a href="#cb80-498" aria-hidden="true" tabindex="-1"></a>One aspect that we need to consider is that more complex models tend to have higher likelihoods and log-likelihoods. Therefore when we compare likelihoods (or log-likelihoods) we need to consider the complexity in addition to the likelihoods. One way to quantify a model's complexity is to consider the number of parameters that are being estimated. The more parameters that we need to estimate, the more complex the model. Recall that the number of parameters for a model are given in the <span class="in">`df`</span> value from the <span class="in">`logLik()`</span> function's output.</span>
<span id="cb80-499"><a href="#cb80-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-500"><a href="#cb80-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-501"><a href="#cb80-501" aria-hidden="true" tabindex="-1"></a>In our example, the <span class="in">`df`</span> value for Model 0 is two, indicating that this model is estimating two parameters ($\beta_0$, and $\sigma^2_{\epsilon}$). For Model 1, the <span class="in">`df`</span> value was three. This indicates that Model 1 is more complex than Model 0.</span>
<span id="cb80-502"><a href="#cb80-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-503"><a href="#cb80-503" aria-hidden="true" tabindex="-1"></a>As we consider using the likelihood ratio (LR) or the difference in log-likelihoods for model selection, we also need to consider the model complexity. In our example, the likelihood ratio of 555.6 indicates that Model 1 has approximately 555.6 times the empirical support than Model 0. But, Model 1 is more complex than Model 0, so we would expect that it would be more empirically supported.</span>
<span id="cb80-504"><a href="#cb80-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-505"><a href="#cb80-505" aria-hidden="true" tabindex="-1"></a>In this case, with a likelihood ratio of 555.6, it seems like the empirical data certainly support adopting Model 1 over Model 0. despite the added complexity of Model 1. But what if the LR was 10? Would that be enough additional support to warrant adopting Model 1 over Model 0? What about a LR of 5? </span>
<span id="cb80-506"><a href="#cb80-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-507"><a href="#cb80-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-508"><a href="#cb80-508" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-509"><a href="#cb80-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-510"><a href="#cb80-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-511"><a href="#cb80-511" aria-hidden="true" tabindex="-1"></a><span class="fu">## Likelihood Ratio Test for Nested Models</span></span>
<span id="cb80-512"><a href="#cb80-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-513"><a href="#cb80-513" aria-hidden="true" tabindex="-1"></a>One key question that arises is, if the likelihood for a more complex model is higher than the likelihood for a simpler model, how large does the likelihood ratio have to be before we adopt the more complex model? In general, there is no perfect answer for this.</span>
<span id="cb80-514"><a href="#cb80-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-515"><a href="#cb80-515" aria-hidden="true" tabindex="-1"></a>If the models being compared are nested, then we can carry out a hypothesis test^<span class="co">[</span><span class="ot">This is in some sense mixing the paradigms of likelihood-based evidence and classical hypothesis test-based evidence. In a future set of notes we will learn about information criteria which eliminate the need to mix these two paradigms.</span><span class="co">]</span> to see if the LR is more than we would expect because of chance. Models are nested when the parameters in the simpler model are a subset of the parameters in the more complex model. For example, in our example, the parameters in Model 0 are a subset of the parameters in Model 1:</span>
<span id="cb80-516"><a href="#cb80-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-517"><a href="#cb80-517" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-518"><a href="#cb80-518" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-519"><a href="#cb80-519" aria-hidden="true" tabindex="-1"></a>\mathbf{Model~1~Parameters:}&amp;\quad<span class="sc">\{</span>\beta_0,~\beta_{\mathrm{News~Exposure}},~\sigma^2_{\epsilon}<span class="sc">\}</span> <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-520"><a href="#cb80-520" aria-hidden="true" tabindex="-1"></a>\mathbf{Model~0~Parameters:}&amp;\quad<span class="sc">\{</span>\beta_0,~\sigma^2_{\epsilon}<span class="sc">\}</span> <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-521"><a href="#cb80-521" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-522"><a href="#cb80-522" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-523"><a href="#cb80-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-524"><a href="#cb80-524" aria-hidden="true" tabindex="-1"></a>The parameters for Model 0 all appear in the list of parameters for Model 1. Because of this we can say that Model 0 is *nested* in Model 1.</span>
<span id="cb80-525"><a href="#cb80-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-526"><a href="#cb80-526" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-527"><a href="#cb80-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-528"><a href="#cb80-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-529"><a href="#cb80-529" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hypothesis Test of the LRT</span></span>
<span id="cb80-530"><a href="#cb80-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-531"><a href="#cb80-531" aria-hidden="true" tabindex="-1"></a>When we have nested models we can carry out a hypothesis test to decide between the following competing hypotheses:</span>
<span id="cb80-532"><a href="#cb80-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-533"><a href="#cb80-533" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-534"><a href="#cb80-534" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-535"><a href="#cb80-535" aria-hidden="true" tabindex="-1"></a>H_0:&amp; ~\theta_0 = <span class="sc">\{</span>\beta_0,~\sigma^2_{\epsilon}<span class="sc">\}\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-536"><a href="#cb80-536" aria-hidden="true" tabindex="-1"></a>H_A:&amp; \theta_1 = <span class="sc">\{</span>\beta_0,~\beta_{\mathrm{News~Exposure}},~\sigma^2_{\epsilon}<span class="sc">\}</span></span>
<span id="cb80-537"><a href="#cb80-537" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-538"><a href="#cb80-538" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-539"><a href="#cb80-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-540"><a href="#cb80-540" aria-hidden="true" tabindex="-1"></a>where $\theta_0$ refers to the simpler model and $\theta_1$ refers to the more complex model. This translates to adopting either the simpler model (fail to reject $H_0$) or the more complex model (reject $H_0$). To carry out this test, we translate our likelihood ratio to a test statistic called $\chi^2$ (pronounced chi-squared):</span>
<span id="cb80-541"><a href="#cb80-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-542"><a href="#cb80-542" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-543"><a href="#cb80-543" aria-hidden="true" tabindex="-1"></a>\chi^2 = -2 \ln \bigg(\frac{\mathcal{L}({\theta_0})}{\mathcal{L}({\theta_1})}\bigg)</span>
<span id="cb80-544"><a href="#cb80-544" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-545"><a href="#cb80-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-546"><a href="#cb80-546" aria-hidden="true" tabindex="-1"></a>That is we compute $-2$ times the log of the likelihood ratio where the likelihood for the simpler model is in the numerator. (Note this is the inverse of how we have been computing the likelihood ratio!) Equivalently, we can compute this as:</span>
<span id="cb80-547"><a href="#cb80-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-548"><a href="#cb80-548" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-549"><a href="#cb80-549" aria-hidden="true" tabindex="-1"></a>\chi^2 = -2 \bigg(\ln \bigg<span class="co">[</span><span class="ot">\mathcal{L}({\theta_0})\bigg</span><span class="co">]</span> - \ln \bigg<span class="co">[</span><span class="ot">\mathcal{L}({\theta_1})\bigg</span><span class="co">]</span>\bigg)</span>
<span id="cb80-550"><a href="#cb80-550" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-551"><a href="#cb80-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-552"><a href="#cb80-552" aria-hidden="true" tabindex="-1"></a>For our example, we compute this using the following syntax:</span>
<span id="cb80-553"><a href="#cb80-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-556"><a href="#cb80-556" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-557"><a href="#cb80-557" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute chi-squared</span></span>
<span id="cb80-558"><a href="#cb80-558" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> (<span class="fu">logLik</span>(lm<span class="fl">.0</span>)[<span class="dv">1</span>] <span class="sc">-</span> <span class="fu">logLik</span>(lm<span class="fl">.1</span>)[<span class="dv">1</span>])</span>
<span id="cb80-559"><a href="#cb80-559" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-560"><a href="#cb80-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-561"><a href="#cb80-561" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-562"><a href="#cb80-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-563"><a href="#cb80-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-564"><a href="#cb80-564" aria-hidden="true" tabindex="-1"></a><span class="fu">## Deviance: A Measure of the Model--Data Error</span></span>
<span id="cb80-565"><a href="#cb80-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-566"><a href="#cb80-566" aria-hidden="true" tabindex="-1"></a>If we re-write the formula for the $\chi^2$-statistic by distributing the $-2$, we get a better glimpse of what this statistic is measuring.</span>
<span id="cb80-567"><a href="#cb80-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-568"><a href="#cb80-568" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-569"><a href="#cb80-569" aria-hidden="true" tabindex="-1"></a>\chi^2 = -2 \ln \bigg<span class="co">[</span><span class="ot">\mathcal{L}({\theta_0})\bigg</span><span class="co">]</span> - \bigg(-2\ln \bigg<span class="co">[</span><span class="ot">\mathcal{L}({\theta_1})\bigg</span><span class="co">]</span>\bigg)</span>
<span id="cb80-570"><a href="#cb80-570" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-571"><a href="#cb80-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-572"><a href="#cb80-572" aria-hidden="true" tabindex="-1"></a>The quantity $-2\ln\big<span class="co">[</span><span class="ot">\mathcal{L}(\theta_k)\big</span><span class="co">]</span>$ is referred to as the *residual deviance*^<span class="co">[</span><span class="ot">The use of the term "residual deviance" is not universal. Some textbooks omit the "residual" part and just refer to it as the "deviance". Others use the term "model deviance".</span><span class="co">]</span> of Model K. It measures the amount of misfit between the model and the data. (As such, when evaluating deviance values, lower is better.) For linear models, with the classic assumptions ($\overset{i.i.d.}{\sim}\mathcal{N}(0,\sigma^2_{\epsilon})$), the deviance is a function of the residual sum of squares (RSS):</span>
<span id="cb80-573"><a href="#cb80-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-574"><a href="#cb80-574" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-575"><a href="#cb80-575" aria-hidden="true" tabindex="-1"></a>\mathrm{Deviance} = n \ln\big(2\pi\sigma^2_{\epsilon}\big) + \frac{\mathrm{RSS}}{\sigma^2_{\epsilon}}</span>
<span id="cb80-576"><a href="#cb80-576" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-577"><a href="#cb80-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-578"><a href="#cb80-578" aria-hidden="true" tabindex="-1"></a>where $\mathrm{RSS}=\sum\epsilon_i^2$ and $\sigma^2_{\epsilon} = \frac{\mathrm{RSS}}{n}$. This formula illustrates that the residual deviance is a generalization of the residual sum of squares (RSS), and measures the model--data misfit.</span>
<span id="cb80-579"><a href="#cb80-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-580"><a href="#cb80-580" aria-hidden="true" tabindex="-1"></a>:::mathnote</span>
<span id="cb80-581"><a href="#cb80-581" aria-hidden="true" tabindex="-1"></a><span class="fu">### Mathematics of Deviance</span></span>
<span id="cb80-582"><a href="#cb80-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-583"><a href="#cb80-583" aria-hidden="true" tabindex="-1"></a>We can express the deviance mathematically by multiplying the log-likelihood by $-2$.</span>
<span id="cb80-584"><a href="#cb80-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-585"><a href="#cb80-585" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-586"><a href="#cb80-586" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-587"><a href="#cb80-587" aria-hidden="true" tabindex="-1"></a>\mathrm{Deviance} &amp;= -2 \times\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-588"><a href="#cb80-588" aria-hidden="true" tabindex="-1"></a>&amp;= -2 \bigg(-\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \epsilon_i^2\bigg) <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-589"><a href="#cb80-589" aria-hidden="true" tabindex="-1"></a>&amp;= -n\ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{\sigma^2_{\epsilon}}\sum \epsilon_i^2 <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-590"><a href="#cb80-590" aria-hidden="true" tabindex="-1"></a>&amp;= -n\ln (2\pi\sigma^2_{\epsilon}) + \frac{\mathrm{RSS}}{\sigma^2_{\epsilon}}</span>
<span id="cb80-591"><a href="#cb80-591" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-592"><a href="#cb80-592" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-593"><a href="#cb80-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-594"><a href="#cb80-594" aria-hidden="true" tabindex="-1"></a>Rewriting this using the parameters from the likelihood:</span>
<span id="cb80-595"><a href="#cb80-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-596"><a href="#cb80-596" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-597"><a href="#cb80-597" aria-hidden="true" tabindex="-1"></a>\mathrm{Deviance} = -n\ln (2\pi\sigma^2_{\epsilon}) + \frac{\sum_{i=1}^n \big<span class="co">[</span><span class="ot">Y_i-\beta_0-\beta_1(X_i)\big</span><span class="co">]</span>^2}{\sigma^2_{\epsilon}}</span>
<span id="cb80-598"><a href="#cb80-598" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-599"><a href="#cb80-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-600"><a href="#cb80-600" aria-hidden="true" tabindex="-1"></a>Once again, we find that the only variables in the deviance function are the regression coefficients.</span>
<span id="cb80-601"><a href="#cb80-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-602"><a href="#cb80-602" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb80-603"><a href="#cb80-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-604"><a href="#cb80-604" aria-hidden="true" tabindex="-1"></a>In practice, we will use the <span class="in">`logLik()`</span> function to compute the deviance.</span>
<span id="cb80-605"><a href="#cb80-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-608"><a href="#cb80-608" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-609"><a href="#cb80-609" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the deviance for Model 0</span></span>
<span id="cb80-610"><a href="#cb80-610" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.0</span>)[<span class="dv">1</span>]</span>
<span id="cb80-611"><a href="#cb80-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-612"><a href="#cb80-612" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the deviance for Model 1</span></span>
<span id="cb80-613"><a href="#cb80-613" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.1</span>)[<span class="dv">1</span>]</span>
<span id="cb80-614"><a href="#cb80-614" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-615"><a href="#cb80-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-616"><a href="#cb80-616" aria-hidden="true" tabindex="-1"></a>Here the deviance for Model 1 (883.5) is less than the deviance for Model 0 (896.2). This indicates that the data have better fit to Model 1 than Model 0. How much better is the model--data fit for Model 1?</span>
<span id="cb80-617"><a href="#cb80-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-620"><a href="#cb80-620" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-621"><a href="#cb80-621" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute difference in deviances</span></span>
<span id="cb80-622"><a href="#cb80-622" aria-hidden="true" tabindex="-1"></a><span class="fl">896.2</span> <span class="sc">-</span> <span class="fl">883.5</span></span>
<span id="cb80-623"><a href="#cb80-623" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-624"><a href="#cb80-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-625"><a href="#cb80-625" aria-hidden="true" tabindex="-1"></a>Model 1 improves the fit (reduces the misfit) by 12.7 over Model 0. This is the value of our $\chi^2$-statistic. That is, the $\chi^2$-statistic is the difference in residual deviance values and measures the amount of improvement in the model--data misfit.</span>
<span id="cb80-626"><a href="#cb80-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-627"><a href="#cb80-627" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-628"><a href="#cb80-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-629"><a href="#cb80-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-630"><a href="#cb80-630" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modeling the Variation in the Test Statistic</span></span>
<span id="cb80-631"><a href="#cb80-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-632"><a href="#cb80-632" aria-hidden="true" tabindex="-1"></a>If the null hypothesis is true, the difference in deviances can be modeled using a $\chi^2$-distribution. The degrees-of-freedom for this $\chi^2$-distribution is based on the difference in the number of parameters between the complex and simpler model. In our case this difference is four ($3-2=1$):</span>
<span id="cb80-633"><a href="#cb80-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-634"><a href="#cb80-634" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-635"><a href="#cb80-635" aria-hidden="true" tabindex="-1"></a>\chi^2(1) = 12.66</span>
<span id="cb80-636"><a href="#cb80-636" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-637"><a href="#cb80-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-640"><a href="#cb80-640" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-641"><a href="#cb80-641" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-01</span></span>
<span id="cb80-642"><a href="#cb80-642" aria-hidden="true" tabindex="-1"></a><span class="co">#| out-width: "70%"</span></span>
<span id="cb80-643"><a href="#cb80-643" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Plot of the probability density function (PDF) for a $\\chi^2(1)$ distribution. The grey shaded area represents the *p*-value based on $\\chi^2=12.66$."</span></span>
<span id="cb80-644"><a href="#cb80-644" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Plot of the probability density function (PDF) for a $\\chi^2(1)$ distribution. The grey shaded area represents the *p*-value based on $\\chi^2=12.66$."</span></span>
<span id="cb80-645"><a href="#cb80-645" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb80-646"><a href="#cb80-646" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dataset</span></span>
<span id="cb80-647"><a href="#cb80-647" aria-hidden="true" tabindex="-1"></a>fig_01 <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb80-648"><a href="#cb80-648" aria-hidden="true" tabindex="-1"></a>  <span class="at">X =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">20</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb80-649"><a href="#cb80-649" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb80-650"><a href="#cb80-650" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb80-651"><a href="#cb80-651" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> <span class="fu">dchisq</span>(<span class="at">x =</span> X, <span class="at">df =</span> <span class="dv">1</span>)</span>
<span id="cb80-652"><a href="#cb80-652" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb80-653"><a href="#cb80-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-654"><a href="#cb80-654" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out X&lt;=65</span></span>
<span id="cb80-655"><a href="#cb80-655" aria-hidden="true" tabindex="-1"></a>shaded <span class="ot">=</span> fig_01 <span class="sc">%&gt;%</span></span>
<span id="cb80-656"><a href="#cb80-656" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(X <span class="sc">&gt;=</span><span class="fl">12.66</span>)</span>
<span id="cb80-657"><a href="#cb80-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-658"><a href="#cb80-658" aria-hidden="true" tabindex="-1"></a><span class="co"># Create plot</span></span>
<span id="cb80-659"><a href="#cb80-659" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> fig_01, <span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y)) <span class="sc">+</span></span>
<span id="cb80-660"><a href="#cb80-660" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb80-661"><a href="#cb80-661" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Chi-squared"</span>) <span class="sc">+</span></span>
<span id="cb80-662"><a href="#cb80-662" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Probability density"</span>) <span class="sc">+</span></span>
<span id="cb80-663"><a href="#cb80-663" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb80-664"><a href="#cb80-664" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> shaded, <span class="at">ymin =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="fu">aes</span>(<span class="at">ymax =</span> Y), <span class="at">color =</span> <span class="st">"#bbbbbb"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>)</span>
<span id="cb80-665"><a href="#cb80-665" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-666"><a href="#cb80-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-667"><a href="#cb80-667" aria-hidden="true" tabindex="-1"></a>To compute the *p*-value we use the <span class="in">`pchisq()`</span> function.</span>
<span id="cb80-668"><a href="#cb80-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-671"><a href="#cb80-671" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-672"><a href="#cb80-672" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute p-value for X^2(1) = 14.50</span></span>
<span id="cb80-673"><a href="#cb80-673" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fl">12.66</span>, <span class="at">df =</span> <span class="dv">1</span>)</span>
<span id="cb80-674"><a href="#cb80-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-675"><a href="#cb80-675" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative method</span></span>
<span id="cb80-676"><a href="#cb80-676" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fl">12.66</span>, <span class="at">df =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb80-677"><a href="#cb80-677" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-678"><a href="#cb80-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-679"><a href="#cb80-679" aria-hidden="true" tabindex="-1"></a>Based on the *p*-value, we would reject the null hypothesis for the likelihood ratio test, which suggests that we should adopt the more complex model (Model 1). This means that the model that includes the effect of news exposure is more empirically supported than a model that includes no predictors. Note that we are making a holistic evaluation about the model rather than about individual predictors. </span>
<span id="cb80-680"><a href="#cb80-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-681"><a href="#cb80-681" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- To determine how much more variation Model 1 explains in news knowledge than Model 0 does, we look at the $R^2$ values from the `glance()` output. --&gt;</span></span>
<span id="cb80-682"><a href="#cb80-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-683"><a href="#cb80-683" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb80-684"><a href="#cb80-684" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Model-level output Model 0 --&gt;</span></span>
<span id="cb80-685"><a href="#cb80-685" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- glance(lm.0) --&gt;</span></span>
<span id="cb80-686"><a href="#cb80-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-687"><a href="#cb80-687" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Model-level output Model 1 --&gt;</span></span>
<span id="cb80-688"><a href="#cb80-688" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- glance(lm.1) --&gt;</span></span>
<span id="cb80-689"><a href="#cb80-689" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb80-690"><a href="#cb80-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-691"><a href="#cb80-691" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Model 1 explains 26.4% of the variation in peer ratings compared to Model 0, which explains 0% of the variation in peer ratings. This difference is statistically significant based on the *p*-value obtained from the likelihood ratio test ($p=0.000041$).  --&gt;</span></span>
<span id="cb80-692"><a href="#cb80-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-693"><a href="#cb80-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-694"><a href="#cb80-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-695"><a href="#cb80-695" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-696"><a href="#cb80-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-697"><a href="#cb80-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-698"><a href="#cb80-698" aria-hidden="true" tabindex="-1"></a><span class="fu">## Using the `lrtest()` Function</span></span>
<span id="cb80-699"><a href="#cb80-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-700"><a href="#cb80-700" aria-hidden="true" tabindex="-1"></a>In practice, we can also use the <span class="in">`lrtest()`</span> function from the <span class="in">`{lmtest}`</span> package to carry out a likelihood ratio test. We provide this function the name of the model object for the simpler model, followed by the name of the model object for the more complex model.</span>
<span id="cb80-701"><a href="#cb80-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-704"><a href="#cb80-704" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-705"><a href="#cb80-705" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb80-706"><a href="#cb80-706" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb80-707"><a href="#cb80-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-708"><a href="#cb80-708" aria-hidden="true" tabindex="-1"></a><span class="co"># LRT to compare Model 0 and Model 1</span></span>
<span id="cb80-709"><a href="#cb80-709" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.0</span>, lm<span class="fl">.1</span>)</span>
<span id="cb80-710"><a href="#cb80-710" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-711"><a href="#cb80-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-712"><a href="#cb80-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-713"><a href="#cb80-713" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-714"><a href="#cb80-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-715"><a href="#cb80-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-716"><a href="#cb80-716" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluating the Effect of News Exposure in Research Question 2</span></span>
<span id="cb80-717"><a href="#cb80-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-718"><a href="#cb80-718" aria-hidden="true" tabindex="-1"></a>In RQ 2, we are evaluating the effect of news exposure on news knowledge after controlling for the set of political and demographic covariates. To do this using a likelihood ratio test, we need to compare a baseline model that includes all of the covariates to a model that includes the covariates AND the effect of news exposure. That is, the only thing that is different between the two models is that the second model includes the effect of news exposure on top of the covariates. That is we will be comparing the following two models:</span>
<span id="cb80-719"><a href="#cb80-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-720"><a href="#cb80-720" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-721"><a href="#cb80-721" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-722"><a href="#cb80-722" aria-hidden="true" tabindex="-1"></a>\mathbf{Simple~Model:~} \quad \mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{Education}_i) + \beta_2(\mathrm{Male}_i) + <span class="sc">\\</span> </span>
<span id="cb80-723"><a href="#cb80-723" aria-hidden="true" tabindex="-1"></a>&amp;\beta_3(\mathrm{Engagement}_i) + \epsilon_i <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb80-724"><a href="#cb80-724" aria-hidden="true" tabindex="-1"></a>\mathbf{Complex~Model:~} \quad \mathrm{News~Knowledge}_i = &amp;\beta_0 + \beta_1(\mathrm{Education}_i) + \beta_2(\mathrm{Male}_i) + <span class="sc">\\</span></span>
<span id="cb80-725"><a href="#cb80-725" aria-hidden="true" tabindex="-1"></a>&amp;\beta_3(\mathrm{Engagement}_i) + \beta_8(\mathrm{News~Exposure}_i) + \epsilon_i <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb80-726"><a href="#cb80-726" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-727"><a href="#cb80-727" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-728"><a href="#cb80-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-729"><a href="#cb80-729" aria-hidden="true" tabindex="-1"></a>By comparing the parameters of the two models, we can see that the simpler model is nested in the more complex model. </span>
<span id="cb80-730"><a href="#cb80-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-731"><a href="#cb80-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-732"><a href="#cb80-732" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-733"><a href="#cb80-733" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb80-734"><a href="#cb80-734" aria-hidden="true" tabindex="-1"></a>\mathbf{Simple~Model~Parameters:}&amp;\quad<span class="sc">\{</span>\beta_0,~\beta_{\mathrm{Education}},~\beta_{\mathrm{Male}},~\beta_{\mathrm{Engagement}},~\sigma^2_{\epsilon}<span class="sc">\}</span> <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-735"><a href="#cb80-735" aria-hidden="true" tabindex="-1"></a>\mathbf{Complex~Model~Parameters:}&amp;\quad<span class="sc">\{</span>\beta_0, ~\beta_{\mathrm{Education}},~\beta_{\mathrm{Male}},~\beta_{\mathrm{Engagement}},~\beta_{\mathrm{News~Exposure}},~\sigma^2_{\epsilon}<span class="sc">\}</span> <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb80-736"><a href="#cb80-736" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb80-737"><a href="#cb80-737" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-738"><a href="#cb80-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-739"><a href="#cb80-739" aria-hidden="true" tabindex="-1"></a>To carry out the LRT we fit the two models, compute the difference in model deviances, and evaluate that difference in a $\chi^2$-distribution with degrees-of-freedom equal to the difference in model complexity (based on the number of parameters being estimated).</span>
<span id="cb80-740"><a href="#cb80-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-743"><a href="#cb80-743" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-744"><a href="#cb80-744" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple model</span></span>
<span id="cb80-745"><a href="#cb80-745" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.2</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement, <span class="at">data =</span> pew)</span>
<span id="cb80-746"><a href="#cb80-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-747"><a href="#cb80-747" aria-hidden="true" tabindex="-1"></a><span class="co"># Complex model</span></span>
<span id="cb80-748"><a href="#cb80-748" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.3</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news, <span class="at">data =</span> pew)</span>
<span id="cb80-749"><a href="#cb80-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-750"><a href="#cb80-750" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the difference in deviances between Model 1 and Model 2</span></span>
<span id="cb80-751"><a href="#cb80-751" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.2</span>)[<span class="dv">1</span>] <span class="sc">-</span> (<span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.3</span>)[<span class="dv">1</span>])</span>
<span id="cb80-752"><a href="#cb80-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-753"><a href="#cb80-753" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the difference in model complexity</span></span>
<span id="cb80-754"><a href="#cb80-754" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span> <span class="sc">-</span> <span class="dv">5</span></span>
<span id="cb80-755"><a href="#cb80-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-756"><a href="#cb80-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-757"><a href="#cb80-757" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute p-value for X^2(1) = 7.960401</span></span>
<span id="cb80-758"><a href="#cb80-758" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fl">8.924345</span>, <span class="at">df =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb80-759"><a href="#cb80-759" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-760"><a href="#cb80-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-761"><a href="#cb80-761" aria-hidden="true" tabindex="-1"></a>The *p*-value is 0.002813943, suggesting that there is an effect of news exposure on news knowledge, after controlling for the set of political and demographic covariates. Again, we could also obtain this same result via using the <span class="in">`lrtest()`</span> function.</span>
<span id="cb80-762"><a href="#cb80-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-765"><a href="#cb80-765" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-766"><a href="#cb80-766" aria-hidden="true" tabindex="-1"></a><span class="co"># LRT to compare Model 2 and Model 3</span></span>
<span id="cb80-767"><a href="#cb80-767" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.2</span>, lm<span class="fl">.3</span>)</span>
<span id="cb80-768"><a href="#cb80-768" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-769"><a href="#cb80-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-770"><a href="#cb80-770" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-771"><a href="#cb80-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-772"><a href="#cb80-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-773"><a href="#cb80-773" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluating the Interaction Effect in Research Question 3</span></span>
<span id="cb80-774"><a href="#cb80-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-775"><a href="#cb80-775" aria-hidden="true" tabindex="-1"></a>To evaluate the potential interaction effect between news exposure and education on news knowledge, after controlling for demographic and political covariates, we need to fit the interaction model and then compare it to a model that includes all the same predictors EXCEPT the interaction effect.</span>
<span id="cb80-776"><a href="#cb80-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-779"><a href="#cb80-779" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-780"><a href="#cb80-780" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit interaction model</span></span>
<span id="cb80-781"><a href="#cb80-781" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-782"><a href="#cb80-782" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-783"><a href="#cb80-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-784"><a href="#cb80-784" aria-hidden="true" tabindex="-1"></a>Note that Model 3 (fitted earlier) is the baseline comparison model to evaluate the interaction effect. Here we will use the <span class="in">`lrtest()`</span> function to compare Models 3 and 4 to evaluate the interaction effect.</span>
<span id="cb80-785"><a href="#cb80-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-786"><a href="#cb80-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-789"><a href="#cb80-789" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-790"><a href="#cb80-790" aria-hidden="true" tabindex="-1"></a><span class="co"># LRT to compare Model 1 and Model 2</span></span>
<span id="cb80-791"><a href="#cb80-791" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.3</span>, lm<span class="fl">.4</span>)</span>
<span id="cb80-792"><a href="#cb80-792" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-793"><a href="#cb80-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-794"><a href="#cb80-794" aria-hidden="true" tabindex="-1"></a>The *p*-value is 0.02324, suggesting that there is an interaction effect between news exposure and education level after controlling for differences in the set of political and demographic covariates.</span>
<span id="cb80-795"><a href="#cb80-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-796"><a href="#cb80-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-797"><a href="#cb80-797" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-798"><a href="#cb80-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-799"><a href="#cb80-799" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluating Assumptions</span></span>
<span id="cb80-800"><a href="#cb80-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-801"><a href="#cb80-801" aria-hidden="true" tabindex="-1"></a>If we were adopting a "final model", the empirical evidence would support adopting Model 4. It is always important to evaluate any adopted final models' assumptions.</span>
<span id="cb80-802"><a href="#cb80-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-805"><a href="#cb80-805" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-806"><a href="#cb80-806" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-residuals-linear</span></span>
<span id="cb80-807"><a href="#cb80-807" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Two residual plots for Model 4."</span></span>
<span id="cb80-808"><a href="#cb80-808" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Two residual plots for Model 4."</span></span>
<span id="cb80-809"><a href="#cb80-809" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb80-810"><a href="#cb80-810" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb80-811"><a href="#cb80-811" aria-hidden="true" tabindex="-1"></a><span class="co">#| out-width: "80%"</span></span>
<span id="cb80-812"><a href="#cb80-812" aria-hidden="true" tabindex="-1"></a><span class="co"># Create residual plots</span></span>
<span id="cb80-813"><a href="#cb80-813" aria-hidden="true" tabindex="-1"></a><span class="fu">residual_plots</span>(lm<span class="fl">.4</span>)</span>
<span id="cb80-814"><a href="#cb80-814" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-815"><a href="#cb80-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-816"><a href="#cb80-816" aria-hidden="true" tabindex="-1"></a>Based on the density plot, the assumption of normality looks reasonably met. The scatterplot suggests the assumption that the average residual is 0 is generally met---the loess smoother suggests the average residual is close to 0 at all fitted values. The homoscadasticity assumption also seems reasonable with the range of residuals generally being constant across the different fitted values. Lastly, since the sample is a random sample of Americans, the independence assumption also seems tenable.</span>
<span id="cb80-817"><a href="#cb80-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-818"><a href="#cb80-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-819"><a href="#cb80-819" aria-hidden="true" tabindex="-1"></a><span class="fu">## Presenting the Results from the LRTs</span></span>
<span id="cb80-820"><a href="#cb80-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-821"><a href="#cb80-821" aria-hidden="true" tabindex="-1"></a>Below we present a table summarizing the results of the likelihood ratio tests.</span>
<span id="cb80-822"><a href="#cb80-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-823"><a href="#cb80-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-824"><a href="#cb80-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-827"><a href="#cb80-827" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-828"><a href="#cb80-828" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-model-likelihood</span></span>
<span id="cb80-829"><a href="#cb80-829" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Results from a set of likelihood ratio tests (LRT) to compare sets of nested candidate models. "</span></span>
<span id="cb80-830"><a href="#cb80-830" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb80-831"><a href="#cb80-831" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb80-832"><a href="#cb80-832" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb80-833"><a href="#cb80-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-834"><a href="#cb80-834" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up data</span></span>
<span id="cb80-835"><a href="#cb80-835" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb80-836"><a href="#cb80-836" aria-hidden="true" tabindex="-1"></a>  <span class="at">comparison =</span> <span class="fu">c</span>(<span class="st">"Model 0 vs. Model 1"</span>, <span class="st">"Model 2 vs. Model 3"</span>, <span class="st">"Model 3 vs. Model 4"</span>),</span>
<span id="cb80-837"><a href="#cb80-837" aria-hidden="true" tabindex="-1"></a>  <span class="at">chi =</span> <span class="fu">c</span>(<span class="st">"$$</span><span class="sc">\\</span><span class="st">chi^2(1) = 12.66$$"</span>, <span class="st">"$$</span><span class="sc">\\</span><span class="st">chi^2(1) = 8.92$$"</span>, <span class="st">"$$</span><span class="sc">\\</span><span class="st">chi^2(1) = 5.15$$"</span>),</span>
<span id="cb80-838"><a href="#cb80-838" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="fu">c</span>(<span class="st">"&lt;.001"</span>, <span class="st">".003"</span>, <span class="st">".023"</span>)</span>
<span id="cb80-839"><a href="#cb80-839" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb80-840"><a href="#cb80-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-841"><a href="#cb80-841" aria-hidden="true" tabindex="-1"></a><span class="co"># Create table</span></span>
<span id="cb80-842"><a href="#cb80-842" aria-hidden="true" tabindex="-1"></a>d <span class="sc">|&gt;</span></span>
<span id="cb80-843"><a href="#cb80-843" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>() <span class="sc">|&gt;</span></span>
<span id="cb80-844"><a href="#cb80-844" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_label</span>(</span>
<span id="cb80-845"><a href="#cb80-845" aria-hidden="true" tabindex="-1"></a>    <span class="at">comparison =</span> <span class="fu">md</span>(<span class="st">"*Model Comparison*"</span>),</span>
<span id="cb80-846"><a href="#cb80-846" aria-hidden="true" tabindex="-1"></a>    <span class="at">chi =</span> <span class="st">"LRT Result"</span>,</span>
<span id="cb80-847"><a href="#cb80-847" aria-hidden="true" tabindex="-1"></a>    <span class="at">p =</span> <span class="fu">md</span>(<span class="st">"*p*"</span>)</span>
<span id="cb80-848"><a href="#cb80-848" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb80-849"><a href="#cb80-849" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb80-850"><a href="#cb80-850" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(comparison),</span>
<span id="cb80-851"><a href="#cb80-851" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"left"</span></span>
<span id="cb80-852"><a href="#cb80-852" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb80-853"><a href="#cb80-853" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb80-854"><a href="#cb80-854" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(chi, p),</span>
<span id="cb80-855"><a href="#cb80-855" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"center"</span></span>
<span id="cb80-856"><a href="#cb80-856" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb80-857"><a href="#cb80-857" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_options</span>(</span>
<span id="cb80-858"><a href="#cb80-858" aria-hidden="true" tabindex="-1"></a>    <span class="at">table.width =</span> <span class="fu">pct</span>(<span class="dv">60</span>),</span>
<span id="cb80-859"><a href="#cb80-859" aria-hidden="true" tabindex="-1"></a>    <span class="at">quarto.disable_processing =</span> <span class="cn">TRUE</span></span>
<span id="cb80-860"><a href="#cb80-860" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb80-861"><a href="#cb80-861" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-862"><a href="#cb80-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-863"><a href="#cb80-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-864"><a href="#cb80-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-865"><a href="#cb80-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-866"><a href="#cb80-866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-867"><a href="#cb80-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-868"><a href="#cb80-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-869"><a href="#cb80-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-870"><a href="#cb80-870" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb80-871"><a href="#cb80-871" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- #| results: asis --&gt;</span></span>
<span id="cb80-872"><a href="#cb80-872" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- #| code-fold: true --&gt;</span></span>
<span id="cb80-873"><a href="#cb80-873" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Load library --&gt;</span></span>
<span id="cb80-874"><a href="#cb80-874" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- library(texreg) --&gt;</span></span>
<span id="cb80-875"><a href="#cb80-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-876"><a href="#cb80-876" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Create the table --&gt;</span></span>
<span id="cb80-877"><a href="#cb80-877" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- htmlreg( --&gt;</span></span>
<span id="cb80-878"><a href="#cb80-878" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   l = list(lm.0, lm.1, lm.2, lm.3, lm.4), --&gt;</span></span>
<span id="cb80-879"><a href="#cb80-879" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   stars = numeric(0),    #No p-value stars --&gt;</span></span>
<span id="cb80-880"><a href="#cb80-880" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   digits = 3, --&gt;</span></span>
<span id="cb80-881"><a href="#cb80-881" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   padding = 20,          #Add space around columns (you may need to adjust this via trial-and-error) --&gt;</span></span>
<span id="cb80-882"><a href="#cb80-882" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   include.adjrs = FALSE, #Omit Adjusted R^2 --&gt;</span></span>
<span id="cb80-883"><a href="#cb80-883" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   include.nobs = FALSE,  #Omit sample size --&gt;</span></span>
<span id="cb80-884"><a href="#cb80-884" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   include.rmse = TRUE,   #Include RMSE --&gt;</span></span>
<span id="cb80-885"><a href="#cb80-885" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   custom.model.names = c("Model 0", "Model 1", "Model 2", "Model 3", "Model 4"), --&gt;</span></span>
<span id="cb80-886"><a href="#cb80-886" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   custom.coef.names = c("Intercept", "News Exposure", --&gt;</span></span>
<span id="cb80-887"><a href="#cb80-887" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                         "Education (in years)", "Male", --&gt;</span></span>
<span id="cb80-888"><a href="#cb80-888" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                         "Political Engagement", --&gt;</span></span>
<span id="cb80-889"><a href="#cb80-889" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                         "Education x News Exposure"), --&gt;</span></span>
<span id="cb80-890"><a href="#cb80-890" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   custom.note = "Note. Male, is a dummy-coded predictors. The reference group is non-males.", --&gt;</span></span>
<span id="cb80-891"><a href="#cb80-891" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   reorder.coef = c(2:6, 1), #Put intercept at bottom of table --&gt;</span></span>
<span id="cb80-892"><a href="#cb80-892" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   custom.gof.rows = list( --&gt;</span></span>
<span id="cb80-893"><a href="#cb80-893" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     `ln(Likelihood)` = c(-448.09, -441.76, -417.93, -413.92, -411.33) --&gt;</span></span>
<span id="cb80-894"><a href="#cb80-894" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   ), --&gt;</span></span>
<span id="cb80-895"><a href="#cb80-895" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   reorder.gof = c(3, 2, 1), --&gt;</span></span>
<span id="cb80-896"><a href="#cb80-896" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   caption.above = TRUE, #Move caption above table --&gt;</span></span>
<span id="cb80-897"><a href="#cb80-897" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   inner.rules = 1, #Include line rule before model-level output --&gt;</span></span>
<span id="cb80-898"><a href="#cb80-898" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   outer.rules = 1,  #Include line rules around table --&gt;</span></span>
<span id="cb80-899"><a href="#cb80-899" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   caption = "Table 2: Coefficients (and standard errors) for five models evaluating predictors of news knowledge." --&gt;</span></span>
<span id="cb80-900"><a href="#cb80-900" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   ) --&gt;</span></span>
<span id="cb80-901"><a href="#cb80-901" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb80-902"><a href="#cb80-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-903"><a href="#cb80-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-904"><a href="#cb80-904" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-905"><a href="#cb80-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-906"><a href="#cb80-906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-907"><a href="#cb80-907" aria-hidden="true" tabindex="-1"></a><span class="fu">## Reporting Individual Predictors From a Model</span></span>
<span id="cb80-908"><a href="#cb80-908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-909"><a href="#cb80-909" aria-hidden="true" tabindex="-1"></a>It is also good practice to report the coefficient-level and model-level estimates from any adopted models in a regression table. We will report results from Model 4. At the coefficient-level, the coefficients and standard errors can be reported from the <span class="in">`tidy()`</span> output. However, since we are using a likelihood framework, the *p*-values from the `tidy()` output are incorrect! We need to compute and report likelihood-based *p*-values.</span>
<span id="cb80-910"><a href="#cb80-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-911"><a href="#cb80-911" aria-hidden="true" tabindex="-1"></a>For example, to evaluate the effect of education on news knowledge we would essentially want to test the hypothesis that:</span>
<span id="cb80-912"><a href="#cb80-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-913"><a href="#cb80-913" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-914"><a href="#cb80-914" aria-hidden="true" tabindex="-1"></a>H_0: \beta_{\mathrm{Education}} = 0</span>
<span id="cb80-915"><a href="#cb80-915" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb80-916"><a href="#cb80-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-917"><a href="#cb80-917" aria-hidden="true" tabindex="-1"></a>To do this with a LRT, we need to compare two models:</span>
<span id="cb80-918"><a href="#cb80-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-919"><a href="#cb80-919" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>One model that includes all of the predictors from Model 4;</span>
<span id="cb80-920"><a href="#cb80-920" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>One model that includes everything from Model 4 *except* the effect of education.</span>
<span id="cb80-921"><a href="#cb80-921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-922"><a href="#cb80-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-923"><a href="#cb80-923" aria-hidden="true" tabindex="-1"></a>The only difference between these two models is the inclusion of the effect of education in the second model. That means any additional empirical support for the second model over the first is completely due to the effect of education. And, because the second model is nested in the first, we can evaluate this via a LRT.</span>
<span id="cb80-924"><a href="#cb80-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-927"><a href="#cb80-927" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-928"><a href="#cb80-928" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit full model 4</span></span>
<span id="cb80-929"><a href="#cb80-929" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-930"><a href="#cb80-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-931"><a href="#cb80-931" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model without education</span></span>
<span id="cb80-932"><a href="#cb80-932" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_education <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-933"><a href="#cb80-933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-934"><a href="#cb80-934" aria-hidden="true" tabindex="-1"></a><span class="co"># Carry out LRT</span></span>
<span id="cb80-935"><a href="#cb80-935" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_education, lm<span class="fl">.4</span>)</span>
<span id="cb80-936"><a href="#cb80-936" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-937"><a href="#cb80-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-938"><a href="#cb80-938" aria-hidden="true" tabindex="-1"></a>The *p*-value associated with the test of whether or not there is an effect of education (at least for the main effect) is 0.0001314. We will need to obtain the likelihood-based *p*-value for all of the other effects in a similar way. We will</span>
<span id="cb80-939"><a href="#cb80-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-942"><a href="#cb80-942" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-943"><a href="#cb80-943" aria-hidden="true" tabindex="-1"></a><span class="co"># Effect of male</span></span>
<span id="cb80-944"><a href="#cb80-944" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-945"><a href="#cb80-945" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_male <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-946"><a href="#cb80-946" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_male, lm<span class="fl">.4</span>) <span class="co"># Carry out LRT</span></span>
<span id="cb80-947"><a href="#cb80-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-948"><a href="#cb80-948" aria-hidden="true" tabindex="-1"></a><span class="co"># Effect of engagement</span></span>
<span id="cb80-949"><a href="#cb80-949" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-950"><a href="#cb80-950" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_engage <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-951"><a href="#cb80-951" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_engage, lm<span class="fl">.4</span>) <span class="co"># Carry out LRT</span></span>
<span id="cb80-952"><a href="#cb80-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-953"><a href="#cb80-953" aria-hidden="true" tabindex="-1"></a><span class="co"># Effect of new exposure (main-effect)</span></span>
<span id="cb80-954"><a href="#cb80-954" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-955"><a href="#cb80-955" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_news <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-956"><a href="#cb80-956" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_news, lm<span class="fl">.4</span>) <span class="co"># Carry out LRT</span></span>
<span id="cb80-957"><a href="#cb80-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-958"><a href="#cb80-958" aria-hidden="true" tabindex="-1"></a><span class="co"># Effect of interaction</span></span>
<span id="cb80-959"><a href="#cb80-959" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-960"><a href="#cb80-960" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_interaction <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news, <span class="at">data =</span> pew)</span>
<span id="cb80-961"><a href="#cb80-961" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_interaction, lm<span class="fl">.4</span>) <span class="co"># Carry out LRT</span></span>
<span id="cb80-962"><a href="#cb80-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-963"><a href="#cb80-963" aria-hidden="true" tabindex="-1"></a><span class="co"># Intercept</span></span>
<span id="cb80-964"><a href="#cb80-964" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span> <span class="ot">=</span> <span class="fu">lm</span>(knowledge <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-965"><a href="#cb80-965" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.4</span>_intercept <span class="ot">=</span> <span class="fu">lm</span>(knowledge<span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> education <span class="sc">+</span> male <span class="sc">+</span> engagement <span class="sc">+</span> news <span class="sc">+</span> news<span class="sc">:</span>education, <span class="at">data =</span> pew)</span>
<span id="cb80-966"><a href="#cb80-966" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.4</span>_intercept, lm<span class="fl">.4</span>) <span class="co"># Carry out LRT</span></span>
<span id="cb80-967"><a href="#cb80-967" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-968"><a href="#cb80-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-969"><a href="#cb80-969" aria-hidden="true" tabindex="-1"></a>We can then replace the *p*-values from the `tidy()` output with these likelihood-based *p*-values. Also, since these *p*-values are based on chi-squared (not a *t*-value), we should replace the *t*-values from the <span class="in">`tidy()`</span> output with the $\chi^2$-values from the LRTs.</span>
<span id="cb80-970"><a href="#cb80-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-971"><a href="#cb80-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-974"><a href="#cb80-974" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-975"><a href="#cb80-975" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(lm<span class="fl">.4</span>) <span class="sc">|&gt;</span></span>
<span id="cb80-976"><a href="#cb80-976" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb80-977"><a href="#cb80-977" aria-hidden="true" tabindex="-1"></a>    <span class="at">statistic =</span> <span class="fu">c</span>(<span class="fl">11.38</span>, <span class="fl">14.62</span>, <span class="fl">12.80</span>, <span class="fl">17.94</span>, <span class="fl">7.45</span>, <span class="fl">5.15</span>),</span>
<span id="cb80-978"><a href="#cb80-978" aria-hidden="true" tabindex="-1"></a>    <span class="at">p.value =</span> <span class="fu">c</span>(<span class="fl">0.0007417</span>, <span class="fl">0.0001314</span>, <span class="fl">0.0003466</span>, <span class="fl">0.0000228</span>, <span class="fl">0.006351</span>, <span class="fl">0.02324</span>)</span>
<span id="cb80-979"><a href="#cb80-979" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb80-980"><a href="#cb80-980" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-981"><a href="#cb80-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-982"><a href="#cb80-982" aria-hidden="true" tabindex="-1"></a>If we were reporting this for publication, we could round the *p*-values to three decimal places. We would also want to indicate that these are likelihood-based *p*-values, and that the LRT is based on 1 *df*.</span>
<span id="cb80-983"><a href="#cb80-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-986"><a href="#cb80-986" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-987"><a href="#cb80-987" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-model-4</span></span>
<span id="cb80-988"><a href="#cb80-988" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Coefficients and standard errors for Model 4. The $\\chi^2$ values and *p*-values are based on likelihood ratio tests (LRT) with 1 degree-of-freedom to evaluate each predictor."</span></span>
<span id="cb80-989"><a href="#cb80-989" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb80-990"><a href="#cb80-990" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb80-991"><a href="#cb80-991" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb80-992"><a href="#cb80-992" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gtsummary) <span class="co"># for formatting p-values</span></span>
<span id="cb80-993"><a href="#cb80-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-994"><a href="#cb80-994" aria-hidden="true" tabindex="-1"></a><span class="co"># Create table</span></span>
<span id="cb80-995"><a href="#cb80-995" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(lm<span class="fl">.4</span>) <span class="sc">|&gt;</span></span>
<span id="cb80-996"><a href="#cb80-996" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb80-997"><a href="#cb80-997" aria-hidden="true" tabindex="-1"></a>    <span class="at">term =</span> <span class="fu">c</span>(<span class="st">"Intercept"</span>, <span class="st">"Education-level"</span>, <span class="st">"Male"</span>, <span class="st">"Political engagement"</span>, <span class="st">"News exposure"</span>, <span class="st">"Education-level x News exposure"</span>),</span>
<span id="cb80-998"><a href="#cb80-998" aria-hidden="true" tabindex="-1"></a>    <span class="at">statistic =</span> <span class="fu">c</span>(<span class="fl">11.38</span>, <span class="fl">14.62</span>, <span class="fl">12.80</span>, <span class="fl">17.94</span>, <span class="fl">7.45</span>, <span class="fl">5.15</span>),</span>
<span id="cb80-999"><a href="#cb80-999" aria-hidden="true" tabindex="-1"></a>    <span class="at">p.value =</span> <span class="fu">style_pvalue</span>(<span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.0001314</span>, <span class="fl">0.0003466</span>, <span class="fl">0.0000228</span>, <span class="fl">0.006351</span>, <span class="fl">0.02324</span>), <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb80-1000"><a href="#cb80-1000" aria-hidden="true" tabindex="-1"></a>  )  <span class="sc">|&gt;</span></span>
<span id="cb80-1001"><a href="#cb80-1001" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>() <span class="sc">|&gt;</span></span>
<span id="cb80-1002"><a href="#cb80-1002" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_label</span>(</span>
<span id="cb80-1003"><a href="#cb80-1003" aria-hidden="true" tabindex="-1"></a>    <span class="at">term =</span> <span class="fu">md</span>(<span class="st">"*Predictor*"</span>),</span>
<span id="cb80-1004"><a href="#cb80-1004" aria-hidden="true" tabindex="-1"></a>    <span class="at">estimate =</span> <span class="fu">md</span>(<span class="st">"*B*"</span>),</span>
<span id="cb80-1005"><a href="#cb80-1005" aria-hidden="true" tabindex="-1"></a>    <span class="at">std.error =</span> <span class="fu">md</span>(<span class="st">"*SE*"</span>),</span>
<span id="cb80-1006"><a href="#cb80-1006" aria-hidden="true" tabindex="-1"></a>    <span class="at">statistic =</span> <span class="st">"$$</span><span class="sc">\\</span><span class="st">chi^2$$"</span>,</span>
<span id="cb80-1007"><a href="#cb80-1007" aria-hidden="true" tabindex="-1"></a>    <span class="at">p.value =</span> <span class="fu">md</span>(<span class="st">"*p*"</span>)</span>
<span id="cb80-1008"><a href="#cb80-1008" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb80-1009"><a href="#cb80-1009" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb80-1010"><a href="#cb80-1010" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(term),</span>
<span id="cb80-1011"><a href="#cb80-1011" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"left"</span></span>
<span id="cb80-1012"><a href="#cb80-1012" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb80-1013"><a href="#cb80-1013" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb80-1014"><a href="#cb80-1014" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(estimate, std.error, statistic, p.value),</span>
<span id="cb80-1015"><a href="#cb80-1015" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"center"</span></span>
<span id="cb80-1016"><a href="#cb80-1016" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb80-1017"><a href="#cb80-1017" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fmt_number</span>(</span>
<span id="cb80-1018"><a href="#cb80-1018" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(estimate, std.error),</span>
<span id="cb80-1019"><a href="#cb80-1019" aria-hidden="true" tabindex="-1"></a>    <span class="at">decimals =</span> <span class="dv">2</span>,</span>
<span id="cb80-1020"><a href="#cb80-1020" aria-hidden="true" tabindex="-1"></a>    <span class="at">use_seps =</span> <span class="cn">FALSE</span></span>
<span id="cb80-1021"><a href="#cb80-1021" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb80-1022"><a href="#cb80-1022" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_options</span>(</span>
<span id="cb80-1023"><a href="#cb80-1023" aria-hidden="true" tabindex="-1"></a>    <span class="at">table.width =</span> <span class="fu">pct</span>(<span class="dv">70</span>)</span>
<span id="cb80-1024"><a href="#cb80-1024" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb80-1025"><a href="#cb80-1025" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_footnote</span>(</span>
<span id="cb80-1026"><a href="#cb80-1026" aria-hidden="true" tabindex="-1"></a>    <span class="at">footnote =</span> <span class="fu">md</span>(<span class="st">"Male is a dummy-coded predictor with non-male as the reference group."</span>),</span>
<span id="cb80-1027"><a href="#cb80-1027" aria-hidden="true" tabindex="-1"></a>    <span class="at">locations =</span>  <span class="fu">cells_body</span>(<span class="at">columns =</span> term, <span class="at">rows =</span> <span class="dv">3</span>)</span>
<span id="cb80-1028"><a href="#cb80-1028" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb80-1029"><a href="#cb80-1029" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-1030"><a href="#cb80-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-1031"><a href="#cb80-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-1032"><a href="#cb80-1032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-1033"><a href="#cb80-1033" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb80-1034"><a href="#cb80-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-1035"><a href="#cb80-1035" aria-hidden="true" tabindex="-1"></a><span class="fu">## References</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>