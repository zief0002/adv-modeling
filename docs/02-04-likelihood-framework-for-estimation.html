<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; Likelihood: A Framework for Estimation – Advanced Modeling and Reproducibility for Educational Scientists</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03-00-modeling-nonlinearity.html" rel="next">
<link href="./02-03-likelihood-framework-for-evidence.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed04999718f06b735b1f8009dce43b94.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7c121de436c7c20b050f1da4c0bef0bb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="assets/sticky-notes.css">
<link rel="stylesheet" href="assets/table-styles.css">
</head>

<body class="nav-sidebar floating fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-00-likelihood.html">Likelihood</a></li><li class="breadcrumb-item"><a href="./02-04-likelihood-framework-for-estimation.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Estimation</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Advanced Modeling and Reproducibility for Educational Scientists</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Front Matter</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./01-00-reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Statistical Reproducibility</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-02-project-organization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Project Organization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-03-introduction-to-quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-04-more-quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">More Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-05-creating-tables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Creating Tables with gt</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./02-00-likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Likelihood</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-01-mathematical-foundations-probability-density.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Mathematical Foundations: Probability Density</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-03-likelihood-framework-for-evidence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Evidence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-04-likelihood-framework-for-estimation.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Estimation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./03-00-modeling-nonlinearity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling Nonlinearity</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-01-polynomial-effects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Polynomial Effects</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-02-information-criteria-and-model-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Information Criteria and Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-03-logarithmic-transformations-predictor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Log-Transforming the Predictor</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-04-logarithmic-transformations-outcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Log-Transforming the Outcome</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-05-rule-of-the-bulge.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Rule of the Bulge—An Example”</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./04-00-modeling-dichotomous-outcomes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling Dichotomous Outcomes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-01-linear-probability-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Linear Probability Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-02-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-03-more-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">More Logistic Regression</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./05-00-modeling-nonindependence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling Nonindependence</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-01-introduction-to-mixed-effects-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction to Mixed-Effects Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-02-lmer-average-change-over-time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">LMER: Average Change Over Time</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-03-lmer-other-random-effects-and-covariates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">LMER: Other Random-Effects and Covariates</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-04-lmer-alt-representations-and-assumptions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">LMER: Alternative Representations and Assumptions</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-00-likelihood.html">Likelihood</a></li><li class="breadcrumb-item"><a href="./02-04-likelihood-framework-for-estimation.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Estimation</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Estimation</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Quarto Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>In this set of notes, you will learn about the method of maximum likelihood to estimate model parameters.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<section id="likelihood" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="likelihood"><span class="header-section-number">7.1</span> Likelihood</h2>
<p>Remember that likelihood is the probability of a particular set of parameters GIVEN (1) the data, and (2) the data are from a particular distribution (e.g., normal). Symbolically,</p>
<p><span class="math display">\[
\mathrm{Likelihood} = P(\mathrm{Parameters} \mid \mathrm{Distribution~and~Data})
\]</span></p>
<p>Also recall, that to compute the likelihood we compute the joint probability density of the data under that particular set of parameters. For example, to compute <span class="math inline">\(\mathcal{L}(\mu = 20, \sigma = 4 \mid x = \{30, 20, 24, 27\}; \mathcal{N})\)</span>, we use the following syntax:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood mu=20, sigma=4</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">20</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.702554e-07</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="likelihood-as-a-framework-for-estimation" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="likelihood-as-a-framework-for-estimation"><span class="header-section-number">7.2</span> Likelihood as a Framework for Estimation</h2>
<p>Likelihood can be used as the basis for estimating parameters given a model and data. The idea is that the “best” estimates for the parameters are those that produce the highest likelihood given the data and model. Consider this example: Which set of parameters,<span class="math inline">\(\mathcal{N}(20,4)\)</span> or <span class="math inline">\(\mathcal{N}(25,4)\)</span>, was <em>more likely</em> to generate the data <span class="math inline">\(x = \{30, 20, 24, 27\}\)</span>? To answer this, we compute the likelihood for both candidate sets of parameters.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood mu=20, sigma=4</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">20</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.702554e-07</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood mu=25, sigma=4</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">25</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.774012e-05</code></pre>
</div>
</div>
<p>Since the second set of parameters produced a higher likelihood, it is more probable that the data were generated from the <span class="math inline">\(\mathcal{N}(25,4)\)</span> distribution than from the <span class="math inline">\(\mathcal{N}(20,4)\)</span> distribution. (Using the likelihood ratio, we can also say how much more likely the data were to be generated from this distribution.)</p>
<p>So now we come to the crux of Maximum Likelihood Estimation (MLE). The goal of MLE is to find a set of parameters that MAXIMIZES the likelihood given the data and a distribution. For example, given the observed data <span class="math inline">\(x = \{30, 20, 24, 27\}\)</span> were generated from a normal distribution, what are the values for the parameters of this distribution (mean and standard deviation) that produce the HIGHEST (or maximum) value of the likelihood?</p>
<p>Whichever parameters produce the highest likelihood end up being the parameter estimates. We will illustrate this a couple examples.</p>
<p><br></p>
</section>
<section id="example-1-using-mle-to-estimate-the-mean" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="example-1-using-mle-to-estimate-the-mean"><span class="header-section-number">7.3</span> Example 1: Using MLE to Estimate the Mean</h2>
<p>For our first example, we will keep it simple by only trying to estimate a single parameter value using MLE. For this example, we will try to estimate the mean value for the four data values, <span class="math inline">\(x=\{30,20,24,27\}\)</span>. To do this we will assume that the data were generated from a normal distribution and that the standard deviation in this normal distribution was <span class="math inline">\(\sigma=4.272\)</span>.</p>
<p>What we need to do, is compute the likelihood for several different <span class="math inline">\(\mu\)</span> values, and determine which produces the highest likelihood value. Here we try five different values for <span class="math inline">\(\mu\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute L(mu = 10)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="fl">4.272</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.449116e-16</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute L(mu = 15)</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">15</span>, <span class="at">sd =</span> <span class="fl">4.272</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.695637e-10</code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute L(mu = 20)</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">20</span>, <span class="at">sd =</span> <span class="fl">4.272</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 8.27684e-07</code></pre>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute L(mu = 25)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">25</span>, <span class="at">sd =</span> <span class="fl">4.272</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.685382e-05</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute L(mu = 30)</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">30</span>, <span class="at">sd =</span> <span class="fl">4.272</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.431642e-06</code></pre>
</div>
</div>
<p>Based on this it looks like a <span class="math inline">\(\mu\approx25\)</span> produces the highest likelihood. We can also plot the likelihood versus the candidate parameter values.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>example_01 <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">L =</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fl">4.272</span>))</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> example_01, <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> L)) <span class="sc">+</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkgrey"</span>, <span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(mu)) <span class="sc">+</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Likelihood"</span>) <span class="sc">+</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-lik_prof_01" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Plot of the likelihood values for five candidate parameter values.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lik_prof_01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-04-likelihood-framework-for-estimation_files/figure-html/fig-lik_prof_01-1.png" class="img-fluid figure-img" alt="Plot of the likelihood values for five candidate parameter values." width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lik_prof_01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1: Plot of the likelihood values for five candidate parameter values.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We could then continue to try values around 30 to hone in on the <span class="math inline">\(\mu\)</span> value that produces the highest likelihood (e.g., <span class="math inline">\(\mu=\{24.7, 24.8, 24.9, 25.1, 25.2, 25.3\}\)</span>). This methodology essentially boils down to continuing to narrow the search space by determining the likelihood value for more and more precisely defined values of the parameter.</p>
<p>We could also carry out this search computationally. Here for example, I set up a data frame that includes candidates for <span class="math inline">\(\mu\)</span>. This search space is looks at all values of <span class="math inline">\(\mu\)</span> between 10.00 and 30.00. This is called the <em>search space</em>. (Given our search space, we will be able to determine <span class="math inline">\(\mu\)</span> to within the nearest hundredth.) We are then going to compute the likelihood based on each of those values. We use <code>rowwise()</code> so that the likelihood (in the <code>mutate()</code> layer) is carried out correctly; using the <span class="math inline">\(\mu\)</span> value in each row. Because <code>rowwise()</code> At the end of the chain, we use <code>ungroup()</code> to return the results to an ungrouped data frame.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up parameter search space</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>example_01_grid <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">10</span>, <span class="at">to =</span> <span class="dv">30</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">L =</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fl">4.272</span>))</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co"># View results</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(example_01_grid)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 2
     mu        L
  &lt;dbl&gt;    &lt;dbl&gt;
1  10   1.45e-16
2  10.0 1.50e-16
3  10.0 1.55e-16
4  10.0 1.60e-16
5  10.0 1.66e-16
6  10.0 1.71e-16</code></pre>
</div>
</div>
<p>We can then plot the likelihood versus the parameter values for these 2,001 parameter candidates. Typically, when there are many values, we do this using a line plot. This is what is referred to as a <em>profile plot</em>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the likelihood versus the parameter values</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> example_01_grid, <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> L)) <span class="sc">+</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(mu)) <span class="sc">+</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Likelihood"</span>) <span class="sc">+</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-plot_example_01" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Likelihood profile for several parameter values assuming a normal distribution and a standard deviation of 4.272.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot_example_01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-04-likelihood-framework-for-estimation_files/figure-html/fig-plot_example_01-1.png" class="img-fluid figure-img" alt="Likelihood profile for several parameter values assuming a normal distribution and a standard deviation of 4.272." width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot_example_01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2: Likelihood profile for several parameter values assuming a normal distribution and a standard deviation of 4.272.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Using the profile plot, we can see that the <span class="math inline">\(\mu\)</span> value that produces the largest value for the likelihood is a bit higher than 25. We can find the exact value in our search space by arranging the rows in our search data frame by their likelihood values, and then using the <code>slice_max()</code> function to find the row with the highest likelihood value. The <code>n=1</code> argument finds the maximum row. If you wanted the highest two rows, we would use <code>n=2</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find mu with maximum likelihood</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>example_01_grid <span class="sc">|&gt;</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(L, <span class="at">n =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
     mu         L
  &lt;dbl&gt;     &lt;dbl&gt;
1  25.2 0.0000170</code></pre>
</div>
</div>
<p>In the candidate values for <span class="math inline">\(\mu\)</span> that we included in the search space, <span class="math inline">\(\mu=25.25\)</span> produces the highest likelihood. Thus, given the data and that the data were generated from a normal distribution with <span class="math inline">\(\sigma=4.272\)</span>, the most probable value for <span class="math inline">\(\mu\)</span> is 25.25. This is our maximum likelihood estimate for the mean!</p>
<div class="protip">
<p>You can get more precision in the estimate by changing the <code>by=</code> argument in the <code>seq()</code> function when you are initially setting up your search space. For example if you need the estimate to the nearest 1000th, set <code>by=.001</code>.</p>
</div>
<p><br></p>
</section>
<section id="example-2-using-mle-to-estimate-the-mean-and-standard-deviation" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="example-2-using-mle-to-estimate-the-mean-and-standard-deviation"><span class="header-section-number">7.4</span> Example 2: Using MLE to Estimate the Mean and Standard Deviation</h2>
<p>In the previous example, we assumed that we knew the value for <span class="math inline">\(\sigma\)</span>. In practice, this often needs to be estimates along with <span class="math inline">\(\mu\)</span>. To do this, you need to set up a search space that includes different combinations of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. Here we search <span class="math inline">\(\mu = \{10.0, 10.1, 10.2,\ldots, 30.0\}\)</span> and <span class="math inline">\(\sigma=\{0.0, 0.1, 0.2,\ldots,10.0\}\)</span> values from 0.1 to 10.0. (Remember, that <span class="math inline">\(\sigma\geq0\)</span>).</p>
<p>The <code>crossing()</code> function creates every combination of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> that we define in our search space. So, for example, [<span class="math inline">\(\mu=10.0; \sigma=0.0\)</span>], ]<span class="math inline">\(\mu=10.0; \sigma=0.1\)</span>], [<span class="math inline">\(\mu=10.0; \sigma=0.2\)</span>], etc. Since we have included 201 <span class="math inline">\(\mu\)</span> values and 101 <span class="math inline">\(\sigma\)</span> values, the search space is <span class="math inline">\(201 \times 101 = 20,301\)</span> parameter combinations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up search space</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the likelihood</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>example_02 <span class="ot">=</span> <span class="fu">crossing</span>(</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">10</span>, <span class="at">to =</span> <span class="dv">30</span>, <span class="at">by =</span> <span class="fl">0.1</span>),</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">L =</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma))</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Find row with highest likelihood</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>example_02 <span class="sc">|&gt;</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(L, <span class="at">n =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
     mu sigma         L
  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
1  25.2   3.7 0.0000183
2  25.3   3.7 0.0000183</code></pre>
</div>
</div>
<p>The parameters that maximize the likelihood (in our search space) are a mean of 25.2 and a standard deviation of 3.7. Again, if you need to be more precise in these estimates, you can increase the precision in the <code>by=</code> argument of the <code>seq()</code> functions.</p>
<p>In computer science, this method for finding the MLE is referred to as a <em>grid search</em>. This is because the combinations of parameter values in the search space constitute a grid. In the figure below, the search space for each parameter is listed in the first row/column of the table. Every other cell of the table (the “grid”) constitutes a particular combination of the parameters. We are then computing the likelihood for each combination of parameters and searching for the cell with the highest likelihood.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-grid-search-example-02" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Grid showing the combinations of parameter values used in the search space.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-grid-search-example-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/grid-search.jpg" class="img-fluid figure-img" alt="Grid showing the combinations of parameter values used in the search space." width="834">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-grid-search-example-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.3: Grid showing the combinations of parameter values used in the search space.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="protip">
<p>When we have two (or more) parameters we need to estimate the time taken to carry out a grid search is increased in a non-linear way. For example, combining 100 values of each parameter does not result in a search space of 200, but a search space of 10,000. So increasing the precision of both parameters to <code>by=.01</code> increases each the number of candidates from <span class="math inline">\(20,301\)</span> to <span class="math inline">\(2001 \times 1001 = 2,003,001\)</span>. This increase the computational time it takes to solve the problem.</p>
<p>If you are relying on grid search, it is often better to operate with less precision initially, and then identify smaller parts of the grid that can be searched with more precision.</p>
</div>
<p><br></p>
<section id="likelihood-profile-for-multiple-parameters" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="likelihood-profile-for-multiple-parameters"><span class="header-section-number">7.4.1</span> Likelihood Profile for Multiple Parameters</h3>
<p>We could also plot the profile of the likelihood for our search space, but this time there would be three dimensions: one dimension for <span class="math inline">\(\mu\)</span> (<em>x</em>-axis), one dimension for <span class="math inline">\(\sigma\)</span> (<em>y</em>-axis), and one dimension for the likelihood (<em>z</em>-axis). When we plot the likelihood profile across both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, the profile looks like an asymmetrical mountain. The highest likelihood value is at the summit of the mountain and corresponds to <span class="math inline">\(\mu=25.2\)</span> and <span class="math inline">\(\sigma=3.7\)</span>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plot3D)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="fu">scatter3D</span>(<span class="at">x =</span> example_02<span class="sc">$</span>mu, <span class="at">y =</span> example_02<span class="sc">$</span>sigma, <span class="at">z =</span> example_02<span class="sc">$</span>L, </span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">pch =</span> <span class="dv">18</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">theta =</span> <span class="dv">45</span>, <span class="at">phi =</span> <span class="dv">20</span>, <span class="at">ticktype =</span> <span class="st">"detailed"</span>,</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">xlab =</span> <span class="fu">expression</span>(mu), <span class="at">ylab =</span> <span class="fu">expression</span>(sigma), <span class="at">zlab =</span> <span class="st">"Likelihood"</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">colkey =</span> <span class="cn">FALSE</span>,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">colvar =</span> example_02<span class="sc">$</span>L,</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">col =</span> <span class="fu">ramp.col</span>(<span class="at">col =</span> <span class="fu">c</span>(<span class="st">"#f6eff7"</span>, <span class="st">"#bdc9e1"</span>, <span class="st">"#67a9cf"</span>, <span class="st">"#1c9099"</span>, <span class="st">"#016c59"</span>), <span class="at">n =</span> <span class="dv">100</span>, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-three-dim" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Likelihood profile for the search space of both $\mu$ and $\sigma$ assuming a normal distribution.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-three-dim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-04-likelihood-framework-for-estimation_files/figure-html/fig-three-dim-1.png" class="img-fluid figure-img" alt="Likelihood profile for the search space of both $\mu$ and $\sigma$ assuming a normal distribution." width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-three-dim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.4: Likelihood profile for the search space of both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> assuming a normal distribution.
</figcaption>
</figure>
</div>
</div>
</div>
<p>If we extend our estimation to three or more parameters, we can still use the computational search to find the maximum likelihood estimates (MLEs), but it would be difficult to plot (there would be four or more dimensions). In general, the profile plots are more useful as a pedagogical tool rather than as a way of actually finding the MLEs.</p>
<p><br></p>
</section>
</section>
<section id="log-likelihood" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="log-likelihood"><span class="header-section-number">7.5</span> Log-Likelihood</h2>
<p>The likelihood values are quite small since we are multiplying several probability densities together. To alleviate this issue, it is typical to compute the natural logarithm of the likelihood and operate on it, rather than on the likelihood itself. For example, in our first example, we would compute the log-likelihood<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and then determine the <span class="math inline">\(\mu\)</span> value that has the highest log-likelihood value.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up parameter search space</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood and</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>example_01 <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">10</span>, <span class="at">to =</span> <span class="dv">30</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">L =</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fl">4.272</span>)),</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">ln_L =</span> <span class="fu">log</span>(L)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Find mu with maximum log-likelihood</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>example_01 <span class="sc">|&gt;</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(ln_L, <span class="at">n =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
     mu         L  ln_L
  &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;
1  25.2 0.0000170 -11.0</code></pre>
</div>
</div>
<p>The profile of the log-likelihood looks a little different than that of the likelihood. What is important here is that the <span class="math inline">\(\mu\)</span> value that produces the highest value for the log-likelihood, is the same <span class="math inline">\(\mu\)</span> value that produces the highest likelihood.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the log-likelihood versus the parameter values</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> example_01, <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> ln_L)) <span class="sc">+</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(mu)) <span class="sc">+</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Log-likelihood"</span>) <span class="sc">+</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-example-03" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Log-likelihood profile for several parameter values assuming a normal distribution and a standard deviation of 4.272.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-example-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-04-likelihood-framework-for-estimation_files/figure-html/fig-example-03-1.png" class="img-fluid figure-img" alt="Log-likelihood profile for several parameter values assuming a normal distribution and a standard deviation of 4.272." width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-example-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.5: Log-likelihood profile for several parameter values assuming a normal distribution and a standard deviation of 4.272.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Maximizing the log-likelihood gives the same parameter values as maximizing the likelihood. Remember that , so maximizing the log-likelihood is the same as maximizing the likelihood<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p><br></p>
</section>
<section id="example-3-using-mle-to-estimate-regression-parameters" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="example-3-using-mle-to-estimate-regression-parameters"><span class="header-section-number">7.6</span> Example 3: Using MLE to Estimate Regression Parameters</h2>
<p>In estimating parameters for a regression model, we want to maximize the likelihood (or log-likelihood) for a given set of residuals that come from a normal distribution. We use the residuals since that is what we make distributional assumptions about in the model (e.g., normality, homogeneity of variance, independence). Our goal in regression is to estimate a set of parameters (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>) that maximize the likelihood of the residuals.</p>
<p>To understand this, consider the following a toy example of <span class="math inline">\(n=10\)</span> observations.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create toy data</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>example_03 <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>),</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">53</span>, <span class="dv">56</span>, <span class="dv">37</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">36</span>, <span class="dv">22</span>, <span class="dv">75</span>, <span class="dv">37</span>, <span class="dv">42</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create table</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>example_03 <span class="sc">|&gt;</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>() <span class="sc">|&gt;</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(x, y),</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"center"</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_label</span>(</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">md</span>(<span class="st">"*x*"</span>),</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">md</span>(<span class="st">"*y*"</span>)</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_options</span>(</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>   <span class="at">table.width =</span> <span class="fu">pct</span>(<span class="dv">30</span>) </span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="tbl-example-03" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-example-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.1: Toy data set that includes predictor (x) and outcome (y) values.
</figcaption>
<div aria-describedby="tbl-example-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="smqrhqyzoy" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#smqrhqyzoy table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#smqrhqyzoy thead, #smqrhqyzoy tbody, #smqrhqyzoy tfoot, #smqrhqyzoy tr, #smqrhqyzoy td, #smqrhqyzoy th {
  border-style: none;
}

#smqrhqyzoy p {
  margin: 0;
  padding: 0;
}

#smqrhqyzoy .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: 30%;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#smqrhqyzoy .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#smqrhqyzoy .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#smqrhqyzoy .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#smqrhqyzoy .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#smqrhqyzoy .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#smqrhqyzoy .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#smqrhqyzoy .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#smqrhqyzoy .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#smqrhqyzoy .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#smqrhqyzoy .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#smqrhqyzoy .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#smqrhqyzoy .gt_spanner_row {
  border-bottom-style: hidden;
}

#smqrhqyzoy .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#smqrhqyzoy .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#smqrhqyzoy .gt_from_md > :first-child {
  margin-top: 0;
}

#smqrhqyzoy .gt_from_md > :last-child {
  margin-bottom: 0;
}

#smqrhqyzoy .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#smqrhqyzoy .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#smqrhqyzoy .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#smqrhqyzoy .gt_row_group_first td {
  border-top-width: 2px;
}

#smqrhqyzoy .gt_row_group_first th {
  border-top-width: 2px;
}

#smqrhqyzoy .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#smqrhqyzoy .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#smqrhqyzoy .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#smqrhqyzoy .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#smqrhqyzoy .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#smqrhqyzoy .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#smqrhqyzoy .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#smqrhqyzoy .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#smqrhqyzoy .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#smqrhqyzoy .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#smqrhqyzoy .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#smqrhqyzoy .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#smqrhqyzoy .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#smqrhqyzoy .gt_left {
  text-align: left;
}

#smqrhqyzoy .gt_center {
  text-align: center;
}

#smqrhqyzoy .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#smqrhqyzoy .gt_font_normal {
  font-weight: normal;
}

#smqrhqyzoy .gt_font_bold {
  font-weight: bold;
}

#smqrhqyzoy .gt_font_italic {
  font-style: italic;
}

#smqrhqyzoy .gt_super {
  font-size: 65%;
}

#smqrhqyzoy .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#smqrhqyzoy .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#smqrhqyzoy .gt_indent_1 {
  text-indent: 5px;
}

#smqrhqyzoy .gt_indent_2 {
  text-indent: 10px;
}

#smqrhqyzoy .gt_indent_3 {
  text-indent: 15px;
}

#smqrhqyzoy .gt_indent_4 {
  text-indent: 20px;
}

#smqrhqyzoy .gt_indent_5 {
  text-indent: 25px;
}

#smqrhqyzoy .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#smqrhqyzoy div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_col_headings header">
<th id="x" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col"><em>x</em></th>
<th id="y" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col"><em>y</em></th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_center" headers="x">4</td>
<td class="gt_row gt_center" headers="y">53</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="x">0</td>
<td class="gt_row gt_center" headers="y">56</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="x">3</td>
<td class="gt_row gt_center" headers="y">37</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="x">4</td>
<td class="gt_row gt_center" headers="y">55</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="x">7</td>
<td class="gt_row gt_center" headers="y">50</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="x">0</td>
<td class="gt_row gt_center" headers="y">36</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="x">0</td>
<td class="gt_row gt_center" headers="y">22</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="x">3</td>
<td class="gt_row gt_center" headers="y">75</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="x">0</td>
<td class="gt_row gt_center" headers="y">37</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="x">2</td>
<td class="gt_row gt_center" headers="y">42</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
<p>We initially enter these observations into two vectors, <code>x</code> and <code>y</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Enter data into vectors</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">53</span>, <span class="dv">56</span>, <span class="dv">37</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">36</span>, <span class="dv">22</span>, <span class="dv">75</span>, <span class="dv">37</span>, <span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we will write a function to compute the log-likelihood of the residuals given a set of coefficient estimates. The bones for how we will create such a function is show below.</p>
<pre><code>ll = function(b_0, b_1){

  *Compute and output the log-likelihood*
}</code></pre>
<p>We use the <code>function()</code> function to write new functions. In our example, this function will be called <code>ll</code>. The arguments to the <code>function()</code> function are the inputs that a user of the function needs to input. Here we are asking users to input the two regression coefficients for a simple linear regression, namely <span class="math inline">\(\hat{\beta}_0\)</span> (<code>b_0</code>) and <span class="math inline">\(\hat{\beta}_1\)</span> (<code>b_1</code>).</p>
<p>All the computation that the function is going to execute is placed in-between the curly braces. For us this means we need to:</p>
<ul>
<li>Compute the residuals based on the inputs to the function;</li>
<li>Compute the log-likelihood based on the residuals; and</li>
<li>Output the log-likelihood value.</li>
</ul>
<p>To compute the residuals, we need to compute the fitted values, and subtract those from the outcome values. This means that we need <code>x</code> and <code>y</code> defined inside our function<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<p>Once we have the residuals, we compute the log-likelihood by incorporating the assumptions of the regression model. Since we assume the residuals are normally distributed, we compute the log-likelihood using the <code>dnorm()</code> function. The regression assumptions also specify that the mean residual value is 0; which implies that we should use the argument <code>mean=0</code> in the <code>dnorm()</code> function.</p>
<p>The assumption about the standard deviation is that the conditional distributions all have the same SD, but it doesn’t specify what that value is. However, the SD of the errors seems like a reasonable value, so we will use that.</p>
<p>Finally, we can output values from a function using the <code>return()</code> function. Below, we will write a function called <code>ll()</code> that takes two arguments as input, <code>b0=</code> and <code>b1=</code>, and outputs the log-likelihood.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to compute the log-likelihood</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>ll <span class="ot">=</span> <span class="cf">function</span>(b_0, b_1){</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Use the following x and y values</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">53</span>, <span class="dv">56</span>, <span class="dv">37</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">36</span>, <span class="dv">22</span>, <span class="dv">75</span>, <span class="dv">37</span>, <span class="dv">42</span>)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the yhat and residuals based on the two input values</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>  yhats <span class="ot">=</span> b_0 <span class="sc">+</span> b_1<span class="sc">*</span>x</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>  errors <span class="ot">=</span> y <span class="sc">-</span> yhats</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the sd of the residuals</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">=</span> <span class="fu">sd</span>(errors)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the log-likelihood</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>  log_lik <span class="ot">=</span> <span class="fu">sum</span>(<span class="fu">dnorm</span>(errors, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Output the log-likelihood</span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(log_lik)</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we read in our function by highlighting the whole thing and running it. Once it has been read in, we can use it just like any other function. For example to find the log-likelihood for the parameters <span class="math inline">\(\beta_0=10\)</span> and <span class="math inline">\(\beta_1=3\)</span> we use:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-likelihood for b_0=10 and b_1=3</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ll</span>(<span class="at">b_0 =</span> <span class="dv">10</span>, <span class="at">b_1 =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -64.29224</code></pre>
</div>
</div>
<p>We can also use our function to compute the log-likelihood in a grid search. Remember, our goal is to estimate the regression coefficients, so we are searching across values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data set of search values and log-likelihoods</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>example_03 <span class="ot">=</span> <span class="fu">crossing</span>(</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">B0 =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">30</span>, <span class="at">to =</span> <span class="dv">50</span>, <span class="at">by =</span> <span class="fl">0.1</span>),</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">B1 =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">to =</span> <span class="dv">5</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">ln_L =</span> <span class="fu">ll</span>(<span class="at">b_0 =</span> B0, <span class="at">b_1 =</span> B1)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Find parameters that produce highest log-likelihood</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>example_03 <span class="sc">|&gt;</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(ln_L, <span class="at">n =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
     B0    B1  ln_L
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1  40.1   2.7 -39.5</code></pre>
</div>
</div>
<p>Here the parameter values that maximize the likelihood are <span class="math inline">\(\beta_0 = 40.1\)</span> and <span class="math inline">\(\beta_1=2.7\)</span>. We can also compute what the standard deviation for the residual distributions was using the estimated parameter values. Remember, this value is an estimate of the RMSE.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute residuals using MLE estimate</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>errors <span class="ot">=</span> y <span class="sc">-</span> <span class="fl">40.1</span> <span class="sc">-</span> <span class="fl">2.7</span><span class="sc">*</span>x</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute estimate of RMSE</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(errors)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 13.18665</code></pre>
</div>
</div>
<p>Here the maximum likelihood estimates for our three parameters are: <span class="math inline">\(\hat{\beta}_0=40.1\)</span>, <span class="math inline">\(\hat{\beta}_1=2.7\)</span>, and <span class="math inline">\(\hat{\sigma}_{\epsilon}=13.2\)</span>.</p>
<p><br></p>
<section id="complications-with-grid-search" class="level3" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="complications-with-grid-search"><span class="header-section-number">7.6.1</span> Complications with Grid Search</h3>
<p>In practice, there are several issues with the grid search methods we have employed so far. The biggest is that you would not have any idea which values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> to limit the search space to. Essentially you would need to search an infinite number of values unless you could limit the search space in some way. For many common methods (e.g., linear regression) finding the ML estimates is mathematically pretty easy (if we know calculus; see the section <a href="#way-too-much-math">Using Calculus to Determine the MLEs</a>). For more complex methods (e.g., mixed-effect models) there is not a mathematical solution. Instead, mathematics is used to help limit the search space and then a grid search is used to hone in on the estimates.</p>
<p>Although not a complication, we made an assumption about the value of the residual standard error, that it was equivalent to <code>sigma(errors)</code>. In practice, this value would also need to be estimated, along with the coefficients.</p>
<p><br></p>
</section>
</section>
<section id="estimating-regression-parameter-ols-vs.-ml-estimation" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="estimating-regression-parameter-ols-vs.-ml-estimation"><span class="header-section-number">7.7</span> Estimating Regression Parameter: OLS vs.&nbsp;ML Estimation</h2>
<p>To compute ML estimates of the coefficients we will use the <code>mle2()</code> function from the <code>{bbmle}</code> package. To use the <code>mle2()</code> function, we need to provide a user-written function that returns the <em>negative log-likelihood</em> given a set of parameter inputs. Below we adapt the function we wrote earlier to return the negative log-likelihood. Since we are also interested in estimating the residual standard error (RSE), we also include this as an input into the function and use that inputted value in the <code>dnorm()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to output the negative log-likelihood</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>neg_ll <span class="ot">=</span> <span class="cf">function</span>(b_0, b_1, rse){</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Use the following x and y values</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">53</span>, <span class="dv">56</span>, <span class="dv">37</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">36</span>, <span class="dv">22</span>, <span class="dv">75</span>, <span class="dv">37</span>, <span class="dv">42</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the yhat and residuals based on the two input values</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>  yhats <span class="ot">=</span> b_0 <span class="sc">+</span> b_1<span class="sc">*</span>x</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>  errors <span class="ot">=</span> y <span class="sc">-</span> yhats</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the negative log-likelihood</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>  neg_log_lik <span class="ot">=</span> <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">dnorm</span>(errors, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> rse, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Output the log-likelihood</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(neg_log_lik)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can use the <code>mle2()</code> function to estimate the three parameters. This function requires the argument, <code>minuslogl=</code>, which takes the user written function returning the negative log-likelihood. It also requires a list of starting values (initial guesses) for the input parameters in the user-written function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bbmle)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: stats4</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'bbmle'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:dplyr':

    slice</code></pre>
</div>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model using ML</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>mle.results <span class="ot">=</span> <span class="fu">mle2</span>(<span class="at">minuslogl =</span> neg_ll, <span class="at">start =</span> <span class="fu">list</span>(<span class="at">b_0 =</span> <span class="fl">20.0</span>, <span class="at">b_1 =</span> <span class="fl">5.0</span>, <span class="at">rse =</span> <span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in dnorm(errors, mean = 0, sd = rse, log = TRUE): NaNs produced</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View results</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mle.results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Maximum likelihood estimation

Call:
mle2(minuslogl = neg_ll, start = list(b_0 = 20, b_1 = 5, rse = 10))

Coefficients:
    Estimate Std. Error z value     Pr(z)    
b_0  40.0072     5.6721  7.0533 1.748e-12 ***
b_1   2.7361     1.7674  1.5481    0.1216    
rse  12.5097     2.7973  4.4721 7.745e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

-2 log L: 78.90883 </code></pre>
</div>
</div>
<p>We also obtain the OLS estimates:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">53</span>, <span class="dv">56</span>, <span class="dv">37</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">36</span>, <span class="dv">22</span>, <span class="dv">75</span>, <span class="dv">37</span>, <span class="dv">42</span>)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model with OLS</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x)</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Get estimates</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(lm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 12
  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1     0.193        0.0926  14.0      1.92   0.203     1  -39.5  84.9  85.8
# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(lm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)    40.0       6.34      6.31 0.000231
2 x               2.74      1.98      1.38 0.203   </code></pre>
</div>
</div>
<p>Both sets of parameter estimates are presented in <a href="#tbl-compare-ests" class="quarto-xref">Table&nbsp;<span>7.2</span></a>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create toy data</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>estimates <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Estimate =</span> <span class="fu">c</span>(<span class="st">"$$</span><span class="sc">\\</span><span class="st">hat{</span><span class="sc">\\</span><span class="st">beta}_0$$"</span>, <span class="st">"$$</span><span class="sc">\\</span><span class="st">hat{</span><span class="sc">\\</span><span class="st">beta}_1$$"</span>, <span class="st">"$$</span><span class="sc">\\</span><span class="st">hat{</span><span class="sc">\\</span><span class="st">sigma}^2_{</span><span class="sc">\\</span><span class="st">epsilon}$$"</span>),</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ML =</span> <span class="fu">c</span>(<span class="fl">40.01</span>, <span class="fl">2.74</span>, <span class="fl">12.51</span>),</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">OLS =</span> <span class="fu">c</span>(<span class="fl">40.01</span>, <span class="fl">2.74</span>, <span class="fl">13.99</span>)</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create table</span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>estimates <span class="sc">|&gt;</span></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>() <span class="sc">|&gt;</span></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(Estimate, ML, OLS),</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"center"</span></span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_options</span>(</span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>   <span class="at">table.width =</span> <span class="fu">pct</span>(<span class="dv">40</span>) </span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="tbl-compare-ests" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-compare-ests-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.2: Parameter estimates using maximum likelihood (ML) and ordinary least squares (OLS) estimation.
</figcaption>
<div aria-describedby="tbl-compare-ests-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="rfksaeetmz" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#rfksaeetmz table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#rfksaeetmz thead, #rfksaeetmz tbody, #rfksaeetmz tfoot, #rfksaeetmz tr, #rfksaeetmz td, #rfksaeetmz th {
  border-style: none;
}

#rfksaeetmz p {
  margin: 0;
  padding: 0;
}

#rfksaeetmz .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: 40%;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#rfksaeetmz .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#rfksaeetmz .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#rfksaeetmz .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#rfksaeetmz .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rfksaeetmz .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rfksaeetmz .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rfksaeetmz .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#rfksaeetmz .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#rfksaeetmz .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#rfksaeetmz .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#rfksaeetmz .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#rfksaeetmz .gt_spanner_row {
  border-bottom-style: hidden;
}

#rfksaeetmz .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#rfksaeetmz .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#rfksaeetmz .gt_from_md > :first-child {
  margin-top: 0;
}

#rfksaeetmz .gt_from_md > :last-child {
  margin-bottom: 0;
}

#rfksaeetmz .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#rfksaeetmz .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#rfksaeetmz .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#rfksaeetmz .gt_row_group_first td {
  border-top-width: 2px;
}

#rfksaeetmz .gt_row_group_first th {
  border-top-width: 2px;
}

#rfksaeetmz .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rfksaeetmz .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#rfksaeetmz .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#rfksaeetmz .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rfksaeetmz .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rfksaeetmz .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#rfksaeetmz .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#rfksaeetmz .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#rfksaeetmz .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rfksaeetmz .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rfksaeetmz .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#rfksaeetmz .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rfksaeetmz .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#rfksaeetmz .gt_left {
  text-align: left;
}

#rfksaeetmz .gt_center {
  text-align: center;
}

#rfksaeetmz .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#rfksaeetmz .gt_font_normal {
  font-weight: normal;
}

#rfksaeetmz .gt_font_bold {
  font-weight: bold;
}

#rfksaeetmz .gt_font_italic {
  font-style: italic;
}

#rfksaeetmz .gt_super {
  font-size: 65%;
}

#rfksaeetmz .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#rfksaeetmz .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#rfksaeetmz .gt_indent_1 {
  text-indent: 5px;
}

#rfksaeetmz .gt_indent_2 {
  text-indent: 10px;
}

#rfksaeetmz .gt_indent_3 {
  text-indent: 15px;
}

#rfksaeetmz .gt_indent_4 {
  text-indent: 20px;
}

#rfksaeetmz .gt_indent_5 {
  text-indent: 25px;
}

#rfksaeetmz .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#rfksaeetmz div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_col_headings header">
<th id="Estimate" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col">Estimate</th>
<th id="ML" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col">ML</th>
<th id="OLS" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col">OLS</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_center" headers="Estimate">$$\hat{\beta}_0$$</td>
<td class="gt_row gt_center" headers="ML">40.01</td>
<td class="gt_row gt_center" headers="OLS">40.01</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="Estimate">$$\hat{\beta}_1$$</td>
<td class="gt_row gt_center" headers="ML">2.74</td>
<td class="gt_row gt_center" headers="OLS">2.74</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="Estimate">$$\hat{\sigma}^2_{\epsilon}$$</td>
<td class="gt_row gt_center" headers="ML">12.51</td>
<td class="gt_row gt_center" headers="OLS">13.99</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
<p>Comparing the coefficient estimates (<span class="math inline">\(\hat\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span>) to those obtained through ordinary least squares, we find they are quite similar. The estimate of the residual standard error (<span class="math inline">\(\sigma_{\epsilon}\)</span>), however, differs between the two estimation methods (although they are somewhat close in value).</p>
<p><br></p>
<section id="estimating-the-residual-variation-maximum-likelihood-vs.-ordinary-least-squares" class="level3" data-number="7.7.1">
<h3 data-number="7.7.1" class="anchored" data-anchor-id="estimating-the-residual-variation-maximum-likelihood-vs.-ordinary-least-squares"><span class="header-section-number">7.7.1</span> Estimating the Residual Variation: Maximum Likelihood vs.&nbsp;Ordinary Least Squares</h3>
<p>The estimates of the residual standard error differ because the two estimation methods use different criteria to optimize over; OLS estimation finds the estimates that minimize the sum of squared errors, and ML finds the estimates that maximize the likelihood. Because of the differences, it is important to report how the model was estimated in any publication.</p>
<p>Both estimation methods have been well studied, and the resulting residual standard error from these estimation methods can be computed directly once we have the coefficient estimates (which are the same for both methods). Namely, the residual standard error resulting from OLS estimation is:</p>
<p><span class="math display">\[
\hat\sigma_{\epsilon}= \sqrt{\frac{\left(Y_i - \hat{Y}_i\right)^2}{n-p-1}}
\]</span></p>
<p>where <em>p</em> is the number of predictors in the model. And the residual standard error resulting from ML estimation is:</p>
<p><span class="math display">\[
\hat\sigma_{\epsilon}=\sqrt{\frac{\left(Y_i - \hat{Y}_i\right)^2}{n}},
\]</span></p>
<p>The smaller denominator from the OLS estimate produces a higher overall estimate of the residual variation (more uncertainty). When <em>n</em> is large, the differences between the OLS and ML estimates of the residual standard error are minimal and can safely be ignored. When <em>n</em> is small, however, these differences can impact statistical results. For example, since the residual standard error is used to compute the standard error estimates for the coefficients, the choice of ML or OLS will have an effect on the size of the <em>t</em>- and <em>p</em>-values for the coefficients. (In practice, it is rare to see the different estimation methods producing substantively different findings, especially when fitting general linear models.)</p>
<p>Lastly, we note that the value of log-likelihood is the same for both the ML and OLS estimated models. The result from the ML output was:</p>
<p><span class="math display">\[
\begin{split}
-2 \ln(\mathrm{Likelihood}) &amp;= 78.91 \\[1ex]
\ln(\mathrm{Likelihood}) &amp;= -39.45
\end{split}
\]</span></p>
<p>The log-likelihood for the OLS estimated model is:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-likelihood for OLS model</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(<span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' -39.45442 (df=3)</code></pre>
</div>
</div>
<p>This is a very useful result. It allows us to use <code>lm()</code> to estimate the coefficients from a model and then use its log-likelihood value in the same way as if we had fitted the model using ML. This will be helpful when we compute measure such as information criteria later in the course.</p>
<div class="note">
<p>In many applications of estimation, it is useful to use a criterion which is modified variant of the likelihood. This variant omits “nuisance parameters” (parameters which are not of direct interest and subsequently not needed in the estimation method) from the computation of the likelihood. This restricted version of the likelihood is then maximized and the estimation method using this modified likelihood is called <em>Restricted Maximum Likelihood</em> (REML).</p>
<p>When REML is used to estimate parameters, the residual standard error turns out to be the same as that computed in the OLS estimation. As such, sometimes this estimate is referred to as the REML estimate of the residual standard error.</p>
</div>
<p><br></p>
</section>
<section id="way-too-much-math" class="level3 mathnote" data-number="7.7.2">
<h3 data-number="7.7.2" class="anchored" data-anchor-id="way-too-much-math"><span class="header-section-number">7.7.2</span> Using Calculus to Determine the MLEs</h3>
<p>A more convenient method to determine the ML estimates of the regression parameters is to use mathematics; specifically calculus. Remember, we can express the likelihood of the regression residuals mathematically as:</p>
<p><span class="math display">\[
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) = p(\epsilon_1) \times p(\epsilon_2) \times \ldots \times p(\epsilon_n)
\]</span></p>
<p>where the probability density of each residual (assuming normality) is:</p>
<p><span class="math display">\[
p(\epsilon_i) = \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{(\epsilon_i-\mu)^2}{2\sigma^2_{\epsilon}}\right]
\]</span></p>
<p>In addition to normality, which gives us the equation to compute the PDF for each residual, the regression assumptions also specify that each conditional error distribution has a mean of 0 and some variance (that is the same for all conditional error distributions). We can call it <span class="math inline">\(\sigma^2_{\epsilon}\)</span>. Substituting these values into the density function, we get,</p>
<p><span class="math display">\[
\begin{split}
p(\epsilon_i) &amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{(\epsilon_i-0)^2}{2\sigma^2_{\epsilon}}\right] \\[1em]
&amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{(\epsilon_i)^2}{2\sigma^2_{\epsilon}}\right]
\end{split}
\]</span></p>
<p>Now we substitute this expression for each of the <span class="math inline">\(p(\epsilon_i)\)</span> values in the likelihood computation.</p>
<p><span class="math display">\[
\begin{split}
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) &amp;= p(\epsilon_1) \times p(\epsilon_2) \times \ldots \times p(\epsilon_n) \\[1em]
&amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_1
^2}{2\sigma^2_{\epsilon}}\right] \times \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right] \times \ldots \times\\ &amp;~~~~\frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right]
\end{split}
\]</span></p>
<p>We can simplify this:</p>
<p><span class="math display">\[
\begin{split}
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) = &amp;\left[ \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right]^n \times \exp\left[-\frac{\epsilon_1^2}{2\sigma^2_{\epsilon}}\right] \times \exp\left[-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right] \times \ldots \times \\
&amp;\exp\left[-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right]
\end{split}
\]</span></p>
<p>Now we will take the natural logarithm of both sides of the expression:</p>
<p><span class="math display">\[
\begin{split}
\ln \Bigl(\mathcal{L}(\beta_0, \beta_1 | \mathrm{data})\Bigr) = &amp;\ln \Biggl( \left[ \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right]^n \times \exp\left[-\frac{\epsilon_1^2}{2\sigma^2_{\epsilon}}\right] \times \exp\left[-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right] \times \ldots \times \\
&amp;\exp\left[-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right] \Biggr)
\end{split}
\]</span></p>
<p>Using our rules for logarithms and re-arranging the terms gives us,</p>
<p><span class="math display">\[
\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = -\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \epsilon_i^2
\]</span></p>
<p>Examining this equation, we see that the log-likelihood is a function of <em>n</em>, <span class="math inline">\(\sigma^2_{\epsilon}\)</span> and the sum of squared residuals (SSR). The observed data define <em>n</em> (the sample size) and the other two components come from the residuals, which are a function of the parameters and the data.</p>
<p>Once we have this function, calculus can be used to find the analytic maximum. Typically before we do this, we replace <span class="math inline">\(\epsilon_i\)</span> with <span class="math inline">\(Y_i - \hat\beta_0 - \hat\beta_1(X_i)\)</span>; writing the residuals as a function of the parameters (which we are solving for) and the data.</p>
<p><span class="math display">\[
\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = -\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2
\]</span></p>
<p>In optimization, maximizing the log-likelihood is mathematically equivalent to minimizing the negative log-likelihood. (Note, this is what the <code>mle2()</code> function is doing.) That means we could also optimize over:</p>
<p><span class="math display">\[
-\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = \frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{2\sigma^2_{\epsilon}} \times \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2
\]</span></p>
<p>This has the advantage that we are removing the negative signs on the right-hand side of the equation. To find the analytic minimum (or maximum), we compute the partial derivatives <em>with respect to</em> <span class="math inline">\(\hat\beta_0\)</span>, <span class="math inline">\(\hat\beta_1\)</span>, and <span class="math inline">\(\hat\sigma^2_{\epsilon}\)</span>, and set these equal to zero and solve for each of the three parameters, respectively. That is:</p>
<p><span class="math display">\[
\begin{split}
\frac{\partial}{\partial \beta_0} \bigg[\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{2\sigma^2_{\epsilon}} \times \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2\bigg] &amp;= 0 \\[1em]
\frac{\partial}{\partial \beta_1} \bigg[\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{2\sigma^2_{\epsilon}} \times \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2\bigg] &amp;= 0 \\[1em]
\frac{\partial}{\partial \sigma^2_{\epsilon}} \bigg[\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{2\sigma^2_{\epsilon}} \times \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2\bigg] &amp;= 0
\end{split}
\]</span></p>
<p>Within each partial derivative, the parameters that are not being partialled can be treated as constants, which often makes the derivative easier to solve. For example in the first two partial derivatives the residual variance can be treated as a mathematical constant. Since all constant terms can be removed from the derivative, this leads to an interesting result:</p>
<p><span class="math display">\[
\frac{\partial}{\partial \boldsymbol{\beta}} \bigg[ -\mathcal{l}(\beta_0, \beta_1 | \mathrm{data})\bigg] = \frac{\partial}{\partial \boldsymbol{\beta}} \bigg[ \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2 \bigg]
\]</span></p>
<p>This means that minimizing the negative log-likelihood is equivalent to minimizing the sum of squared residuals! This implies that the coefficients we get for OLS and ML estimation are the same.</p>
<p>When we solve the third partial derivative for the residual standard error, we find that:</p>
<p><span class="math display">\[
\sigma^2_{\epsilon} = \frac{\sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2}{n}
\]</span></p>
<p>That is, the residual variance is equal to the sum of squared residuals divided by the sample size. In OLS estimation, the residual variance is the sum of squared residuals divided by the error degrees of freedom for the model. In the simple regression model the residual variance estimated using OLS would be:</p>
<p><span class="math display">\[
\sigma^2_{\epsilon} = \frac{\sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2}{n-2}
\]</span></p>
<p>This is why the residual standard errors were different when we used OLS and ML to carry out the estimation; the criteria we are optimizing over (sum of squared residuals vs.&nbsp;log-likelihood) impact the value of the residual variance estimate. Again, when <em>n</em> is large, the estimation method does not make a difference (i.e., <span class="math inline">\(n \approx n-2\)</span>).</p>
</section>
<p><br></p>
</section>
<section id="references" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="references"><span class="header-section-number">7.8</span> References</h2>


<!-- -->

</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>We could also compute the log-likelihood directly using <code>sum(dnorm(c(30, 20, 24, 27), mean = mu, sd = 4.272, log = TRUE))</code>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>This is because taking the logarithm of a set of numbers keeps the same ordination of values as the original values.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Alternatively, <code>x</code> and <code>y</code> could be included as additional inputs into the function.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-03-likelihood-framework-for-evidence.html" class="pagination-link" aria-label="Likelihood: A Framework for Evidence">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Evidence</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03-00-modeling-nonlinearity.html" class="pagination-link" aria-label="Modeling Nonlinearity">
        <span class="nav-page-text">Modeling Nonlinearity</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb57" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Likelihood: A Framework for Estimation</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>In this set of notes, you will learn about the method of maximum likelihood to estimate model parameters. </span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Load libraries</span></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a><span class="fu">## Likelihood</span></span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a>Remember that likelihood is the probability of a particular set of parameters GIVEN (1) the data, and (2) the data are from a particular distribution (e.g., normal). Symbolically,</span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>\mathrm{Likelihood} = P(\mathrm{Parameters} \mid \mathrm{Distribution~and~Data})</span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a>Also recall, that to compute the likelihood we compute the joint probability density of the data under that particular set of parameters. For example, to compute $\mathcal{L}(\mu = 20, \sigma = 4 \mid x = <span class="sc">\{</span>30, 20, 24, 27<span class="sc">\}</span>; \mathcal{N})$, we use the following syntax:</span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-33"><a href="#cb57-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood mu=20, sigma=4</span></span>
<span id="cb57-34"><a href="#cb57-34" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">20</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span>
<span id="cb57-35"><a href="#cb57-35" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-36"><a href="#cb57-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-37"><a href="#cb57-37" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-38"><a href="#cb57-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-39"><a href="#cb57-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-40"><a href="#cb57-40" aria-hidden="true" tabindex="-1"></a><span class="fu">## Likelihood as a Framework for Estimation</span></span>
<span id="cb57-41"><a href="#cb57-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-42"><a href="#cb57-42" aria-hidden="true" tabindex="-1"></a>Likelihood can be used as the basis for estimating parameters given a model and data. The idea is that the "best" estimates for the parameters are those that produce the highest likelihood given the data and model. Consider this example: Which set of parameters,$\mathcal{N}(20,4)$ or $\mathcal{N}(25,4)$, was *more likely* to generate the data $x = <span class="sc">\{</span>30, 20, 24, 27<span class="sc">\}</span>$? To answer this, we compute the likelihood for both candidate sets of parameters.</span>
<span id="cb57-43"><a href="#cb57-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-46"><a href="#cb57-46" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-47"><a href="#cb57-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood mu=20, sigma=4</span></span>
<span id="cb57-48"><a href="#cb57-48" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">20</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span>
<span id="cb57-49"><a href="#cb57-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-50"><a href="#cb57-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood mu=25, sigma=4</span></span>
<span id="cb57-51"><a href="#cb57-51" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">25</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span>
<span id="cb57-52"><a href="#cb57-52" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-53"><a href="#cb57-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-54"><a href="#cb57-54" aria-hidden="true" tabindex="-1"></a>Since the second set of parameters produced a higher likelihood, it is more probable that the data were generated from the $\mathcal{N}(25,4)$ distribution than from the $\mathcal{N}(20,4)$ distribution. (Using the likelihood ratio, we can also say how much more likely the data were to be generated from this distribution.)</span>
<span id="cb57-55"><a href="#cb57-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-56"><a href="#cb57-56" aria-hidden="true" tabindex="-1"></a>So now we come to the crux of Maximum Likelihood Estimation (MLE). The goal of MLE is to find a set of parameters that MAXIMIZES the likelihood given the data and a distribution. For example, given the observed data $x = <span class="sc">\{</span>30, 20, 24, 27<span class="sc">\}</span>$ were generated from a normal distribution, what are the values for the parameters of this distribution (mean and standard deviation) that produce the HIGHEST (or maximum) value of the likelihood?</span>
<span id="cb57-57"><a href="#cb57-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-58"><a href="#cb57-58" aria-hidden="true" tabindex="-1"></a>Whichever parameters produce the highest likelihood end up being the parameter estimates. We will illustrate this a couple examples.</span>
<span id="cb57-59"><a href="#cb57-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-60"><a href="#cb57-60" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-61"><a href="#cb57-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-62"><a href="#cb57-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-63"><a href="#cb57-63" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example 1: Using MLE to Estimate the Mean</span></span>
<span id="cb57-64"><a href="#cb57-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-65"><a href="#cb57-65" aria-hidden="true" tabindex="-1"></a>For our first example, we will keep it simple by only trying to estimate a single parameter value using MLE. For this example, we will try to estimate the mean value for the four data values, $x=<span class="sc">\{</span>30,20,24,27<span class="sc">\}</span>$. To do this we will assume that the data were generated from a normal distribution and that the standard deviation in this normal distribution was $\sigma=4.272$.</span>
<span id="cb57-66"><a href="#cb57-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-67"><a href="#cb57-67" aria-hidden="true" tabindex="-1"></a>What we need to do, is compute the likelihood for several different $\mu$ values, and determine which produces the highest likelihood value. Here we try five different values for $\mu$.</span>
<span id="cb57-68"><a href="#cb57-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-71"><a href="#cb57-71" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-72"><a href="#cb57-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute L(mu = 10)</span></span>
<span id="cb57-73"><a href="#cb57-73" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="fl">4.272</span>))</span>
<span id="cb57-74"><a href="#cb57-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-75"><a href="#cb57-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute L(mu = 15)</span></span>
<span id="cb57-76"><a href="#cb57-76" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">15</span>, <span class="at">sd =</span> <span class="fl">4.272</span>))</span>
<span id="cb57-77"><a href="#cb57-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-78"><a href="#cb57-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute L(mu = 20)</span></span>
<span id="cb57-79"><a href="#cb57-79" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">20</span>, <span class="at">sd =</span> <span class="fl">4.272</span>))</span>
<span id="cb57-80"><a href="#cb57-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-81"><a href="#cb57-81" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute L(mu = 25)</span></span>
<span id="cb57-82"><a href="#cb57-82" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">25</span>, <span class="at">sd =</span> <span class="fl">4.272</span>))</span>
<span id="cb57-83"><a href="#cb57-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-84"><a href="#cb57-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute L(mu = 30)</span></span>
<span id="cb57-85"><a href="#cb57-85" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">30</span>, <span class="at">sd =</span> <span class="fl">4.272</span>))</span>
<span id="cb57-86"><a href="#cb57-86" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-87"><a href="#cb57-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-88"><a href="#cb57-88" aria-hidden="true" tabindex="-1"></a>Based on this it looks like a $\mu\approx25$ produces the highest likelihood. We can also plot the likelihood versus the candidate parameter values.</span>
<span id="cb57-89"><a href="#cb57-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-92"><a href="#cb57-92" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-93"><a href="#cb57-93" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-lik_prof_01</span></span>
<span id="cb57-94"><a href="#cb57-94" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Plot of the likelihood values for five candidate parameter values."</span></span>
<span id="cb57-95"><a href="#cb57-95" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Plot of the likelihood values for five candidate parameter values."</span></span>
<span id="cb57-96"><a href="#cb57-96" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb57-97"><a href="#cb57-97" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data</span></span>
<span id="cb57-98"><a href="#cb57-98" aria-hidden="true" tabindex="-1"></a>example_01 <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb57-99"><a href="#cb57-99" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>)</span>
<span id="cb57-100"><a href="#cb57-100" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb57-101"><a href="#cb57-101" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb57-102"><a href="#cb57-102" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb57-103"><a href="#cb57-103" aria-hidden="true" tabindex="-1"></a>    <span class="at">L =</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fl">4.272</span>))</span>
<span id="cb57-104"><a href="#cb57-104" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb57-105"><a href="#cb57-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-106"><a href="#cb57-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-107"><a href="#cb57-107" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb57-108"><a href="#cb57-108" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> example_01, <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> L)) <span class="sc">+</span></span>
<span id="cb57-109"><a href="#cb57-109" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkgrey"</span>, <span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb57-110"><a href="#cb57-110" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb57-111"><a href="#cb57-111" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(mu)) <span class="sc">+</span></span>
<span id="cb57-112"><a href="#cb57-112" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Likelihood"</span>) <span class="sc">+</span></span>
<span id="cb57-113"><a href="#cb57-113" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span>
<span id="cb57-114"><a href="#cb57-114" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-115"><a href="#cb57-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-116"><a href="#cb57-116" aria-hidden="true" tabindex="-1"></a>We could then continue to try values around 30 to hone in on the $\mu$ value that produces the highest likelihood (e.g., $\mu=<span class="sc">\{</span>24.7, 24.8, 24.9, 25.1, 25.2, 25.3<span class="sc">\}</span>$). This methodology essentially boils down to continuing to narrow the search space by determining the likelihood value for more and more precisely defined values of the parameter.</span>
<span id="cb57-117"><a href="#cb57-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-118"><a href="#cb57-118" aria-hidden="true" tabindex="-1"></a>We could also carry out this search computationally. Here for example, I set up a data frame that includes candidates for $\mu$. This search space is looks at all values of $\mu$ between 10.00 and 30.00. This is called the *search space*. (Given our search space, we will be able to determine $\mu$ to within the nearest hundredth.) We are then going to compute the likelihood based on each of those values. We use <span class="in">`rowwise()`</span> so that the likelihood (in the <span class="in">`mutate()`</span> layer) is carried out correctly; using the $\mu$ value in each row. Because <span class="in">`rowwise()`</span> At the end of the chain, we use <span class="in">`ungroup()`</span> to return the results to an ungrouped data frame.</span>
<span id="cb57-119"><a href="#cb57-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-122"><a href="#cb57-122" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-123"><a href="#cb57-123" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: example_01</span></span>
<span id="cb57-124"><a href="#cb57-124" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up parameter search space</span></span>
<span id="cb57-125"><a href="#cb57-125" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood</span></span>
<span id="cb57-126"><a href="#cb57-126" aria-hidden="true" tabindex="-1"></a>example_01_grid <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb57-127"><a href="#cb57-127" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">10</span>, <span class="at">to =</span> <span class="dv">30</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb57-128"><a href="#cb57-128" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb57-129"><a href="#cb57-129" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb57-130"><a href="#cb57-130" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb57-131"><a href="#cb57-131" aria-hidden="true" tabindex="-1"></a>    <span class="at">L =</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fl">4.272</span>))</span>
<span id="cb57-132"><a href="#cb57-132" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb57-133"><a href="#cb57-133" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb57-134"><a href="#cb57-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-135"><a href="#cb57-135" aria-hidden="true" tabindex="-1"></a><span class="co"># View results</span></span>
<span id="cb57-136"><a href="#cb57-136" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(example_01_grid)</span>
<span id="cb57-137"><a href="#cb57-137" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-138"><a href="#cb57-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-139"><a href="#cb57-139" aria-hidden="true" tabindex="-1"></a>We can then plot the likelihood versus the parameter values for these 2,001 parameter candidates. Typically, when there are many values, we do this using a line plot. This is what is referred to as a *profile plot*.</span>
<span id="cb57-140"><a href="#cb57-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-143"><a href="#cb57-143" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-144"><a href="#cb57-144" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot_example_01</span></span>
<span id="cb57-145"><a href="#cb57-145" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Likelihood profile for several parameter values assuming a normal distribution and a standard deviation of 4.272."</span></span>
<span id="cb57-146"><a href="#cb57-146" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Likelihood profile for several parameter values assuming a normal distribution and a standard deviation of 4.272."</span></span>
<span id="cb57-147"><a href="#cb57-147" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the likelihood versus the parameter values</span></span>
<span id="cb57-148"><a href="#cb57-148" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> example_01_grid, <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> L)) <span class="sc">+</span></span>
<span id="cb57-149"><a href="#cb57-149" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb57-150"><a href="#cb57-150" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(mu)) <span class="sc">+</span></span>
<span id="cb57-151"><a href="#cb57-151" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Likelihood"</span>) <span class="sc">+</span></span>
<span id="cb57-152"><a href="#cb57-152" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span>
<span id="cb57-153"><a href="#cb57-153" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-154"><a href="#cb57-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-155"><a href="#cb57-155" aria-hidden="true" tabindex="-1"></a>Using the profile plot, we can see that the $\mu$ value that produces the largest value for the likelihood is a bit higher than 25. We can find the exact value in our search space by arranging the rows in our search data frame by their likelihood values, and then using the <span class="in">`slice_max()`</span> function to find the row with the highest likelihood value. The <span class="in">`n=1`</span> argument finds the maximum row. If you wanted the highest two rows, we would use <span class="in">`n=2`</span></span>
<span id="cb57-156"><a href="#cb57-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-159"><a href="#cb57-159" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-160"><a href="#cb57-160" aria-hidden="true" tabindex="-1"></a><span class="co"># Find mu with maximum likelihood</span></span>
<span id="cb57-161"><a href="#cb57-161" aria-hidden="true" tabindex="-1"></a>example_01_grid <span class="sc">|&gt;</span></span>
<span id="cb57-162"><a href="#cb57-162" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(L, <span class="at">n =</span> <span class="dv">1</span>)</span>
<span id="cb57-163"><a href="#cb57-163" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-164"><a href="#cb57-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-165"><a href="#cb57-165" aria-hidden="true" tabindex="-1"></a>In the candidate values for $\mu$ that we included in the search space, $\mu=25.25$ produces the highest likelihood. Thus, given the data and that the data were generated from a normal distribution with $\sigma=4.272$, the most probable value for $\mu$ is 25.25. This is our maximum likelihood estimate for the mean!</span>
<span id="cb57-166"><a href="#cb57-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-167"><a href="#cb57-167" aria-hidden="true" tabindex="-1"></a>:::protip</span>
<span id="cb57-168"><a href="#cb57-168" aria-hidden="true" tabindex="-1"></a>You can get more precision in the estimate by changing the <span class="in">`by=`</span> argument in the <span class="in">`seq()`</span> function when you are initially setting up your search space. For example if you need the estimate to the nearest 1000th, set <span class="in">`by=.001`</span>.</span>
<span id="cb57-169"><a href="#cb57-169" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb57-170"><a href="#cb57-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-171"><a href="#cb57-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-172"><a href="#cb57-172" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-173"><a href="#cb57-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-174"><a href="#cb57-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-175"><a href="#cb57-175" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example 2: Using MLE to Estimate the Mean and Standard Deviation</span></span>
<span id="cb57-176"><a href="#cb57-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-177"><a href="#cb57-177" aria-hidden="true" tabindex="-1"></a>In the previous example, we assumed that we knew the value for $\sigma$. In practice, this often needs to be estimates along with $\mu$. To do this, you need to set up a search space that includes different combinations of $\mu$ and $\sigma$. Here we search $\mu = <span class="sc">\{</span>10.0, 10.1, 10.2,\ldots, 30.0<span class="sc">\}</span>$ and $\sigma=<span class="sc">\{</span>0.0, 0.1, 0.2,\ldots,10.0<span class="sc">\}</span>$ values from 0.1 to 10.0. (Remember, that $\sigma\geq0$).</span>
<span id="cb57-178"><a href="#cb57-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-179"><a href="#cb57-179" aria-hidden="true" tabindex="-1"></a>The <span class="in">`crossing()`</span> function creates every combination of $\mu$ and $\sigma$ that we define in our search space. So, for example, <span class="co">[</span><span class="ot">$\mu=10.0; \sigma=0.0$</span><span class="co">]</span>, ]$\mu=10.0; \sigma=0.1$], <span class="co">[</span><span class="ot">$\mu=10.0; \sigma=0.2$</span><span class="co">]</span>, etc. Since we have included 201 $\mu$ values and 101 $\sigma$ values, the search space is $201 \times 101 = 20,301$ parameter combinations.</span>
<span id="cb57-180"><a href="#cb57-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-183"><a href="#cb57-183" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-184"><a href="#cb57-184" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up search space</span></span>
<span id="cb57-185"><a href="#cb57-185" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the likelihood</span></span>
<span id="cb57-186"><a href="#cb57-186" aria-hidden="true" tabindex="-1"></a>example_02 <span class="ot">=</span> <span class="fu">crossing</span>(</span>
<span id="cb57-187"><a href="#cb57-187" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">10</span>, <span class="at">to =</span> <span class="dv">30</span>, <span class="at">by =</span> <span class="fl">0.1</span>),</span>
<span id="cb57-188"><a href="#cb57-188" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb57-189"><a href="#cb57-189" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb57-190"><a href="#cb57-190" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb57-191"><a href="#cb57-191" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb57-192"><a href="#cb57-192" aria-hidden="true" tabindex="-1"></a>    <span class="at">L =</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma))</span>
<span id="cb57-193"><a href="#cb57-193" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb57-194"><a href="#cb57-194" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb57-195"><a href="#cb57-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-196"><a href="#cb57-196" aria-hidden="true" tabindex="-1"></a><span class="co"># Find row with highest likelihood</span></span>
<span id="cb57-197"><a href="#cb57-197" aria-hidden="true" tabindex="-1"></a>example_02 <span class="sc">|&gt;</span></span>
<span id="cb57-198"><a href="#cb57-198" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(L, <span class="at">n =</span> <span class="dv">1</span>)</span>
<span id="cb57-199"><a href="#cb57-199" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-200"><a href="#cb57-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-201"><a href="#cb57-201" aria-hidden="true" tabindex="-1"></a>The parameters that maximize the likelihood (in our search space) are a mean of 25.2 and a standard deviation of 3.7. Again, if you need to be more precise in these estimates, you can increase the precision in the <span class="in">`by=`</span> argument of the <span class="in">`seq()`</span> functions.</span>
<span id="cb57-202"><a href="#cb57-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-203"><a href="#cb57-203" aria-hidden="true" tabindex="-1"></a>In computer science, this method for finding the MLE is referred to as a *grid search*. This is because the combinations of parameter values in the search space constitute a grid. In the figure below, the search space for each parameter is listed in the first row/column of the table. Every other cell of the table (the "grid") constitutes a particular combination of the parameters. We are then computing the likelihood for each combination of parameters and searching for the cell with the highest likelihood.</span>
<span id="cb57-204"><a href="#cb57-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-207"><a href="#cb57-207" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-208"><a href="#cb57-208" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-grid-search-example-02</span></span>
<span id="cb57-209"><a href="#cb57-209" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Grid showing the combinations of parameter values used in the search space."</span></span>
<span id="cb57-210"><a href="#cb57-210" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Grid showing the combinations of parameter values used in the search space."</span></span>
<span id="cb57-211"><a href="#cb57-211" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb57-212"><a href="#cb57-212" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figs/grid-search.jpg"</span>)</span>
<span id="cb57-213"><a href="#cb57-213" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-214"><a href="#cb57-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-215"><a href="#cb57-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-216"><a href="#cb57-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-217"><a href="#cb57-217" aria-hidden="true" tabindex="-1"></a>:::protip</span>
<span id="cb57-218"><a href="#cb57-218" aria-hidden="true" tabindex="-1"></a>When we have two (or more) parameters we need to estimate the time taken to carry out a grid search is increased in a non-linear way. For example, combining 100 values of each parameter does not result in a search space of 200, but a search space of 10,000. So increasing the precision of both parameters to <span class="in">`by=.01`</span> increases each the number of candidates from $20,301$ to $2001 \times 1001 = 2,003,001$. This increase the computational time it takes to solve the problem.</span>
<span id="cb57-219"><a href="#cb57-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-220"><a href="#cb57-220" aria-hidden="true" tabindex="-1"></a>If you are relying on grid search, it is often better to operate with less precision initially, and then identify smaller parts of the grid that can be searched with more precision.</span>
<span id="cb57-221"><a href="#cb57-221" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb57-222"><a href="#cb57-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-223"><a href="#cb57-223" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-224"><a href="#cb57-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-225"><a href="#cb57-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-226"><a href="#cb57-226" aria-hidden="true" tabindex="-1"></a><span class="fu">### Likelihood Profile for Multiple Parameters</span></span>
<span id="cb57-227"><a href="#cb57-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-228"><a href="#cb57-228" aria-hidden="true" tabindex="-1"></a>We could also plot the profile of the likelihood for our search space, but this time there would be three dimensions: one dimension for $\mu$ (*x*-axis), one dimension for $\sigma$ (*y*-axis), and one dimension for the likelihood (*z*-axis). When we plot the likelihood profile across both $\mu$ and $\sigma$, the profile looks like an asymmetrical mountain. The highest likelihood value is at the summit of the mountain and corresponds to $\mu=25.2$ and $\sigma=3.7$.</span>
<span id="cb57-229"><a href="#cb57-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-232"><a href="#cb57-232" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-233"><a href="#cb57-233" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-three-dim</span></span>
<span id="cb57-234"><a href="#cb57-234" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Likelihood profile for the search space of both $\\mu$ and $\\sigma$ assuming a normal distribution."</span></span>
<span id="cb57-235"><a href="#cb57-235" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Likelihood profile for the search space of both $\\mu$ and $\\sigma$ assuming a normal distribution."</span></span>
<span id="cb57-236"><a href="#cb57-236" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb57-237"><a href="#cb57-237" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb57-238"><a href="#cb57-238" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plot3D)</span>
<span id="cb57-239"><a href="#cb57-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-240"><a href="#cb57-240" aria-hidden="true" tabindex="-1"></a><span class="fu">scatter3D</span>(<span class="at">x =</span> example_02<span class="sc">$</span>mu, <span class="at">y =</span> example_02<span class="sc">$</span>sigma, <span class="at">z =</span> example_02<span class="sc">$</span>L, </span>
<span id="cb57-241"><a href="#cb57-241" aria-hidden="true" tabindex="-1"></a>          <span class="at">pch =</span> <span class="dv">18</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">theta =</span> <span class="dv">45</span>, <span class="at">phi =</span> <span class="dv">20</span>, <span class="at">ticktype =</span> <span class="st">"detailed"</span>,</span>
<span id="cb57-242"><a href="#cb57-242" aria-hidden="true" tabindex="-1"></a>          <span class="at">xlab =</span> <span class="fu">expression</span>(mu), <span class="at">ylab =</span> <span class="fu">expression</span>(sigma), <span class="at">zlab =</span> <span class="st">"Likelihood"</span>,</span>
<span id="cb57-243"><a href="#cb57-243" aria-hidden="true" tabindex="-1"></a>          <span class="at">colkey =</span> <span class="cn">FALSE</span>,</span>
<span id="cb57-244"><a href="#cb57-244" aria-hidden="true" tabindex="-1"></a>          <span class="at">colvar =</span> example_02<span class="sc">$</span>L,</span>
<span id="cb57-245"><a href="#cb57-245" aria-hidden="true" tabindex="-1"></a>          <span class="at">col =</span> <span class="fu">ramp.col</span>(<span class="at">col =</span> <span class="fu">c</span>(<span class="st">"#f6eff7"</span>, <span class="st">"#bdc9e1"</span>, <span class="st">"#67a9cf"</span>, <span class="st">"#1c9099"</span>, <span class="st">"#016c59"</span>), <span class="at">n =</span> <span class="dv">100</span>, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb57-246"><a href="#cb57-246" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb57-247"><a href="#cb57-247" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-248"><a href="#cb57-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-249"><a href="#cb57-249" aria-hidden="true" tabindex="-1"></a>If we extend our estimation to three or more parameters, we can still use the computational search to find the maximum likelihood estimates (MLEs), but it would be difficult to plot (there would be four or more dimensions). In general, the profile plots are more useful as a pedagogical tool rather than as a way of actually finding the MLEs.</span>
<span id="cb57-250"><a href="#cb57-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-251"><a href="#cb57-251" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-252"><a href="#cb57-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-253"><a href="#cb57-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-254"><a href="#cb57-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-255"><a href="#cb57-255" aria-hidden="true" tabindex="-1"></a><span class="fu">## Log-Likelihood</span></span>
<span id="cb57-256"><a href="#cb57-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-257"><a href="#cb57-257" aria-hidden="true" tabindex="-1"></a>The likelihood values are quite small since we are multiplying several probability densities together. To alleviate this issue, it is typical to compute the natural logarithm of the likelihood and operate on it, rather than on the likelihood itself. For example, in our first example, we would compute the log-likelihood^<span class="co">[</span><span class="ot">We could also compute the log-likelihood directly using `sum(dnorm(c(30, 20, 24, 27), mean = mu, sd = 4.272, log = TRUE))`.</span><span class="co">]</span> and then determine the $\mu$ value that has the highest log-likelihood value.</span>
<span id="cb57-258"><a href="#cb57-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-261"><a href="#cb57-261" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-262"><a href="#cb57-262" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: example_01_revisited</span></span>
<span id="cb57-263"><a href="#cb57-263" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up parameter search space</span></span>
<span id="cb57-264"><a href="#cb57-264" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood and</span></span>
<span id="cb57-265"><a href="#cb57-265" aria-hidden="true" tabindex="-1"></a>example_01 <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb57-266"><a href="#cb57-266" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">10</span>, <span class="at">to =</span> <span class="dv">30</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb57-267"><a href="#cb57-267" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb57-268"><a href="#cb57-268" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb57-269"><a href="#cb57-269" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb57-270"><a href="#cb57-270" aria-hidden="true" tabindex="-1"></a>    <span class="at">L =</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fl">4.272</span>)),</span>
<span id="cb57-271"><a href="#cb57-271" aria-hidden="true" tabindex="-1"></a>    <span class="at">ln_L =</span> <span class="fu">log</span>(L)</span>
<span id="cb57-272"><a href="#cb57-272" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb57-273"><a href="#cb57-273" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb57-274"><a href="#cb57-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-275"><a href="#cb57-275" aria-hidden="true" tabindex="-1"></a><span class="co"># Find mu with maximum log-likelihood</span></span>
<span id="cb57-276"><a href="#cb57-276" aria-hidden="true" tabindex="-1"></a>example_01 <span class="sc">|&gt;</span></span>
<span id="cb57-277"><a href="#cb57-277" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(ln_L, <span class="at">n =</span> <span class="dv">1</span>)</span>
<span id="cb57-278"><a href="#cb57-278" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-279"><a href="#cb57-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-280"><a href="#cb57-280" aria-hidden="true" tabindex="-1"></a>The profile of the log-likelihood looks a little different than that of the likelihood. What is important here is that the $\mu$ value that produces the highest value for the log-likelihood, is the same $\mu$ value that produces the highest likelihood.</span>
<span id="cb57-281"><a href="#cb57-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-282"><a href="#cb57-282" aria-hidden="true" tabindex="-1"></a><span class="in">```{r plot_example_1_ln, fig.cap=""}</span></span>
<span id="cb57-283"><a href="#cb57-283" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-example-03</span></span>
<span id="cb57-284"><a href="#cb57-284" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Log-likelihood profile for several parameter values assuming a normal distribution and a standard deviation of 4.272."</span></span>
<span id="cb57-285"><a href="#cb57-285" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-alt: "Log-likelihood profile for several parameter values assuming a normal distribution and a standard deviation of 4.272."</span></span>
<span id="cb57-286"><a href="#cb57-286" aria-hidden="true" tabindex="-1"></a><span class="in"># Plot the log-likelihood versus the parameter values</span></span>
<span id="cb57-287"><a href="#cb57-287" aria-hidden="true" tabindex="-1"></a><span class="in">ggplot(data = example_01, aes(x = mu, y = ln_L)) +</span></span>
<span id="cb57-288"><a href="#cb57-288" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_line() +</span></span>
<span id="cb57-289"><a href="#cb57-289" aria-hidden="true" tabindex="-1"></a><span class="in">  xlab(expression(mu)) +</span></span>
<span id="cb57-290"><a href="#cb57-290" aria-hidden="true" tabindex="-1"></a><span class="in">  ylab("Log-likelihood") +</span></span>
<span id="cb57-291"><a href="#cb57-291" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_light()</span></span>
<span id="cb57-292"><a href="#cb57-292" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-293"><a href="#cb57-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-294"><a href="#cb57-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-295"><a href="#cb57-295" aria-hidden="true" tabindex="-1"></a>Maximizing the log-likelihood gives the same parameter values as maximizing the likelihood. Remember that , so maximizing the log-likelihood is the same as maximizing the likelihood^<span class="co">[</span><span class="ot">This is because taking the logarithm of a set of numbers keeps the same ordination of values as the original values.</span><span class="co">]</span>.</span>
<span id="cb57-296"><a href="#cb57-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-297"><a href="#cb57-297" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-298"><a href="#cb57-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-299"><a href="#cb57-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-300"><a href="#cb57-300" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example 3: Using MLE to Estimate Regression Parameters</span></span>
<span id="cb57-301"><a href="#cb57-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-302"><a href="#cb57-302" aria-hidden="true" tabindex="-1"></a>In estimating parameters for a regression model, we want to maximize the likelihood (or log-likelihood) for a given set of residuals that come from a normal distribution. We use the residuals since that is what we make distributional assumptions about in the model (e.g., normality, homogeneity of variance, independence). Our goal in regression is to estimate a set of parameters ($\beta_0$, $\beta_1$) that maximize the likelihood of the residuals.</span>
<span id="cb57-303"><a href="#cb57-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-304"><a href="#cb57-304" aria-hidden="true" tabindex="-1"></a>To understand this, consider the following a toy example of $n=10$ observations.</span>
<span id="cb57-305"><a href="#cb57-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-308"><a href="#cb57-308" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-309"><a href="#cb57-309" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-example-03</span></span>
<span id="cb57-310"><a href="#cb57-310" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Toy data set that includes predictor (x) and outcome (y) values."</span></span>
<span id="cb57-311"><a href="#cb57-311" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb57-312"><a href="#cb57-312" aria-hidden="true" tabindex="-1"></a><span class="co"># create toy data</span></span>
<span id="cb57-313"><a href="#cb57-313" aria-hidden="true" tabindex="-1"></a>example_03 <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb57-314"><a href="#cb57-314" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>),</span>
<span id="cb57-315"><a href="#cb57-315" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">53</span>, <span class="dv">56</span>, <span class="dv">37</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">36</span>, <span class="dv">22</span>, <span class="dv">75</span>, <span class="dv">37</span>, <span class="dv">42</span>)</span>
<span id="cb57-316"><a href="#cb57-316" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb57-317"><a href="#cb57-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-318"><a href="#cb57-318" aria-hidden="true" tabindex="-1"></a><span class="co"># Create table</span></span>
<span id="cb57-319"><a href="#cb57-319" aria-hidden="true" tabindex="-1"></a>example_03 <span class="sc">|&gt;</span></span>
<span id="cb57-320"><a href="#cb57-320" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>() <span class="sc">|&gt;</span></span>
<span id="cb57-321"><a href="#cb57-321" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb57-322"><a href="#cb57-322" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(x, y),</span>
<span id="cb57-323"><a href="#cb57-323" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"center"</span></span>
<span id="cb57-324"><a href="#cb57-324" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb57-325"><a href="#cb57-325" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_label</span>(</span>
<span id="cb57-326"><a href="#cb57-326" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">md</span>(<span class="st">"*x*"</span>),</span>
<span id="cb57-327"><a href="#cb57-327" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">md</span>(<span class="st">"*y*"</span>)</span>
<span id="cb57-328"><a href="#cb57-328" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb57-329"><a href="#cb57-329" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_options</span>(</span>
<span id="cb57-330"><a href="#cb57-330" aria-hidden="true" tabindex="-1"></a>   <span class="at">table.width =</span> <span class="fu">pct</span>(<span class="dv">30</span>) </span>
<span id="cb57-331"><a href="#cb57-331" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb57-332"><a href="#cb57-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-333"><a href="#cb57-333" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-334"><a href="#cb57-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-335"><a href="#cb57-335" aria-hidden="true" tabindex="-1"></a>We initially enter these observations into two vectors, <span class="in">`x`</span> and <span class="in">`y`</span>.</span>
<span id="cb57-336"><a href="#cb57-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-339"><a href="#cb57-339" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-340"><a href="#cb57-340" aria-hidden="true" tabindex="-1"></a><span class="co"># Enter data into vectors</span></span>
<span id="cb57-341"><a href="#cb57-341" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb57-342"><a href="#cb57-342" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">53</span>, <span class="dv">56</span>, <span class="dv">37</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">36</span>, <span class="dv">22</span>, <span class="dv">75</span>, <span class="dv">37</span>, <span class="dv">42</span>)</span>
<span id="cb57-343"><a href="#cb57-343" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-344"><a href="#cb57-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-345"><a href="#cb57-345" aria-hidden="true" tabindex="-1"></a>Next, we will write a function to compute the log-likelihood of the residuals given a set of coefficient estimates. The bones for how we will create such a function is show below.</span>
<span id="cb57-346"><a href="#cb57-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-347"><a href="#cb57-347" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-348"><a href="#cb57-348" aria-hidden="true" tabindex="-1"></a><span class="in">ll = function(b_0, b_1){</span></span>
<span id="cb57-349"><a href="#cb57-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-350"><a href="#cb57-350" aria-hidden="true" tabindex="-1"></a><span class="in">  *Compute and output the log-likelihood*</span></span>
<span id="cb57-351"><a href="#cb57-351" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb57-352"><a href="#cb57-352" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-353"><a href="#cb57-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-354"><a href="#cb57-354" aria-hidden="true" tabindex="-1"></a>We use the <span class="in">`function()`</span> function to write new functions. In our example, this function will be called <span class="in">`ll`</span>. The arguments to the <span class="in">`function()`</span> function are the inputs that a user of the function needs to input. Here we are asking users to input the two regression coefficients for a simple linear regression, namely $\hat{\beta}_0$ (<span class="in">`b_0`</span>) and $\hat{\beta}_1$ (<span class="in">`b_1`</span>).</span>
<span id="cb57-355"><a href="#cb57-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-356"><a href="#cb57-356" aria-hidden="true" tabindex="-1"></a>All the computation that the function is going to execute is placed in-between the curly braces. For us this means we need to:</span>
<span id="cb57-357"><a href="#cb57-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-358"><a href="#cb57-358" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compute the residuals based on the inputs to the function;</span>
<span id="cb57-359"><a href="#cb57-359" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compute the log-likelihood based on the residuals; and</span>
<span id="cb57-360"><a href="#cb57-360" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Output the log-likelihood value.</span>
<span id="cb57-361"><a href="#cb57-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-362"><a href="#cb57-362" aria-hidden="true" tabindex="-1"></a>To compute the residuals, we need to compute the fitted values, and subtract those from the outcome values. This means that we need <span class="in">`x`</span> and <span class="in">`y`</span> defined inside our function^<span class="co">[</span><span class="ot">Alternatively, `x` and `y` could be included as additional inputs into the function.</span><span class="co">]</span>.</span>
<span id="cb57-363"><a href="#cb57-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-364"><a href="#cb57-364" aria-hidden="true" tabindex="-1"></a>Once we have the residuals, we compute the log-likelihood by incorporating the assumptions of the regression model. Since we assume the residuals are normally distributed, we compute the log-likelihood using the <span class="in">`dnorm()`</span> function. The regression assumptions also specify that the mean residual value is 0; which implies that we should use the argument <span class="in">`mean=0`</span> in the <span class="in">`dnorm()`</span> function.</span>
<span id="cb57-365"><a href="#cb57-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-366"><a href="#cb57-366" aria-hidden="true" tabindex="-1"></a>The assumption about the standard deviation is that the conditional distributions all have the same SD, but it doesn't specify what that value is. However, the SD of the errors seems like a reasonable value, so we will use that.</span>
<span id="cb57-367"><a href="#cb57-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-368"><a href="#cb57-368" aria-hidden="true" tabindex="-1"></a>Finally, we can output values from a function using the <span class="in">`return()`</span> function. Below, we will write a function called <span class="in">`ll()`</span> that takes two arguments as input, <span class="in">`b0=`</span> and <span class="in">`b1=`</span>, and outputs the log-likelihood.</span>
<span id="cb57-369"><a href="#cb57-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-372"><a href="#cb57-372" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-373"><a href="#cb57-373" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to compute the log-likelihood</span></span>
<span id="cb57-374"><a href="#cb57-374" aria-hidden="true" tabindex="-1"></a>ll <span class="ot">=</span> <span class="cf">function</span>(b_0, b_1){</span>
<span id="cb57-375"><a href="#cb57-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-376"><a href="#cb57-376" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Use the following x and y values</span></span>
<span id="cb57-377"><a href="#cb57-377" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb57-378"><a href="#cb57-378" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">53</span>, <span class="dv">56</span>, <span class="dv">37</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">36</span>, <span class="dv">22</span>, <span class="dv">75</span>, <span class="dv">37</span>, <span class="dv">42</span>)</span>
<span id="cb57-379"><a href="#cb57-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-380"><a href="#cb57-380" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the yhat and residuals based on the two input values</span></span>
<span id="cb57-381"><a href="#cb57-381" aria-hidden="true" tabindex="-1"></a>  yhats <span class="ot">=</span> b_0 <span class="sc">+</span> b_1<span class="sc">*</span>x</span>
<span id="cb57-382"><a href="#cb57-382" aria-hidden="true" tabindex="-1"></a>  errors <span class="ot">=</span> y <span class="sc">-</span> yhats</span>
<span id="cb57-383"><a href="#cb57-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-384"><a href="#cb57-384" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the sd of the residuals</span></span>
<span id="cb57-385"><a href="#cb57-385" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">=</span> <span class="fu">sd</span>(errors)</span>
<span id="cb57-386"><a href="#cb57-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-387"><a href="#cb57-387" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the log-likelihood</span></span>
<span id="cb57-388"><a href="#cb57-388" aria-hidden="true" tabindex="-1"></a>  log_lik <span class="ot">=</span> <span class="fu">sum</span>(<span class="fu">dnorm</span>(errors, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb57-389"><a href="#cb57-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-390"><a href="#cb57-390" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Output the log-likelihood</span></span>
<span id="cb57-391"><a href="#cb57-391" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(log_lik)</span>
<span id="cb57-392"><a href="#cb57-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-393"><a href="#cb57-393" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb57-394"><a href="#cb57-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-395"><a href="#cb57-395" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-396"><a href="#cb57-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-397"><a href="#cb57-397" aria-hidden="true" tabindex="-1"></a>Now we read in our function by highlighting the whole thing and running it. Once it has been read in, we can use it just like any other function. For example to find the log-likelihood for the parameters $\beta_0=10$ and $\beta_1=3$ we use:</span>
<span id="cb57-398"><a href="#cb57-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-401"><a href="#cb57-401" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-402"><a href="#cb57-402" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-likelihood for b_0=10 and b_1=3</span></span>
<span id="cb57-403"><a href="#cb57-403" aria-hidden="true" tabindex="-1"></a><span class="fu">ll</span>(<span class="at">b_0 =</span> <span class="dv">10</span>, <span class="at">b_1 =</span> <span class="dv">3</span>)</span>
<span id="cb57-404"><a href="#cb57-404" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-405"><a href="#cb57-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-406"><a href="#cb57-406" aria-hidden="true" tabindex="-1"></a>We can also use our function to compute the log-likelihood in a grid search. Remember, our goal is to estimate the regression coefficients, so we are searching across values of $\beta_0$ and $\beta_1$.</span>
<span id="cb57-407"><a href="#cb57-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-410"><a href="#cb57-410" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-411"><a href="#cb57-411" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data set of search values and log-likelihoods</span></span>
<span id="cb57-412"><a href="#cb57-412" aria-hidden="true" tabindex="-1"></a>example_03 <span class="ot">=</span> <span class="fu">crossing</span>(</span>
<span id="cb57-413"><a href="#cb57-413" aria-hidden="true" tabindex="-1"></a>  <span class="at">B0 =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">30</span>, <span class="at">to =</span> <span class="dv">50</span>, <span class="at">by =</span> <span class="fl">0.1</span>),</span>
<span id="cb57-414"><a href="#cb57-414" aria-hidden="true" tabindex="-1"></a>  <span class="at">B1 =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">to =</span> <span class="dv">5</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb57-415"><a href="#cb57-415" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span></span>
<span id="cb57-416"><a href="#cb57-416" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb57-417"><a href="#cb57-417" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb57-418"><a href="#cb57-418" aria-hidden="true" tabindex="-1"></a>    <span class="at">ln_L =</span> <span class="fu">ll</span>(<span class="at">b_0 =</span> B0, <span class="at">b_1 =</span> B1)</span>
<span id="cb57-419"><a href="#cb57-419" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb57-420"><a href="#cb57-420" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb57-421"><a href="#cb57-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-422"><a href="#cb57-422" aria-hidden="true" tabindex="-1"></a><span class="co"># Find parameters that produce highest log-likelihood</span></span>
<span id="cb57-423"><a href="#cb57-423" aria-hidden="true" tabindex="-1"></a>example_03 <span class="sc">|&gt;</span></span>
<span id="cb57-424"><a href="#cb57-424" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(ln_L, <span class="at">n =</span> <span class="dv">1</span>)</span>
<span id="cb57-425"><a href="#cb57-425" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-426"><a href="#cb57-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-427"><a href="#cb57-427" aria-hidden="true" tabindex="-1"></a>Here the parameter values that maximize the likelihood are $\beta_0 = 40.1$ and $\beta_1=2.7$. We can also compute what the standard deviation for the residual distributions was using the estimated parameter values. Remember, this value is an estimate of the RMSE.</span>
<span id="cb57-428"><a href="#cb57-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-431"><a href="#cb57-431" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-432"><a href="#cb57-432" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute residuals using MLE estimate</span></span>
<span id="cb57-433"><a href="#cb57-433" aria-hidden="true" tabindex="-1"></a>errors <span class="ot">=</span> y <span class="sc">-</span> <span class="fl">40.1</span> <span class="sc">-</span> <span class="fl">2.7</span><span class="sc">*</span>x</span>
<span id="cb57-434"><a href="#cb57-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-435"><a href="#cb57-435" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute estimate of RMSE</span></span>
<span id="cb57-436"><a href="#cb57-436" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(errors)</span>
<span id="cb57-437"><a href="#cb57-437" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-438"><a href="#cb57-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-439"><a href="#cb57-439" aria-hidden="true" tabindex="-1"></a>Here the maximum likelihood estimates for our three parameters are: $\hat{\beta}_0=40.1$, $\hat{\beta}_1=2.7$, and $\hat{\sigma}_{\epsilon}=13.2$.</span>
<span id="cb57-440"><a href="#cb57-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-441"><a href="#cb57-441" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-442"><a href="#cb57-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-443"><a href="#cb57-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-444"><a href="#cb57-444" aria-hidden="true" tabindex="-1"></a><span class="fu">### Complications with Grid Search</span></span>
<span id="cb57-445"><a href="#cb57-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-446"><a href="#cb57-446" aria-hidden="true" tabindex="-1"></a>In practice, there are several issues with the grid search methods we have employed so far. The biggest is that you would not have any idea which values of $\beta_0$ and $\beta_1$ to limit the search space to. Essentially you would need to search an infinite number of values unless you could limit the search space in some way. For many common methods (e.g., linear regression) finding the ML estimates is mathematically pretty easy (if we know calculus; see the section <span class="co">[</span><span class="ot">Using Calculus to Determine the MLEs</span><span class="co">](#way-too-much-math)</span>). For more complex methods (e.g., mixed-effect models) there is not a mathematical solution. Instead, mathematics is used to help limit the search space and then a grid search is used to hone in on the estimates.</span>
<span id="cb57-447"><a href="#cb57-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-448"><a href="#cb57-448" aria-hidden="true" tabindex="-1"></a>Although not a complication, we made an assumption about the value of the residual standard error, that it was equivalent to <span class="in">`sigma(errors)`</span>. In practice, this value would also need to be estimated, along with the coefficients.</span>
<span id="cb57-449"><a href="#cb57-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-450"><a href="#cb57-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-451"><a href="#cb57-451" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-452"><a href="#cb57-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-453"><a href="#cb57-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-454"><a href="#cb57-454" aria-hidden="true" tabindex="-1"></a><span class="fu">## Estimating Regression Parameter: OLS vs. ML Estimation</span></span>
<span id="cb57-455"><a href="#cb57-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-456"><a href="#cb57-456" aria-hidden="true" tabindex="-1"></a>To compute ML estimates of the coefficients we will use the <span class="in">`mle2()`</span> function from the <span class="in">`{bbmle}`</span> package. To use the <span class="in">`mle2()`</span> function, we need to provide a user-written function that returns the *negative log-likelihood* given a set of parameter inputs. Below we adapt the function we wrote earlier to return the negative log-likelihood. Since we are also interested in estimating the residual standard error (RSE), we also include this as an input into the function and use that inputted value in the <span class="in">`dnorm()`</span> function.</span>
<span id="cb57-457"><a href="#cb57-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-458"><a href="#cb57-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-461"><a href="#cb57-461" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-462"><a href="#cb57-462" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to output the negative log-likelihood</span></span>
<span id="cb57-463"><a href="#cb57-463" aria-hidden="true" tabindex="-1"></a>neg_ll <span class="ot">=</span> <span class="cf">function</span>(b_0, b_1, rse){</span>
<span id="cb57-464"><a href="#cb57-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-465"><a href="#cb57-465" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Use the following x and y values</span></span>
<span id="cb57-466"><a href="#cb57-466" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb57-467"><a href="#cb57-467" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">53</span>, <span class="dv">56</span>, <span class="dv">37</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">36</span>, <span class="dv">22</span>, <span class="dv">75</span>, <span class="dv">37</span>, <span class="dv">42</span>)</span>
<span id="cb57-468"><a href="#cb57-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-469"><a href="#cb57-469" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the yhat and residuals based on the two input values</span></span>
<span id="cb57-470"><a href="#cb57-470" aria-hidden="true" tabindex="-1"></a>  yhats <span class="ot">=</span> b_0 <span class="sc">+</span> b_1<span class="sc">*</span>x</span>
<span id="cb57-471"><a href="#cb57-471" aria-hidden="true" tabindex="-1"></a>  errors <span class="ot">=</span> y <span class="sc">-</span> yhats</span>
<span id="cb57-472"><a href="#cb57-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-473"><a href="#cb57-473" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the negative log-likelihood</span></span>
<span id="cb57-474"><a href="#cb57-474" aria-hidden="true" tabindex="-1"></a>  neg_log_lik <span class="ot">=</span> <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">dnorm</span>(errors, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> rse, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb57-475"><a href="#cb57-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-476"><a href="#cb57-476" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Output the log-likelihood</span></span>
<span id="cb57-477"><a href="#cb57-477" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(neg_log_lik)</span>
<span id="cb57-478"><a href="#cb57-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-479"><a href="#cb57-479" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb57-480"><a href="#cb57-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-481"><a href="#cb57-481" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-482"><a href="#cb57-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-483"><a href="#cb57-483" aria-hidden="true" tabindex="-1"></a>Now we can use the <span class="in">`mle2()`</span> function to estimate the three parameters. This function requires the argument, <span class="in">`minuslogl=`</span>, which takes the user written function returning the negative log-likelihood. It also requires a list of starting values (initial guesses) for the input parameters in the user-written function.</span>
<span id="cb57-484"><a href="#cb57-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-487"><a href="#cb57-487" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-488"><a href="#cb57-488" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb57-489"><a href="#cb57-489" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bbmle)</span>
<span id="cb57-490"><a href="#cb57-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-491"><a href="#cb57-491" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model using ML</span></span>
<span id="cb57-492"><a href="#cb57-492" aria-hidden="true" tabindex="-1"></a>mle.results <span class="ot">=</span> <span class="fu">mle2</span>(<span class="at">minuslogl =</span> neg_ll, <span class="at">start =</span> <span class="fu">list</span>(<span class="at">b_0 =</span> <span class="fl">20.0</span>, <span class="at">b_1 =</span> <span class="fl">5.0</span>, <span class="at">rse =</span> <span class="dv">10</span>))</span>
<span id="cb57-493"><a href="#cb57-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-494"><a href="#cb57-494" aria-hidden="true" tabindex="-1"></a><span class="co"># View results</span></span>
<span id="cb57-495"><a href="#cb57-495" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mle.results)</span>
<span id="cb57-496"><a href="#cb57-496" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-497"><a href="#cb57-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-498"><a href="#cb57-498" aria-hidden="true" tabindex="-1"></a>We also obtain the OLS estimates:</span>
<span id="cb57-499"><a href="#cb57-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-502"><a href="#cb57-502" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-503"><a href="#cb57-503" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data</span></span>
<span id="cb57-504"><a href="#cb57-504" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb57-505"><a href="#cb57-505" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">53</span>, <span class="dv">56</span>, <span class="dv">37</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">36</span>, <span class="dv">22</span>, <span class="dv">75</span>, <span class="dv">37</span>, <span class="dv">42</span>)</span>
<span id="cb57-506"><a href="#cb57-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-507"><a href="#cb57-507" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model with OLS</span></span>
<span id="cb57-508"><a href="#cb57-508" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x)</span>
<span id="cb57-509"><a href="#cb57-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-510"><a href="#cb57-510" aria-hidden="true" tabindex="-1"></a><span class="co"># Get estimates</span></span>
<span id="cb57-511"><a href="#cb57-511" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(lm<span class="fl">.1</span>)</span>
<span id="cb57-512"><a href="#cb57-512" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(lm<span class="fl">.1</span>)</span>
<span id="cb57-513"><a href="#cb57-513" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-514"><a href="#cb57-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-515"><a href="#cb57-515" aria-hidden="true" tabindex="-1"></a>Both sets of parameter estimates are presented in @tbl-compare-ests. </span>
<span id="cb57-516"><a href="#cb57-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-517"><a href="#cb57-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-520"><a href="#cb57-520" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-521"><a href="#cb57-521" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-compare-ests</span></span>
<span id="cb57-522"><a href="#cb57-522" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Parameter estimates using maximum likelihood (ML) and ordinary least squares (OLS) estimation."</span></span>
<span id="cb57-523"><a href="#cb57-523" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb57-524"><a href="#cb57-524" aria-hidden="true" tabindex="-1"></a><span class="co"># create toy data</span></span>
<span id="cb57-525"><a href="#cb57-525" aria-hidden="true" tabindex="-1"></a>estimates <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb57-526"><a href="#cb57-526" aria-hidden="true" tabindex="-1"></a>  <span class="at">Estimate =</span> <span class="fu">c</span>(<span class="st">"$$</span><span class="sc">\\</span><span class="st">hat{</span><span class="sc">\\</span><span class="st">beta}_0$$"</span>, <span class="st">"$$</span><span class="sc">\\</span><span class="st">hat{</span><span class="sc">\\</span><span class="st">beta}_1$$"</span>, <span class="st">"$$</span><span class="sc">\\</span><span class="st">hat{</span><span class="sc">\\</span><span class="st">sigma}^2_{</span><span class="sc">\\</span><span class="st">epsilon}$$"</span>),</span>
<span id="cb57-527"><a href="#cb57-527" aria-hidden="true" tabindex="-1"></a>  <span class="at">ML =</span> <span class="fu">c</span>(<span class="fl">40.01</span>, <span class="fl">2.74</span>, <span class="fl">12.51</span>),</span>
<span id="cb57-528"><a href="#cb57-528" aria-hidden="true" tabindex="-1"></a>  <span class="at">OLS =</span> <span class="fu">c</span>(<span class="fl">40.01</span>, <span class="fl">2.74</span>, <span class="fl">13.99</span>)</span>
<span id="cb57-529"><a href="#cb57-529" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb57-530"><a href="#cb57-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-531"><a href="#cb57-531" aria-hidden="true" tabindex="-1"></a><span class="co"># Create table</span></span>
<span id="cb57-532"><a href="#cb57-532" aria-hidden="true" tabindex="-1"></a>estimates <span class="sc">|&gt;</span></span>
<span id="cb57-533"><a href="#cb57-533" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>() <span class="sc">|&gt;</span></span>
<span id="cb57-534"><a href="#cb57-534" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cols_align</span>(</span>
<span id="cb57-535"><a href="#cb57-535" aria-hidden="true" tabindex="-1"></a>    <span class="at">columns =</span> <span class="fu">c</span>(Estimate, ML, OLS),</span>
<span id="cb57-536"><a href="#cb57-536" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="st">"center"</span></span>
<span id="cb57-537"><a href="#cb57-537" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb57-538"><a href="#cb57-538" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_options</span>(</span>
<span id="cb57-539"><a href="#cb57-539" aria-hidden="true" tabindex="-1"></a>   <span class="at">table.width =</span> <span class="fu">pct</span>(<span class="dv">40</span>) </span>
<span id="cb57-540"><a href="#cb57-540" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb57-541"><a href="#cb57-541" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-542"><a href="#cb57-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-543"><a href="#cb57-543" aria-hidden="true" tabindex="-1"></a>Comparing the coefficient estimates ($\hat\beta_0$ and $\hat\beta_1$) to those obtained through ordinary least squares, we find they are quite similar. The estimate of the residual standard error ($\sigma_{\epsilon}$), however, differs between the two estimation methods (although they are somewhat close in value).</span>
<span id="cb57-544"><a href="#cb57-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-545"><a href="#cb57-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-546"><a href="#cb57-546" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-547"><a href="#cb57-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-548"><a href="#cb57-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-549"><a href="#cb57-549" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimating the Residual Variation: Maximum Likelihood vs. Ordinary Least Squares</span></span>
<span id="cb57-550"><a href="#cb57-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-551"><a href="#cb57-551" aria-hidden="true" tabindex="-1"></a>The estimates of the residual standard error differ because the two estimation methods use different criteria to optimize over; OLS estimation finds the estimates that minimize the sum of squared errors, and ML finds the estimates that maximize the likelihood. Because of the differences, it is important to report how the model was estimated in any publication.</span>
<span id="cb57-552"><a href="#cb57-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-553"><a href="#cb57-553" aria-hidden="true" tabindex="-1"></a>Both estimation methods have been well studied, and the resulting residual standard error from these estimation methods can be computed directly once we have the coefficient estimates (which are the same for both methods). Namely, the residual standard error resulting from OLS estimation is:</span>
<span id="cb57-554"><a href="#cb57-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-555"><a href="#cb57-555" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-556"><a href="#cb57-556" aria-hidden="true" tabindex="-1"></a>\hat\sigma_{\epsilon}= \sqrt{\frac{\left(Y_i - \hat{Y}_i\right)^2}{n-p-1}}</span>
<span id="cb57-557"><a href="#cb57-557" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-558"><a href="#cb57-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-559"><a href="#cb57-559" aria-hidden="true" tabindex="-1"></a>where *p* is the number of predictors in the model. And the residual standard error resulting from ML estimation is:</span>
<span id="cb57-560"><a href="#cb57-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-561"><a href="#cb57-561" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-562"><a href="#cb57-562" aria-hidden="true" tabindex="-1"></a>\hat\sigma_{\epsilon}=\sqrt{\frac{\left(Y_i - \hat{Y}_i\right)^2}{n}},</span>
<span id="cb57-563"><a href="#cb57-563" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-564"><a href="#cb57-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-565"><a href="#cb57-565" aria-hidden="true" tabindex="-1"></a>The smaller denominator from the OLS estimate produces a higher overall estimate of the residual variation (more uncertainty). When *n* is large, the differences between the OLS and ML  estimates of the residual standard error are minimal and can safely be ignored. When *n* is small, however, these differences can impact statistical results. For example, since the residual standard error is used to compute the standard error estimates for the coefficients, the choice of ML or OLS will have an effect on the size of the *t*- and *p*-values for the coefficients. (In practice, it is rare to see the different estimation methods producing substantively different findings, especially when fitting general linear models.)</span>
<span id="cb57-566"><a href="#cb57-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-567"><a href="#cb57-567" aria-hidden="true" tabindex="-1"></a>Lastly, we note that the value of log-likelihood is the same for both the ML and OLS estimated models. The result from the ML output was:</span>
<span id="cb57-568"><a href="#cb57-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-569"><a href="#cb57-569" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-570"><a href="#cb57-570" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb57-571"><a href="#cb57-571" aria-hidden="true" tabindex="-1"></a>-2 \ln(\mathrm{Likelihood}) &amp;= 78.91 <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb57-572"><a href="#cb57-572" aria-hidden="true" tabindex="-1"></a>\ln(\mathrm{Likelihood}) &amp;= -39.45</span>
<span id="cb57-573"><a href="#cb57-573" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb57-574"><a href="#cb57-574" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-575"><a href="#cb57-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-576"><a href="#cb57-576" aria-hidden="true" tabindex="-1"></a>The log-likelihood for the OLS estimated model is:</span>
<span id="cb57-577"><a href="#cb57-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-580"><a href="#cb57-580" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-581"><a href="#cb57-581" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-likelihood for OLS model</span></span>
<span id="cb57-582"><a href="#cb57-582" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(<span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x))</span>
<span id="cb57-583"><a href="#cb57-583" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-584"><a href="#cb57-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-585"><a href="#cb57-585" aria-hidden="true" tabindex="-1"></a>This is a very useful result. It allows us to use <span class="in">`lm()`</span> to estimate the coefficients from a model and then use its log-likelihood value in the same way as if we had fitted the model using ML. This will be helpful when we compute measure such as information criteria later in the course.</span>
<span id="cb57-586"><a href="#cb57-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-587"><a href="#cb57-587" aria-hidden="true" tabindex="-1"></a>:::note</span>
<span id="cb57-588"><a href="#cb57-588" aria-hidden="true" tabindex="-1"></a>In many applications of estimation, it is useful to use  a criterion which is modified variant of the likelihood. This variant omits "nuisance parameters" (parameters which are not of direct interest and subsequently not needed in the estimation method) from the computation of the likelihood. This restricted version of the likelihood is then maximized and the estimation method using this modified likelihood is called *Restricted Maximum Likelihood* (REML).</span>
<span id="cb57-589"><a href="#cb57-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-590"><a href="#cb57-590" aria-hidden="true" tabindex="-1"></a>When REML is used to estimate parameters, the residual standard error turns out to be the same as that computed in the OLS estimation. As such, sometimes this estimate is referred to as the REML estimate of the residual standard error.</span>
<span id="cb57-591"><a href="#cb57-591" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb57-592"><a href="#cb57-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-593"><a href="#cb57-593" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-594"><a href="#cb57-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-595"><a href="#cb57-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-596"><a href="#cb57-596" aria-hidden="true" tabindex="-1"></a>:::mathnote</span>
<span id="cb57-597"><a href="#cb57-597" aria-hidden="true" tabindex="-1"></a><span class="fu">### Using Calculus to Determine the MLEs {#way-too-much-math}</span></span>
<span id="cb57-598"><a href="#cb57-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-599"><a href="#cb57-599" aria-hidden="true" tabindex="-1"></a>A more convenient method to determine the ML estimates of the regression parameters is to use mathematics; specifically calculus. Remember, we can express the likelihood of the regression residuals mathematically as:</span>
<span id="cb57-600"><a href="#cb57-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-601"><a href="#cb57-601" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-602"><a href="#cb57-602" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) = p(\epsilon_1) \times p(\epsilon_2) \times \ldots \times p(\epsilon_n)</span>
<span id="cb57-603"><a href="#cb57-603" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-604"><a href="#cb57-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-605"><a href="#cb57-605" aria-hidden="true" tabindex="-1"></a>where the probability density of each residual (assuming normality) is:</span>
<span id="cb57-606"><a href="#cb57-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-607"><a href="#cb57-607" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-608"><a href="#cb57-608" aria-hidden="true" tabindex="-1"></a>p(\epsilon_i) = \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left<span class="co">[</span><span class="ot">-\frac{(\epsilon_i-\mu)^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span></span>
<span id="cb57-609"><a href="#cb57-609" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-610"><a href="#cb57-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-611"><a href="#cb57-611" aria-hidden="true" tabindex="-1"></a>In addition to normality, which gives us the equation to compute the PDF for each residual, the regression assumptions also specify that each conditional error distribution has a mean of 0 and some variance (that is the same for all conditional error distributions). We can call it $\sigma^2_{\epsilon}$. Substituting these values into the density function, we get,</span>
<span id="cb57-612"><a href="#cb57-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-613"><a href="#cb57-613" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-614"><a href="#cb57-614" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb57-615"><a href="#cb57-615" aria-hidden="true" tabindex="-1"></a>p(\epsilon_i) &amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left<span class="co">[</span><span class="ot">-\frac{(\epsilon_i-0)^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb57-616"><a href="#cb57-616" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left<span class="co">[</span><span class="ot">-\frac{(\epsilon_i)^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span></span>
<span id="cb57-617"><a href="#cb57-617" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb57-618"><a href="#cb57-618" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-619"><a href="#cb57-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-620"><a href="#cb57-620" aria-hidden="true" tabindex="-1"></a>Now we substitute this expression for each of the $p(\epsilon_i)$ values in the likelihood computation.</span>
<span id="cb57-621"><a href="#cb57-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-622"><a href="#cb57-622" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-623"><a href="#cb57-623" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb57-624"><a href="#cb57-624" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) &amp;= p(\epsilon_1) \times p(\epsilon_2) \times \ldots \times p(\epsilon_n) <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb57-625"><a href="#cb57-625" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_1</span>
<span id="cb57-626"><a href="#cb57-626" aria-hidden="true" tabindex="-1"></a>^2}{2\sigma^2_{\epsilon}}\right] \times \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \times \ldots \times<span class="sc">\\</span> &amp;~~~~\frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span></span>
<span id="cb57-627"><a href="#cb57-627" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb57-628"><a href="#cb57-628" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-629"><a href="#cb57-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-630"><a href="#cb57-630" aria-hidden="true" tabindex="-1"></a>We can simplify this:</span>
<span id="cb57-631"><a href="#cb57-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-632"><a href="#cb57-632" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-633"><a href="#cb57-633" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb57-634"><a href="#cb57-634" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) = &amp;\left<span class="co">[</span><span class="ot"> \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right</span><span class="co">]</span>^n \times \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_1^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \times \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \times \ldots \times <span class="sc">\\</span></span>
<span id="cb57-635"><a href="#cb57-635" aria-hidden="true" tabindex="-1"></a>&amp;\exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span></span>
<span id="cb57-636"><a href="#cb57-636" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb57-637"><a href="#cb57-637" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-638"><a href="#cb57-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-639"><a href="#cb57-639" aria-hidden="true" tabindex="-1"></a>Now we will take the natural logarithm of both sides of the expression:</span>
<span id="cb57-640"><a href="#cb57-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-641"><a href="#cb57-641" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-642"><a href="#cb57-642" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb57-643"><a href="#cb57-643" aria-hidden="true" tabindex="-1"></a>\ln \Bigl(\mathcal{L}(\beta_0, \beta_1 | \mathrm{data})\Bigr) = &amp;\ln \Biggl( \left<span class="co">[</span><span class="ot"> \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right</span><span class="co">]</span>^n \times \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_1^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \times \exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \times \ldots \times <span class="sc">\\</span> </span>
<span id="cb57-644"><a href="#cb57-644" aria-hidden="true" tabindex="-1"></a>&amp;\exp\left<span class="co">[</span><span class="ot">-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right</span><span class="co">]</span> \Biggr)</span>
<span id="cb57-645"><a href="#cb57-645" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb57-646"><a href="#cb57-646" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-647"><a href="#cb57-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-648"><a href="#cb57-648" aria-hidden="true" tabindex="-1"></a>Using our rules for logarithms and re-arranging the terms gives us,</span>
<span id="cb57-649"><a href="#cb57-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-650"><a href="#cb57-650" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-651"><a href="#cb57-651" aria-hidden="true" tabindex="-1"></a>\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = -\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \epsilon_i^2</span>
<span id="cb57-652"><a href="#cb57-652" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-653"><a href="#cb57-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-654"><a href="#cb57-654" aria-hidden="true" tabindex="-1"></a>Examining this equation, we see that the log-likelihood is a function of *n*, $\sigma^2_{\epsilon}$ and the sum of squared residuals (SSR). The observed data define *n* (the sample size) and the other two components come from the residuals, which are a function of the parameters and the data.</span>
<span id="cb57-655"><a href="#cb57-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-656"><a href="#cb57-656" aria-hidden="true" tabindex="-1"></a>Once we have this function, calculus can be used to find the analytic maximum. Typically before we do this, we replace $\epsilon_i$ with $Y_i - \hat\beta_0 - \hat\beta_1(X_i)$; writing the residuals as a function of the parameters (which we are solving for) and the data.</span>
<span id="cb57-657"><a href="#cb57-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-658"><a href="#cb57-658" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-659"><a href="#cb57-659" aria-hidden="true" tabindex="-1"></a>\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = -\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2</span>
<span id="cb57-660"><a href="#cb57-660" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-661"><a href="#cb57-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-662"><a href="#cb57-662" aria-hidden="true" tabindex="-1"></a>In optimization, maximizing the log-likelihood is mathematically equivalent to minimizing the negative log-likelihood. (Note, this is what the <span class="in">`mle2()`</span> function is doing.) That means we could also optimize over:</span>
<span id="cb57-663"><a href="#cb57-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-664"><a href="#cb57-664" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-665"><a href="#cb57-665" aria-hidden="true" tabindex="-1"></a>-\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = \frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{2\sigma^2_{\epsilon}} \times \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2</span>
<span id="cb57-666"><a href="#cb57-666" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-667"><a href="#cb57-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-668"><a href="#cb57-668" aria-hidden="true" tabindex="-1"></a>This has the advantage that we are removing the negative signs on the right-hand side of the equation. To find the analytic minimum (or maximum), we compute the partial derivatives *with respect to* $\hat\beta_0$, $\hat\beta_1$, and $\hat\sigma^2_{\epsilon}$, and set these equal to zero and solve for each of the three parameters, respectively. That is:</span>
<span id="cb57-669"><a href="#cb57-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-670"><a href="#cb57-670" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-671"><a href="#cb57-671" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb57-672"><a href="#cb57-672" aria-hidden="true" tabindex="-1"></a>\frac{\partial}{\partial \beta_0} \bigg<span class="co">[</span><span class="ot">\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{2\sigma^2_{\epsilon}} \times \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2\bigg</span><span class="co">]</span> &amp;= 0 <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb57-673"><a href="#cb57-673" aria-hidden="true" tabindex="-1"></a>\frac{\partial}{\partial \beta_1} \bigg<span class="co">[</span><span class="ot">\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{2\sigma^2_{\epsilon}} \times \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2\bigg</span><span class="co">]</span> &amp;= 0 <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb57-674"><a href="#cb57-674" aria-hidden="true" tabindex="-1"></a>\frac{\partial}{\partial \sigma^2_{\epsilon}} \bigg<span class="co">[</span><span class="ot">\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{2\sigma^2_{\epsilon}} \times \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2\bigg</span><span class="co">]</span> &amp;= 0</span>
<span id="cb57-675"><a href="#cb57-675" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb57-676"><a href="#cb57-676" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-677"><a href="#cb57-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-678"><a href="#cb57-678" aria-hidden="true" tabindex="-1"></a>Within each partial derivative, the parameters that are not being partialled can be treated as constants, which often makes the derivative easier to solve. For example in the first two partial derivatives the residual variance can be treated as a mathematical constant. Since all constant terms can be removed from the derivative, this leads to an interesting result:</span>
<span id="cb57-679"><a href="#cb57-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-680"><a href="#cb57-680" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-681"><a href="#cb57-681" aria-hidden="true" tabindex="-1"></a>\frac{\partial}{\partial \boldsymbol{\beta}} \bigg<span class="co">[</span><span class="ot"> -\mathcal{l}(\beta_0, \beta_1 | \mathrm{data})\bigg</span><span class="co">]</span> = \frac{\partial}{\partial \boldsymbol{\beta}} \bigg<span class="co">[</span><span class="ot"> \sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2 \bigg</span><span class="co">]</span></span>
<span id="cb57-682"><a href="#cb57-682" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-683"><a href="#cb57-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-684"><a href="#cb57-684" aria-hidden="true" tabindex="-1"></a>This means that minimizing the negative log-likelihood is equivalent to minimizing the sum of squared residuals! This implies that the coefficients we get for OLS and ML estimation are the same.</span>
<span id="cb57-685"><a href="#cb57-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-686"><a href="#cb57-686" aria-hidden="true" tabindex="-1"></a>When we solve the third partial derivative for the residual standard error, we find that:</span>
<span id="cb57-687"><a href="#cb57-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-688"><a href="#cb57-688" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-689"><a href="#cb57-689" aria-hidden="true" tabindex="-1"></a>\sigma^2_{\epsilon} = \frac{\sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2}{n}</span>
<span id="cb57-690"><a href="#cb57-690" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-691"><a href="#cb57-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-692"><a href="#cb57-692" aria-hidden="true" tabindex="-1"></a>That is, the residual variance is equal to the sum of squared residuals divided by the sample size. In OLS estimation, the residual variance is the sum of squared residuals divided by the error degrees of freedom for the model. In the simple regression model the residual variance estimated using OLS would be:</span>
<span id="cb57-693"><a href="#cb57-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-694"><a href="#cb57-694" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-695"><a href="#cb57-695" aria-hidden="true" tabindex="-1"></a>\sigma^2_{\epsilon} = \frac{\sum \bigg(Y_i - \beta_0 - \beta_1(X_i)\bigg)^2}{n-2}</span>
<span id="cb57-696"><a href="#cb57-696" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-697"><a href="#cb57-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-698"><a href="#cb57-698" aria-hidden="true" tabindex="-1"></a>This is why the residual standard errors were different when we used OLS and ML to carry out the estimation; the criteria we are optimizing over (sum of squared residuals vs. log-likelihood) impact the value of the residual variance estimate. Again, when *n* is large, the estimation method does not make a difference (i.e., $n \approx n-2$).</span>
<span id="cb57-699"><a href="#cb57-699" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb57-700"><a href="#cb57-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-701"><a href="#cb57-701" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb57-702"><a href="#cb57-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-703"><a href="#cb57-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-704"><a href="#cb57-704" aria-hidden="true" tabindex="-1"></a><span class="fu">## References</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>