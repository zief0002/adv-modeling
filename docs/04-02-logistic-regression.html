<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>14&nbsp; Logistic Regression – Advanced Modeling and Reproducibility for Educational Scientists</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./04-03-more-logistic-regression.html" rel="next">
<link href="./04-01-linear-probability-model.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed04999718f06b735b1f8009dce43b94.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7c121de436c7c20b050f1da4c0bef0bb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="assets/sticky-notes.css">
<link rel="stylesheet" href="assets/table-styles.css">
</head>

<body class="nav-sidebar floating fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04-00-modeling-dichotomous-outcomes.html">Modeling Dichotomous Outcomes</a></li><li class="breadcrumb-item"><a href="./04-02-logistic-regression.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Logistic Regression</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Advanced Modeling and Reproducibility for Educational Scientists</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Front Matter</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./01-00-reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Statistical Reproducibility</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-02-project-organization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Project Organization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-03-introduction-to-quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-04-more-quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">More Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-05-creating-tables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Creating Tables with gt</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./02-00-likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Likelihood</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-01-mathematical-foundations-probability-density.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Mathematical Foundations: Probability Density</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-03-likelihood-framework-for-evidence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Evidence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-04-likelihood-framework-for-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Likelihood: A Framework for Estimation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./03-00-modeling-nonlinearity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling Nonlinearity</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-01-polynomial-effects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Polynomial Effects</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-02-information-criteria-and-model-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Information Criteria and Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-03-logarithmic-transformations-predictor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Log-Transforming the Predictor</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-04-logarithmic-transformations-outcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Log-Transforming the Outcome</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-05-rule-of-the-bulge.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Rule of the Bulge—An Example”</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./04-00-modeling-dichotomous-outcomes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling Dichotomous Outcomes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-01-linear-probability-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Linear Probability Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-02-logistic-regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-03-more-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">More Logistic Regression</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./05-00-modeling-nonindependence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling Nonindependence</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-01-introduction-to-mixed-effects-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction to Mixed-Effects Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-02-lmer-average-change-over-time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">LMER: Average Change Over Time</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-03-lmer-other-random-effects-and-covariates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">LMER: Other Random-Effects and Covariates</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-04-lmer-alt-representations-and-assumptions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">LMER: Alternative Representations and Assumptions</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04-00-modeling-dichotomous-outcomes.html">Modeling Dichotomous Outcomes</a></li><li class="breadcrumb-item"><a href="./04-02-logistic-regression.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Logistic Regression</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Logistic Regression</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Quarto Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="preparation" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="preparation"><span class="header-section-number">14.1</span> Preparation</h2>
<p>In this chapter, you will learn how to use logistic regression models to model dichotomous categorical outcome variables (e.g., dummy coded outcome). We will use data from the file <em>graduation.csv</em> to explore predictors of college graduation.</p>
<ul>
<li><a href="https://raw.githubusercontent.com/zief0002/fluffy-ants/main/data/graduation.csv">CSV File</a></li>
<li><a href="http://zief0002.github.io/fluffy-ants/codebooks/graduation.html">Data Codebook</a></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AICcmodavg)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrr)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(performance)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in data and create dummy variable for outcome</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>grad <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="at">file =</span> <span class="st">"https://raw.githubusercontent.com/zief0002/fluffy-ants/main/data/graduation.csv"</span>) <span class="sc">|&gt;</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">got_degree =</span> <span class="fu">if_else</span>(degree <span class="sc">==</span> <span class="st">"Yes"</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2,344 × 8
   student degree   act scholarship ap_courses first_gen non_traditional
     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;          
 1       1 Yes       21         0            0 No        No             
 2       2 Yes       19         0            0 No        No             
 3       3 Yes       27         0            0 Yes       No             
 4       4 Yes       25         0.5          0 Yes       No             
 5       5 No        28         0           17 Yes       No             
 6       6 Yes       21         0            0 No        Yes            
 7       7 Yes       27         0            8 Yes       No             
 8       8 No        20         0            0 No        No             
 9       9 Yes       26         0            0 Yes       No             
10      10 Yes       25         0            4 Yes       No             
# ℹ 2,334 more rows
# ℹ 1 more variable: got_degree &lt;dbl&gt;</code></pre>
</div>
</div>
<p>We will also examine the empirical proportions of students who obtain a degree at different ACT scores to remind us about the relationship we will be modeling.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain the proportion who obtain a degree for each ACT score</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>prop_grad <span class="ot">=</span> grad <span class="sc">|&gt;</span> </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(act, degree) <span class="sc">|&gt;</span> </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">N =</span> <span class="fu">n</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">Prop =</span> N <span class="sc">/</span> <span class="fu">sum</span> (N)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">|&gt;</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(degree <span class="sc">==</span> <span class="st">"Yes"</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatterplot</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> prop_grad, <span class="fu">aes</span>(<span class="at">x =</span> act, <span class="at">y =</span> Prop)) <span class="sc">+</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">size =</span> N)) <span class="sc">+</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">weight =</span> N), <span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"ACT score"</span>) <span class="sc">+</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Proportion who obtained a degree"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-scatterplot-proportion" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Proportion of students who obtain a degree conditional on ACT score. Size of the dot is proportional to sample size. The loess smoother is based on the raw data." data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scatterplot-proportion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="04-02-logistic-regression_files/figure-html/fig-scatterplot-proportion-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%" alt="Proportion of students who obtain a degree conditional on ACT score. Size of the dot is proportional to sample size. The loess smoother is based on the raw data.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scatterplot-proportion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.1: Proportion of students who obtain a degree conditional on ACT score. Size of the dot is proportional to sample size. The loess smoother is based on the raw data.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Because the sample sizes differs across ACT scores, we need to account for that by weighting the loess smoother. To do this we include <code>aes(weight=)</code> in the <code>geom_smooth()</code> layer.</p>
<p>In the last set of notes, we saw that using the linear probability model leads to direct violations of the linear model’s assumptions. If that isn’t problematic enough, it is possible to run into severe issues when we make predictions. For example, given the constant effect of <em>X</em> in these models it is possible to have an <em>X</em> value that results in a predicted proportion that is either greater than 1 or less than 0. This is a problem since proportions are constrained to the range of <span class="math inline">\(\left[0,~1\right]\)</span>.</p>
<p><br></p>
</section>
<section id="alternative-models-to-the-linear-probability-model" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="alternative-models-to-the-linear-probability-model"><span class="header-section-number">14.2</span> Alternative Models to the Linear Probability Model</h2>
<p>Many of the non-linear models that are typically used to model dichotomous outcome data are “S”-shaped models. Below is a plot of one-such “S”-shaped model.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-s-shape" class="quarto-float quarto-figure quarto-figure-center anchored" alt="An 'S'-shaped model." data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s-shape-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="04-02-logistic-regression_files/figure-html/fig-s-shape-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%" alt="An 'S'-shaped model.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s-shape-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.2: An ‘S’-shaped model.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The non-linear “S”-shaped model has many attractive features. First, the predicted proportions (<span class="math inline">\(\pi_i\)</span>) are bounded between 0 and 1. Furthermore, as <em>X</em> gets smaller, <span class="math inline">\(\pi_i\)</span> approaches 0 at a slower rate. Similarly, as <em>X</em> gets larger, <span class="math inline">\(\pi_i\)</span> approaches 1 at a slower rate. Lastly, this model curve is monotonic; smaller values of <em>X</em> are associated with smaller predicted proportions and larger values of <em>X</em> are associated with larger predicted proportions. (Or, if the “S” were backwards, smaller values of <em>X</em> are associated with larger predicted proportions and larger values of <em>X</em> would be associated with smaller predicted proportions). The key is that there are no bends in the curve; it is always growing or always decreasing.</p>
<p>In our student example, the empirical data maps well to this curve. Higher ACT scores are associated with a higher proportion of students who obtain a degree (monotonic). The effect of ACT, however, is not constant, and seems to diminish at higher ACT scores. Lastly, we want to bound the proportion who obtain a degree at every ACT score to lie between 0 and 1.</p>
<p><br></p>
<section id="a-transformation-to-fit-the-s-shaped-curve" class="level3" data-number="14.2.1">
<h3 data-number="14.2.1" class="anchored" data-anchor-id="a-transformation-to-fit-the-s-shaped-curve"><span class="header-section-number">14.2.1</span> A Transformation to Fit the “S”-shaped Curve</h3>
<p>We need to identify a mathematical function that relates <em>X</em> to <em>Y</em> in such a way that we produce this “S”-shaped curve. To do this we apply a transformation function, call it <span class="math inline">\(\Lambda\)</span> (Lambda), that fits the criteria for such a function (monotonic, nonlinear, maps to <span class="math inline">\([0,~1]\)</span> space). There are several mathematical functions that do this. One commonly used function that meets these specifications is the <strong>logistic function</strong>. Mathematically, the logistic function is:</p>
<p><span class="math display">\[
\Lambda(x) = \frac{1}{1 + e^{-x}}
\]</span></p>
<p>where <em>x</em> is the value fed into the logistic function. For example, to logistically transform <span class="math inline">\(x=3\)</span>, we use</p>
<p><span class="math display">\[
\begin{split}
\Lambda(3) &amp;= \frac{1}{1 + e^{-3}} \\[1ex]
&amp;= 0.953
\end{split}
\]</span></p>
<p>Below we show how to transform many such values using R.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create w values and transformed values</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>example <span class="ot">=</span> <span class="fu">tibble</span>(</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">4</span>, <span class="at">to =</span> <span class="dv">4</span>, <span class="at">by =</span> <span class="fl">0.01</span>)  <span class="co"># Set up values</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">Lambda =</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>x))  <span class="co"># Transform using logistic function</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>example</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 801 × 2
       x Lambda
   &lt;dbl&gt;  &lt;dbl&gt;
 1 -4    0.0180
 2 -3.99 0.0182
 3 -3.98 0.0183
 4 -3.97 0.0185
 5 -3.96 0.0187
 6 -3.95 0.0189
 7 -3.94 0.0191
 8 -3.93 0.0193
 9 -3.92 0.0195
10 -3.91 0.0196
# ℹ 791 more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> example, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> Lambda)) <span class="sc">+</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-logistic" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Plot of the logistically transformed values for a sequence of values from -4 to 4." data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-logistic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="04-02-logistic-regression_files/figure-html/fig-logistic-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%" alt="Plot of the logistically transformed values for a sequence of values from -4 to 4.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-logistic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.3: Plot of the logistically transformed values for a sequence of values from -4 to 4.
</figcaption>
</figure>
</div>
</div>
</div>
<p>You can see that by using this transformation we get a monotonic “S”-shaped curve. Now try substituting a really large value of <em>x</em> into the function. This gives an asymptote at 1. Also substitute a really “large”” negative value in for <em>x</em>. This gives an asymptote at 0. So this function also bounds the output between 0 and 1.</p>
<p><br></p>
</section>
</section>
<section id="using-the-logistic-function-in-regression" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="using-the-logistic-function-in-regression"><span class="header-section-number">14.3</span> Using the Logistic Function in Regression</h2>
<p>How does this work in a regression? There, we are relating the <em>predicted values</em>, that is, the <span class="math inline">\(\beta_0 + \beta_1(X_i)\)</span> values, to the probability of <em>Y</em>. So we need to apply the “S”-shaped logistic transformation to convert those predicted values:</p>
<p><span class="math display">\[
\pi_i = \Lambda\bigg[\beta_0 + \beta_1(X_i)\bigg]
\]</span></p>
<p>Substituting the predicted equation into the logistic transformation, we get:</p>
<p><span class="math display">\[
\pi_i = \frac{1}{1 + e^{-\big[\beta_0 + \beta_1(X_i)\big]}}
\]</span></p>
<p>Since we took a linear model (<span class="math inline">\(\beta_0 + \beta_1(X_i)\)</span>) and applied a logistic transformation, we refer to the resulting model as the <strong>linear logistic model</strong> or more simply, the <strong>logistic model</strong>.</p>
<p><br></p>
<section id="re-expressing-a-logistic-transformation" class="level3" data-number="14.3.1">
<h3 data-number="14.3.1" class="anchored" data-anchor-id="re-expressing-a-logistic-transformation"><span class="header-section-number">14.3.1</span> Re-Expressing a Logistic Transformation</h3>
<p>The logistic model expresses the proportion of 1s (<span class="math inline">\(\pi_i\)</span>) as a function of the predictor <span class="math inline">\(X\)</span>. It can be mathematically expressed as:</p>
<p><span class="math display">\[
\pi_i = \frac{1}{1 + e^{-\big[\beta_0 + \beta_1(X_i)\big]}}
\]</span></p>
<p>We can re-express this using algebra and rules of logarithms.</p>
<p><span class="math display">\[
\begin{split}
\pi_i &amp;= \frac{1}{1 + e^{-\big[\beta_0 + \beta_1(X_i)\big]}} \\[2ex]
\pi_i \times (1 + e^{-\big[\beta_0 + \beta_1(X_i)\big]} ) &amp;= 1 \\[2ex]
\pi_i + \pi_i(e^{-\big[\beta_0 + \beta_1(X_i)\big]}) &amp;= 1 \\[2ex]
\pi_i(e^{-\big[\beta_0 + \beta_1(X_i)\big]}) &amp;= 1 - \pi_i \\[2ex]
e^{-\big[\beta_0 + \beta_1(X_i)\big]} &amp;= \frac{1 - \pi_i}{\pi_i} \\[2ex]
e^{\big[\beta_0 + \beta_1(X_i)\big]} &amp;= \frac{\pi_i}{1 - \pi_i} \\[2ex]
\ln \bigg(e^{\big[\beta_0 + \beta_1(X_i)\big]}\bigg) &amp;= \ln \bigg( \frac{\pi_i}{1 - \pi_i} \bigg) \\[2ex]
\beta_0 + \beta_1(X_i) &amp;= \ln \bigg( \frac{\pi_i}{1 - \pi_i}\bigg)
\end{split}
\]</span></p>
<p>Or,</p>
<p><span class="math display">\[
\ln \bigg( \frac{\pi_i}{1 - \pi_i}\bigg) = \beta_0 + \beta_1(X_i)
\]</span></p>
<div class="fyi">
<p><strong>FYI</strong></p>
<p>The logistic model expresses the natural logarithm of <span class="math inline">\(\frac{\pi_i}{1 - \pi_i}\)</span> as a linear function of <em>X</em>. Note that there is no error term on this model. This is because the model is for the mean structure only (the proportions), we are not modeling the actual <span class="math inline">\(Y_i\)</span> values (i.e., the 0s and 1s) with the logistic regression model.</p>
</div>
<p><br></p>
</section>
</section>
<section id="odds-a-ratio-of-probabilities" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="odds-a-ratio-of-probabilities"><span class="header-section-number">14.4</span> Odds: A Ratio of Probabilities</h2>
<p>The ratio that we are taking the logarithm of, <span class="math inline">\(\frac{\pi_i}{1 - \pi_i}\)</span>, is referred to as <em>odds</em>. Odds are the ratio of two probabilities. Namely the chance an event occurs (<span class="math inline">\(\pi_i\)</span>) versus the chance that same event does not occur (<span class="math inline">\(1 - \pi_i\)</span>). As such, it gives the <em>relative probability</em> of that event occurring. To understand this better, we will look at a couple examples.</p>
<p>Let’s assume that the probability of getting an “A” in a course is 0.7. Then we know the probability of NOT getting an “A” in that course is 0.3. The odds of getting an “A” are then</p>
<p><span class="math display">\[
\mathrm{Odds} = \frac{0.7}{0.3} = 2.33
\]</span></p>
<p>The relative probability of getting an “A” is 2.33. That is, the probability of getting an “A” in the class is 2.33 times more likely than NOT getting an “A” in the class.</p>
<p>As another example, Fivethirtyeight.com predicted on March 08, 2022 that the <a href="https://projects.fivethirtyeight.com/2022-nhl-predictions/">probability the Minnesota Wild would win the Stanley Cup was 0.02</a>. The odds of the Minnesota Wild winning the Stanley Cup is then:</p>
<p><span class="math display">\[
\mathrm{Odds} = \frac{0.02}{0.98} = 0.0204
\]</span></p>
<p>The probability that the Minnesota Wild win the Stanley Cup is 0.0204 times as likely them NOT winning the Stanley Cup. (Odds less than 1 indicate that is is more likely for an event NOT to occur than to occur. Invert the fraction to compute how much more like the event is not to occur.)</p>
<div class="fyi">
<p><strong>FYI</strong></p>
<p>In the logistic model, we are predicting the log-odds (also referred to as the <em>logit</em>. When we get these values, we typically transform the logits to odds by inverting the log-transformation (take <em>e</em> to that power.)</p>
</div>
<p><br></p>
</section>
<section id="relationship-between-x-and-different-transformations" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="relationship-between-x-and-different-transformations"><span class="header-section-number">14.5</span> Relationship between X and Different Transformations</h2>
<p>Odds are a re-expression of the probabilities, and similarly log-odds (or logits) is a transformation of the odds onto the log scale. While the logistic regression is performed on the logits of Y, like any model where we have transformed variables to work in the model, we can back-transform when we present the results. In logistic regression we can present our results in logits, odds, or probabilities. Because of the transformations, each of these will have a different relationship with the predictor.</p>
<p>For example, let’s re-examine the plot of the “S”-shaped example data. This depicted the relationship between a predictor <em>X</em> and the probability of <em>Y</em>. We could also depict the relationship between <em>X</em> and the odds of <em>Y</em>, or the relationship between <em>X</em> and the log-odds of <em>Y</em>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create odds and logit values</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>example <span class="ot">=</span> example <span class="sc">|&gt;</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">Odds =</span> Lambda <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> Lambda),  <span class="co"># Transform to odds</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">Logits =</span> <span class="fu">log</span>(Odds)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>example</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 801 × 4
       x Lambda   Odds Logits
   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
 1 -4    0.0180 0.0183  -4   
 2 -3.99 0.0182 0.0185  -3.99
 3 -3.98 0.0183 0.0187  -3.98
 4 -3.97 0.0185 0.0189  -3.97
 5 -3.96 0.0187 0.0191  -3.96
 6 -3.95 0.0189 0.0193  -3.95
 7 -3.94 0.0191 0.0194  -3.94
 8 -3.93 0.0193 0.0196  -3.93
 9 -3.92 0.0195 0.0198  -3.92
10 -3.91 0.0196 0.0200  -3.91
# ℹ 791 more rows</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># S-shaped curve (probabilities)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">=</span> <span class="fu">ggplot</span>(<span class="at">data =</span> example, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> Lambda)) <span class="sc">+</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Probabilities"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Exponential growth curve (odds)</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">=</span> <span class="fu">ggplot</span>(<span class="at">data =</span> example, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> Odds)) <span class="sc">+</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Odds"</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear (log-odds)</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">=</span> <span class="fu">ggplot</span>(<span class="at">data =</span> example, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> Logits)) <span class="sc">+</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Logits"</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Output plots</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">|</span> p2 <span class="sc">|</span> p3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-prob-odds-logits" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Plot showing the relationship between the probability of *Y* versus *X* (LEFT), the odds of *Y* versus *X* (CENTER), and the log-odds of *Y* versus *X* (RIGHT)." data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-prob-odds-logits-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="04-02-logistic-regression_files/figure-html/fig-prob-odds-logits-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%" alt="Plot showing the relationship between the probability of *Y* versus *X* (LEFT), the odds of *Y* versus *X* (CENTER), and the log-odds of *Y* versus *X* (RIGHT).">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-prob-odds-logits-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.4: Plot showing the relationship between the probability of <em>Y</em> versus <em>X</em> (LEFT), the odds of <em>Y</em> versus <em>X</em> (CENTER), and the log-odds of <em>Y</em> versus <em>X</em> (RIGHT).
</figcaption>
</figure>
</div>
</div>
</div>
<p>Note that by transforming the probabilities into odds, we have changed the “S”-shaped curve into a classic exponential growth curve. (The Rule-of-the-Bulge suggests we can “fix” this by applying a downward power transformation on <em>Y</em>.) Then, by log-transforming the <em>Y</em>-values (the odds in this case), the resulting relationship is now linear. Thus an “S”-shaped curve can be “linearized” by transforming probabilities to logits (log-odds). Mathematically, this is equivalent to applying a logistic transformation to the predicted values.</p>
<p><br></p>
</section>
<section id="binomially-distributed-errors" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="binomially-distributed-errors"><span class="header-section-number">14.6</span> Binomially Distributed Errors</h2>
<p>The logistic transformation fixed two problems: (1) the non-linearity in the conditional mean function, and (2) bounding any predicted values between 0 and 1. However, just fitting this transformation does not fix the problem of non-normality. Remember from the previous notes we learned that at each <span class="math inline">\(X_i\)</span> there were only two potential values for <span class="math inline">\(Y_i\)</span>; 0 or 1. Rather than use a normal (or Gaussian) distribution to model the conditional distribution of <span class="math inline">\(Y_i\)</span>, we will use the <em>binomial distribution</em>.</p>
<p>The binomial distribution is a discrete probability distribution that gives the probability of obtaining exactly <em>k</em> successes out of <em>n</em> Bernoulli trials (where the result of each Bernoulli trial is true with probability <span class="math inline">\(\pi\)</span> and false with probability <span class="math inline">\(1-\pi\)</span>). This is appropriate since at each ACT value of there are <span class="math inline">\(n_i\)</span> students, <em>k</em> of which obtained their degree (<span class="math inline">\(Y=1\)</span>).</p>
<p><br></p>
</section>
<section id="fitting-the-binomial-logistic-model-in-r" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="fitting-the-binomial-logistic-model-in-r"><span class="header-section-number">14.7</span> Fitting the Binomial Logistic Model in R</h2>
<p>To fit a logistic regression model with binomial errors, we use the <code>glm()</code> function.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> The syntax to fit the logistic model using <code>glm()</code> is:</p>
<p><span class="math display">\[
\mathtt{glm(} \mathrm{y} \sim \mathrm{1~+~x,~}\mathtt{data=}~\mathrm{dataframe,~}\mathtt{family~=~binomial(link~=~"logit")}
\]</span></p>
<p>The formula depicting the model and the <code>data=</code> arguments are specified in the same manner as in the <code>lm()</code> function. We also need to specify the distribution for the conditional <span class="math inline">\(Y_i\)</span> values (binomial) and the link function (logit) via the <code>family=</code> argument.</p>
<p>For our example,</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit logistic model</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>glm<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">glm</span>(got_degree <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> act, <span class="at">data =</span> grad, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The coefficients of the model can be printed using <code>coef()</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get coefficients</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(glm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)         act 
 -1.6108878   0.1075389 </code></pre>
</div>
</div>
<p>Based on this output, the fitted equation for the model is:</p>
<p><span class="math display">\[
\ln \bigg( \frac{\hat\pi_i}{1 - \hat\pi_i}\bigg) = -1.61 + 0.11(\mathrm{ACT~Score}_i)
\]</span></p>
<div class="interpret">
<p><strong>INTERPRETATION</strong></p>
<p>We interpret the coefficients in the same manner as we interpret coefficients from a linear model, with the caveat that the outcome is now in log-odds (or logits):</p>
<ul>
<li>The predicted log-odds of obtaining a degree for students with an ACT score of 0 are <span class="math inline">\(-1.61\)</span>.</li>
<li>Each one-point difference in ACT score is associated with a difference of 0.11 in the predicted log-odds of obtaining a degree, on average.</li>
</ul>
</div>
<p><br></p>
<section id="back-transforming-to-odds" class="level3" data-number="14.7.1">
<h3 data-number="14.7.1" class="anchored" data-anchor-id="back-transforming-to-odds"><span class="header-section-number">14.7.1</span> Back-Transforming to Odds</h3>
<p>For better interpretations, we can back-transform log-odds to odds. This is typically a better metric for interpretation of the coefficients. To back-transform to odds, we exponentiate both sides of the fitted equation and use the rules of exponents to simplify:</p>
<p><span class="math display">\[
\begin{split}
\ln \bigg( \frac{\hat\pi_i}{1 - \hat\pi_i}\bigg) &amp;= -1.61 + 0.11(\mathrm{ACT~Score}_i) \\[4ex]
e^{\ln \bigg( \frac{\hat\pi_i}{1 - \hat\pi_i}\bigg)} &amp;= e^{-1.61 + 0.11(\mathrm{ACT~Score}_i)} \\[2ex]
\frac{\hat\pi_i}{1 - \hat\pi_i} &amp;= e^{-1.61} \times e^{0.11(\mathrm{ACT~Score}_i)}
\end{split}
\]</span></p>
<p>When ACT score = 0, the <em>predicted odds of obtaining a degree</em> are</p>
<p><span class="math display">\[
\begin{split}
\frac{\hat\pi_i}{1 - \hat\pi_i} &amp;= e^{-1.61} \times e^{0.11(0)} \\
&amp;= e^{-1.61} \times 1 \\
&amp;= e^{-1.61} \\
&amp;= 0.2
\end{split}
\]</span></p>
<p>The odds of obtaining a degree for students with an ACT score of 0 are 0.2. That is, for these students, the probability of obtaining a degree is 0.2 times that of not obtaining a degree (Although it is extrapolating, it is far more likely these students will not obtain their degree!)</p>
<p>To interpret the effect of ACT on the odds of obtaining a degree, we will compare the odds of obtaining a degree for students that have ACT score that differ by one point. Say ACT = 0 and ACT = 1.</p>
<p>We already know the predicted odds for students with ACT = 0, namely <span class="math inline">\(e^{-1.61}\)</span>. For students with an ACT of 1, their predicted odds of obtaining a degree are:</p>
<p><span class="math display">\[
\begin{split}
\frac{\hat\pi_i}{1 - \hat\pi_i} &amp;= e^{-1.61} \times e^{0.11(1)} \\
&amp;= e^{-1.61} \times e^{0.11} \\
\end{split}
\]</span></p>
<p>These students odds of obtaining a degree are <span class="math inline">\(e^{0.11}\)</span> times greater than students with an ACT score of 0. Moreover, this increase in the odds, on average, is the case for every one-point difference in ACT score. In general,</p>
<ul>
<li>The predicted odds for <span class="math inline">\(X=0\)</span> are <span class="math inline">\(e^{\hat\beta_0}\)</span>.</li>
<li>Each one-unit difference in <span class="math inline">\(X\)</span> is associated with a <span class="math inline">\(e^{\hat\beta_1}\)</span> times increase (decrease) in the odds.</li>
</ul>
<p>We can obtain these values in R by using the <code>coef()</code> function to obtain the fitted model’s coefficients and then exponentiating them using the <code>exp()</code> function.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Exponentiate the coefficients</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">coef</span>(glm<span class="fl">.1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)         act 
  0.1997102   1.1135342 </code></pre>
</div>
</div>
<div class="interpret">
<p><strong>INTERPRETATION</strong></p>
<p>From these values, we interpret the coefficients in the odds metric as:</p>
<ul>
<li>The predicted odds of obtaining a degree for students with an ACT score of 0 are 0.20.</li>
<li>Each one-point difference in ACT score is associated with 1.11 times greater odds of obtaining a degree.</li>
</ul>
</div>
<p>To even further understand and interpret the fitted model, we can plot the predicted odds of obtaining a degree for a range of ACT scores. Recall, the general fitted equation for the logistic regression model is written as:</p>
<p><span class="math display">\[
\ln\bigg[\frac{\hat\pi_i}{1 - \hat\pi_i}\bigg] = \hat\beta_0 + \hat\beta_1(x_i)
\]</span></p>
<p>We need to predict odds rather than log-odds on the left-hand side of the equation. To do this we exponentiate both sides of the equation:</p>
<p><span class="math display">\[
\begin{split}
e^{\ln\bigg[\frac{\hat\pi_i}{1 - \hat\pi_i}\bigg]} &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} \\[1em]
\frac{\hat\pi_i}{1 - \hat\pi_i} &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)}
\end{split}
\]</span></p>
<p>We include the right-side of this in the argument <code>fun=</code> of the <code>geom_function()</code> layer, substituting in the values for <span class="math inline">\(\hat\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span>. Below we plot the results from our fitted logistic model.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the fitted equation</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> grad, <span class="fu">aes</span>(<span class="at">x =</span> act, <span class="at">y =</span> got_degree)) <span class="sc">+</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> <span class="cf">function</span>(x) {<span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.611</span> <span class="sc">+</span> <span class="fl">0.108</span><span class="sc">*</span>x)}</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"ACT score"</span>) <span class="sc">+</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted odds of obtaining a degree"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-predicted-odds" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Predicted odds of obtaining a degree as a function of ACT score." data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-predicted-odds-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="04-02-logistic-regression_files/figure-html/fig-predicted-odds-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%" alt="Predicted odds of obtaining a degree as a function of ACT score.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-predicted-odds-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.5: Predicted odds of obtaining a degree as a function of ACT score.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The monotonic increase in the curve indicates the positive effect of ACT score on the odds of obtaining a degree. The exponential growth curve indicates that students with higher ACT scores have increasingly higher odds of obtaining a degree.</p>
<p><br></p>
</section>
<section id="back-transforming-to-probability" class="level3" data-number="14.7.2">
<h3 data-number="14.7.2" class="anchored" data-anchor-id="back-transforming-to-probability"><span class="header-section-number">14.7.2</span> Back-Transforming to Probability</h3>
<p>We can also back-transform from odds to probability. To do this, we will again start with the logistic fitted equation and use algebra to isolate the probability of obtaining a degree (<span class="math inline">\(\pi_i\)</span>) on the left-hand side of the equation.</p>
<p><span class="math display">\[
\begin{split}
\ln\bigg[\frac{\hat\pi_i}{1 - \hat\pi_i}\bigg] &amp;= \hat\beta_0 + \hat\beta_1(x_i) \\[1em]
\frac{\hat\pi_i}{1 - \hat\pi_i} &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} \\[1em]
\hat\pi_i &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} (1 - \hat\pi_i) \\[1em]
\hat\pi_i &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} - e^{\hat\beta_0 + \hat\beta_1(x_i)}(\hat\pi_i) \\[1em]
\hat\pi_i + e^{\hat\beta_0 + \hat\beta_1(x_i)}(\hat\pi_i) &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} \\[1em]
\hat\pi_i(1 + e^{\hat\beta_0 + \hat\beta_1(x_i)}) &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} \\[1em]
\hat\pi_i &amp;= \frac{e^{\hat\beta_0 + \hat\beta_1(x_i)}}{1 + e^{\hat\beta_0 + \hat\beta_1(x_i)}} \\[1em]
\hat\pi_i &amp;= \frac{e^{\hat Y_i}}{1 + e^{\hat Y_i}}
\end{split}
\]</span></p>
<p>That is, to obtain the probability of obtaining a degree, we can transform the fitted values (i.e., the predicted log-odds) from the logistic model. For example, the intercept from the logistic fitted equation, <span class="math inline">\(-1.61\)</span> was the predicted log-odds of obtaining a degree for students with an ACT of 0. To obtain the predicted probability of obtaining a degree for students with an ACT of 0:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted probability of obtaining a degree; ACT=0</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.61</span>) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.61</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1665886</code></pre>
</div>
</div>
<p>For students with ACT of 0, the predicted probability of obtaining a degree is 0.17.</p>
<p>This transformation from log-odds to probability, is non-linear, which means that there is not a clean interpretation of the effects of ACT (i.e., the slope) on the probability of obtaining a degree To understand this effect we can plot the probability of obtaining a degree across the range of ACT scores. To do this, we use <code>geom_function()</code> and input the transformation to probability with the fitted equation:</p>
<p><span class="math display">\[
\hat\pi_i = \frac{e^{\hat\beta_0 + \hat\beta_1(x_i)}}{1 + e^{\hat\beta_0 + \hat\beta_1(x_i)}}
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the fitted equation</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> grad, <span class="fu">aes</span>(<span class="at">x =</span> act, <span class="at">y =</span> got_degree)) <span class="sc">+</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> <span class="cf">function</span>(x) {<span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.611</span> <span class="sc">+</span> <span class="fl">0.108</span><span class="sc">*</span>x) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.611</span> <span class="sc">+</span> <span class="fl">0.108</span><span class="sc">*</span>x))}</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"ACT score"</span>) <span class="sc">+</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted probability of obtaining a degree"</span>) <span class="sc">+</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-predicted-probability" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Predicted probability of obtaining a degree as a function of ACT score." data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-predicted-probability-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="04-02-logistic-regression_files/figure-html/fig-predicted-probability-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%" alt="Predicted probability of obtaining a degree as a function of ACT score.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-predicted-probability-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.6: Predicted probability of obtaining a degree as a function of ACT score.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The effect of ACT on the probability of obtaining a degree follows a monotonic increasing “S”-curve. While there is always an increasing effect of ACT on the probability of obtaining a degree, the magnitude of this effect depends on ACT score. For lower ACT scores there is a larger effect of ACT score on the probability of obtaining a degree than for higher ACT scores.</p>
<p>One interesting point on the plot is the ACT score where the probability of obtaining a degree is 0.5. In our example, this is at an ACT score of approximately 15. This implies that students who score less than 15 are more likely to not obtain a degree than to obtain a degree (on average), and those that score higher than 15 are more likely to obtain a degree than not (on average).</p>
<p><br></p>
<section id="rough-interpretation-of-the-slope" class="level4" data-number="14.7.2.1">
<h4 data-number="14.7.2.1" class="anchored" data-anchor-id="rough-interpretation-of-the-slope"><span class="header-section-number">14.7.2.1</span> Rough Interpretation of the Slope</h4>
<p>One rough interpretation that is often used is to divide the slope coefficient by 4 to get an upper bound of the predictive difference in probability of <em>Y</em> per unit increase in <em>X</em>. In our example, each one-point difference in ACT score is associated with, at most, a <span class="math inline">\(0.108/4=.027\)</span> difference in the probability of obtaining a degree, on average.</p>
<div class="mathnote">
<p>The mathematics behind this rough interpretation is based on maximizing the rate-of-change, which is based on setting the first derivative of the logistic function to zero and solving. Recall that the logistic function relates the probabilities to the fitted equation as:</p>
<p><span class="math display">\[
\hat\pi_i = \frac{e^{\hat\beta_0 + \hat\beta_1(x_i)}}{1 + e^{\hat\beta_0 + \hat\beta_1(x_i)}}
\]</span></p>
<p>The first derivative, with respect to <em>x</em> is:</p>
<p><span class="math display">\[
\frac{\hat\beta_1e^{\hat\beta_0 + \hat\beta_1(x_i)}}{\bigg[e^{\hat\beta_0 + \hat\beta_1(x_i)} + 1\bigg]^2}
\]</span></p>
<p>This is maximized when <span class="math inline">\(\hat\beta_0 + \hat\beta_1(x_i)=0\)</span>, which means we can substitute 0 into the derivative to determine the maximum rate-of-change:</p>
<p><span class="math display">\[
\begin{split}
&amp;= \frac{\hat\beta_1e^{0}}{\bigg[e^{0} + 1\bigg]^2} \\[1ex]
&amp;= \frac{\hat\beta_1}{\bigg[1 + 1\bigg]^2} \\[1ex]
&amp;= \frac{\hat\beta_1}{4} \\[1ex]
\end{split}
\]</span></p>
<p>Thus the maximum rate-of-change is the based on the slope coefficient divided by four.</p>
</div>
<p><br></p>
</section>
</section>
</section>
<section id="model-level-summaries" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="model-level-summaries"><span class="header-section-number">14.8</span> Model-Level Summaries</h2>
<p>The <code>glance()</code> output for the GLM model also included model-level information. For the model we fitted, the model-level output was:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model-level output</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(glm<span class="fl">.1</span>) <span class="sc">|&gt;</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="at">width =</span> <span class="cn">Inf</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 8
  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs
          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;
1         2723.    2343 -1317. 2637. 2649.    2633.        2342  2344</code></pre>
</div>
</div>
<p>The metric of measuring residual fit is the deviance (remember the deviance was <span class="math inline">\(-2 \times\)</span> log-likelihood). The value in the <code>null.deviance</code> column is the residual deviance from fitting the intercept-only model. It acts as a baseline to compare other models.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit intercept-only model</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>glm<span class="fl">.0</span> <span class="ot">=</span> <span class="fu">glm</span>(got_degree <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> grad, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute deviance</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(glm<span class="fl">.0</span>)[[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2722.546</code></pre>
</div>
</div>
<p>The value in the <code>deviance</code> column is the residual deviance from fitting whichever model was fitted, in our case the model that used ACT score as a predictor.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute deviance for glm.1</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(glm<span class="fl">.1</span>)[[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2633.236</code></pre>
</div>
</div>
<p>Recall that deviance is akin to the sum of squared residuals (SSE) in conventional linear regression; smaller values indicate less error. In our case, the model that includes ACT score as a predictor has less error than the intercept only model; its deviance is 90 less than the intercept-only model.</p>
<p>The deviance values or log-likelihoods are often reported in a table of regression results. They are also used to compute differenct information criteria.</p>
<p><br></p>
</section>
<section id="evaluating-the-effect-of-act-acore" class="level2" data-number="14.9">
<h2 data-number="14.9" class="anchored" data-anchor-id="evaluating-the-effect-of-act-acore"><span class="header-section-number">14.9</span> Evaluating the Effect of ACT Acore</h2>
<p>To evaluate the effect of ACT we compute the AICc values and other metrics in out table of model evidence.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">aictab</span>(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">cand.set =</span> <span class="fu">list</span>(glm<span class="fl">.0</span>, glm<span class="fl">.1</span>),</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">modnames =</span> <span class="fu">c</span>(<span class="st">"Intercept-Only"</span>, <span class="st">"Effect of ACT"</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Model selection based on AICc:

               K    AICc Delta_AICc AICcWt Cum.Wt       LL
Effect of ACT  2 2637.24       0.00      1      1 -1316.62
Intercept-Only 1 2724.55      87.31      0      1 -1361.27</code></pre>
</div>
</div>
<p>Here, given the data and the candidate set of models, there is overwhelming empirical support to adopt the model that includes ACT score.</p>
<p><br></p>
<section id="assessing-statistical-significance-of-the-predictor" class="level3 fyi" data-number="14.9.1">
<h3 data-number="14.9.1" class="anchored" data-anchor-id="assessing-statistical-significance-of-the-predictor"><span class="header-section-number">14.9.1</span> Assessing Statistical Significance of the Predictor 🤮</h3>
<p>We can obtain <em>p</em>-values to evaluate statistical significance of predictors. Similar to the regression model, we can obtain <em>p</em>-values under the classical framework and under the likelihood framework for inference. Under the classical framework we use <code>tidy()</code>. The <em>z</em>-values and <em>p</em>-values from <code>tidy()</code> are sometimes referred to as <em>Wald statistics</em> and <em>Wald p-values</em>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Classical framework for inference</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Wald values</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(glm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)   -1.61     0.283      -5.70 1.21e- 8
2 act            0.108    0.0116      9.25 2.20e-20</code></pre>
</div>
</div>
<p>We can also use the log-likelihood values to carry out a likelihood ratio test to test the improvement in deviance from the baseline model (using the likelihood framework). Since the intercept-only model is nested in the model that includes ACT as a predictor, we can use a Likelihood Ratio Test to examine this. To do so, we use the <code>anova()</code> function with the added argument <code>test="LRT"</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood framework for inference</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(glm<span class="fl">.0</span>, glm<span class="fl">.1</span>, <span class="at">test =</span> <span class="st">"LRT"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model 1: got_degree ~ 1
Model 2: got_degree ~ 1 + act
  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
1      2343     2722.6                          
2      2342     2633.2  1    89.31 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The null hypothesis of this test is that there is NO improvement in the deviance. The results of this test, <span class="math inline">\(\chi^2(1)=89.3\)</span>, <span class="math inline">\(p&lt;.001\)</span>, indicate that the observed difference of 89.3 is more than we would expect if the null hypothesis was true. In practice, this implies that the more complex model has significantly less error than the intercept-only model and should be adopted.</p>
</section>
<p><br></p>
</section>
<section id="pseudo-r-squared-values" class="level2" data-number="14.10">
<h2 data-number="14.10" class="anchored" data-anchor-id="pseudo-r-squared-values"><span class="header-section-number">14.10</span> Pseudo R-Squared Values</h2>
<p>When we fitted linear regression models, we computed an <span class="math inline">\(R^2\)</span> value for the model as a summary measure of the model. This value quantified the amount of variation in the outcome that was explainable by the predictors included in the model. To compute this, we computed:</p>
<p><span class="math display">\[
R^2 = \frac{\mathrm{SSE}_{\mathrm{Baseline}} - \mathrm{SSE}_{\mathrm{Model}}}{\mathrm{SSE}_{\mathrm{Baseline}}}
\]</span></p>
<p>where the baseline model was the intercept-only model. This measured the proportion of reduction in the residuals from the baseline to the fitted model.</p>
<p>With logistic models, there is no sum of squared error, so we cannot compute an <span class="math inline">\(R^2\)</span> value. However, the residual deviance is a similar measure to the sum of squared error. We can substitute the deviance in for SSE in our computation,</p>
<p><span class="math display">\[
\mathrm{Pseudo}\mbox{-}R^2 = \frac{\mathrm{Deviance}_{\mathrm{Baseline}} - \mathrm{Deviance}_{\mathrm{Model}}}{\mathrm{Deviance}_{\mathrm{Baseline}}}
\]</span></p>
<p>This measure is referred to as a pseudo-<span class="math inline">\(R^2\)</span> value. To compute this measure for our example:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Baseline residual deviance: 2722.6</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Model residual deviance: 2633.2</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute pseudo R-squared</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>(<span class="fl">2722.6</span> <span class="sc">-</span> <span class="fl">2633.2</span>) <span class="sc">/</span> <span class="fl">2722.6</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.03283626</code></pre>
</div>
</div>
<p>Interpreting pseudo <span class="math inline">\(R^2\)</span> values are somewhat problematic. A naive interpretation is that differences in ACT scores explains 3.28% of the variation in graduation status. However, this interpretation is a bit sketchy. Pseudo <span class="math inline">\(R^2\)</span> values mimic <span class="math inline">\(R^2\)</span> values in that they are generally on a similar scale, ranging from 0 to 1 (though remember pseudo <span class="math inline">\(R^2\)</span> values can be negative). Moreover, higher pseudo <span class="math inline">\(R^2\)</span> values, like <span class="math inline">\(R^2\)</span> values, indicate better model fit. So while I wouldn’t offer the earlier interpretation of the value of 0.0328 in a paper, the value close to 0 does suggest that ACT scores are not perhaps incredibly predictive of the log-odds (or odds or probability) of obtaining a degree.</p>
<div class="fyi">
<p><strong>FYI</strong> In logistic regression, several other pseudo <span class="math inline">\(R^2\)</span> values have also been proposed. See https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/ for more information.</p>
</div>
<p><br></p>
</section>
<section id="assumptions-of-the-logistic-model" class="level2" data-number="14.11">
<h2 data-number="14.11" class="anchored" data-anchor-id="assumptions-of-the-logistic-model"><span class="header-section-number">14.11</span> Assumptions of the Logistic Model</h2>
<p>The assumptions for the logistic model are quite different than those for the linear model. The three major assumptions are:</p>
<ol type="1">
<li>The outcome is binary (only two possible outcomes).</li>
<li>The observations (or residuals) are independent.</li>
<li>There is a linear relationship between the predictors and the logit of the outcome. (Or that the average residual from the fitted logistic model is 0 for all fitted values.)</li>
</ol>
<p>Unlike with linear regression, we have no assumption that the residuals are normally distributed, nor that there is homoskedasticity. In our example, Assumption 1 is met since the only two values of the outcome were “obtained a degree” or “did not obtain a degree”. We need to use the same logic we used in linear regression to verify the independence assumption. Here it seems tenable, since knowing whether one student obtained a degree, does not give us information about whether another student obtains a degree.</p>
<p>To evaluate the third assumption, we will again plot the residuals versus the fitted values and again look to ensure the <span class="math inline">\(Y=0\)</span> line is encompassed in the confidence envelope for the loess smoother. However, as we saw earlier, plots of the raw and standardized residuals from a logistic regression are not that useful. Instead we will create a <strong>binned residual plot</strong>. Binned residuals are obtained by ordering all the observations by the fitted values, separating them into <em>g</em> roughly equal bins, and calculating the average residual value in each bin. The binned residual plot is then created by plotting the average residuals in each bin versus the average fitted value in each bin.</p>
<p>To obtain the average fitted values and average residuals in each bin, we will use the <code>binned_residuals()</code> function from the <code>{performance}</code> package. The <code>print()</code> function will then be used to create the binned residual plot.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain average fitted values and average residuals</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>out<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">binned_residuals</span>(glm<span class="fl">.1</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># View binned residuals</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(out<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                xbar         ybar   n      x.lo      x.hi        se
conf_int   0.4773158 -0.092349642  54 0.3946137 0.5005491 0.3142217
conf_int1  0.5441433 -0.409240401  67 0.5274063 0.5541059 0.2716741
conf_int2  0.5804968 -0.065295207  49 0.5804968 0.5804968 0.3333386
conf_int3  0.6064352  0.254763834  73 0.6064352 0.6064352 0.2538567
conf_int4  0.6317871  0.196713174 109 0.6317871 0.6317871 0.2088610
conf_int5  0.6564311  0.152169899 143 0.6564311 0.6564311 0.1828020
conf_int6  0.6802604 -0.001183704 163 0.6802604 0.6802604 0.1773462
conf_int7  0.7031843  0.273568198 195 0.7031843 0.7031843 0.1432526
conf_int8  0.7251288  0.292833498 213 0.7251288 0.7251288 0.1323670
conf_int9  0.7460368  0.038106405 233 0.7460368 0.7460368 0.1428258
conf_int10 0.7658680  0.247625181 237 0.7658680 0.7658680 0.1238422
conf_int11 0.7845977  0.152357342 189 0.7845977 0.7845977 0.1455285
conf_int12 0.8022160  0.138971890 169 0.8022160 0.8022160 0.1525677
conf_int13 0.8187263  0.211235395 159 0.8187263 0.8187263 0.1452254
conf_int14 0.8341432  0.085452419 116 0.8341432 0.8341432 0.1849288
conf_int15 0.8484916  0.103580947  75 0.8484916 0.8484916 0.2233596
conf_int16 0.8618044  0.089109799  50 0.8618044 0.8618044 0.2726814
conf_int17 0.8741210  0.078271252  29 0.8741210 0.8741210 0.3574272
conf_int18 0.8879763  0.240126242  21 0.8854857 0.8959465 0.3366564
                 CI_low     CI_high group
conf_int   -0.230751241  0.04605196   yes
conf_int1  -0.529241205 -0.28923960    no
conf_int2  -0.211260477  0.08067006   yes
conf_int3   0.143218379  0.36630929    no
conf_int4   0.105486192  0.28794016   yes
conf_int5   0.072776878  0.23156292   yes
conf_int6  -0.077710885  0.07534348   yes
conf_int7   0.211745203  0.33539119    no
conf_int8   0.235925500  0.34974150    no
conf_int9  -0.022604005  0.09881681   yes
conf_int10  0.194957304  0.30029306    no
conf_int11  0.090769880  0.21394480    no
conf_int12  0.074659052  0.20328473   yes
conf_int13  0.150047581  0.27242321    no
conf_int14  0.008085150  0.16281969   yes
conf_int15  0.009914453  0.19724744   yes
conf_int16 -0.025193868  0.20341347   yes
conf_int17 -0.071374483  0.22791699   yes
conf_int18  0.094113698  0.38613879   yes</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Residual plot</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This will also require you to install the {see} package</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(out<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-resid" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Binned residuals versus the binned fitted values for the model that includes the linear effect of ACT to predict the log-odds of obtaining a degree." data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-resid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="04-02-logistic-regression_files/figure-html/fig-resid-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%" alt="Binned residuals versus the binned fitted values for the model that includes the linear effect of ACT to predict the log-odds of obtaining a degree.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-resid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.7: Binned residuals versus the binned fitted values for the model that includes the linear effect of ACT to predict the log-odds of obtaining a degree.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Good fit to the assumption of linearity is indicated by most of the residuals being encompassed within the error bounds of the <span class="math inline">\(Y=0\)</span> line. We can see some misfit in the binned residual plot. The warning message produced from the <code>binned_residuals()</code> function also indicates that we may have some misfits given that only 89% of the residuals are within the error bounds.</p>
<p>It is unclear from this plot what the misfit is due to. It may be because the relationship between ACT and the log-odds of obtaining a degree is non-linear. It may be because there are other predictors (main effects or interactions) that we are missing. (We will explore this in the next set of notes.)</p>
<p><br></p>


<!-- -->

</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>The logistic regression model is from a family of models referred to as <em>Generalized Linear Regression</em> models. The General Linear Model (i.e., fixed-effects regression model) is also a member of the Generalized Linear Model family.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./04-01-linear-probability-model.html" class="pagination-link" aria-label="Linear Probability Model">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Linear Probability Model</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./04-03-more-logistic-regression.html" class="pagination-link" aria-label="More Logistic Regression">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">More Logistic Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb36" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Logistic Regression</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"scripts/_common.R"</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="fu">## Preparation</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>In this chapter, you will learn how to use logistic regression models to model dichotomous categorical outcome variables (e.g., dummy coded outcome). We will use data from the file *graduation.csv* to explore predictors of college graduation. </span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">CSV File</span><span class="co">](https://raw.githubusercontent.com/zief0002/fluffy-ants/main/data/graduation.csv)</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Data Codebook</span><span class="co">](http://zief0002.github.io/fluffy-ants/codebooks/graduation.html)</span></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Load libraries</span></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AICcmodavg)</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrr)</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(performance)</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in data and create dummy variable for outcome</span></span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>grad <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="at">file =</span> <span class="st">"https://raw.githubusercontent.com/zief0002/fluffy-ants/main/data/graduation.csv"</span>) <span class="sc">|&gt;</span></span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">got_degree =</span> <span class="fu">if_else</span>(degree <span class="sc">==</span> <span class="st">"Yes"</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>grad</span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a>We will also examine the empirical proportions of students who obtain a degree at different ACT scores to remind us about the relationship we will be modeling. </span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-46"><a href="#cb36-46" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-47"><a href="#cb36-47" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-scatterplot-proportion</span></span>
<span id="cb36-48"><a href="#cb36-48" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Proportion of students who obtain a degree conditional on ACT score. Size of the dot is proportional to sample size. The loess smoother is based on the raw data."</span></span>
<span id="cb36-49"><a href="#cb36-49" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Proportion of students who obtain a degree conditional on ACT score. Size of the dot is proportional to sample size. The loess smoother is based on the raw data."</span></span>
<span id="cb36-50"><a href="#cb36-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain the proportion who obtain a degree for each ACT score</span></span>
<span id="cb36-51"><a href="#cb36-51" aria-hidden="true" tabindex="-1"></a>prop_grad <span class="ot">=</span> grad <span class="sc">|&gt;</span> </span>
<span id="cb36-52"><a href="#cb36-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(act, degree) <span class="sc">|&gt;</span> </span>
<span id="cb36-53"><a href="#cb36-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">N =</span> <span class="fu">n</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb36-54"><a href="#cb36-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb36-55"><a href="#cb36-55" aria-hidden="true" tabindex="-1"></a>    <span class="at">Prop =</span> N <span class="sc">/</span> <span class="fu">sum</span> (N)</span>
<span id="cb36-56"><a href="#cb36-56" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb36-57"><a href="#cb36-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">|&gt;</span></span>
<span id="cb36-58"><a href="#cb36-58" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(degree <span class="sc">==</span> <span class="st">"Yes"</span>)</span>
<span id="cb36-59"><a href="#cb36-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-60"><a href="#cb36-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatterplot</span></span>
<span id="cb36-61"><a href="#cb36-61" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> prop_grad, <span class="fu">aes</span>(<span class="at">x =</span> act, <span class="at">y =</span> Prop)) <span class="sc">+</span></span>
<span id="cb36-62"><a href="#cb36-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">size =</span> N)) <span class="sc">+</span></span>
<span id="cb36-63"><a href="#cb36-63" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">weight =</span> N), <span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb36-64"><a href="#cb36-64" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb36-65"><a href="#cb36-65" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"ACT score"</span>) <span class="sc">+</span></span>
<span id="cb36-66"><a href="#cb36-66" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Proportion who obtained a degree"</span>)</span>
<span id="cb36-67"><a href="#cb36-67" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-68"><a href="#cb36-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-69"><a href="#cb36-69" aria-hidden="true" tabindex="-1"></a>Because the sample sizes differs across ACT scores, we need to account for that by weighting the loess smoother. To do this we include <span class="in">`aes(weight=)`</span> in the <span class="in">`geom_smooth()`</span> layer. </span>
<span id="cb36-70"><a href="#cb36-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-71"><a href="#cb36-71" aria-hidden="true" tabindex="-1"></a>In the last set of notes, we saw that using the linear probability model leads to direct violations of the linear model's assumptions. If that isn't problematic enough, it is possible to run into severe issues when we make predictions. For example, given the constant effect of *X* in these models it is possible to have an *X* value that results in a predicted proportion that is either greater than 1 or less than 0. This is a problem since proportions are constrained to the range of $\left<span class="co">[</span><span class="ot">0,~1\right</span><span class="co">]</span>$.</span>
<span id="cb36-72"><a href="#cb36-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-73"><a href="#cb36-73" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-74"><a href="#cb36-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-75"><a href="#cb36-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-76"><a href="#cb36-76" aria-hidden="true" tabindex="-1"></a><span class="fu">## Alternative Models to the Linear Probability Model</span></span>
<span id="cb36-77"><a href="#cb36-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-78"><a href="#cb36-78" aria-hidden="true" tabindex="-1"></a>Many of the non-linear models that are typically used to model dichotomous outcome data are "S"-shaped models. Below is a plot of one-such "S"-shaped model.</span>
<span id="cb36-79"><a href="#cb36-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-82"><a href="#cb36-82" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-83"><a href="#cb36-83" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-s-shape</span></span>
<span id="cb36-84"><a href="#cb36-84" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "An 'S'-shaped model."</span></span>
<span id="cb36-85"><a href="#cb36-85" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "An 'S'-shaped model."</span></span>
<span id="cb36-86"><a href="#cb36-86" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb36-87"><a href="#cb36-87" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">4</span>, <span class="at">to =</span> <span class="dv">4</span>, <span class="at">by =</span> .<span class="dv">01</span>)</span>
<span id="cb36-88"><a href="#cb36-88" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>(<span class="dv">0</span> <span class="sc">+</span> <span class="dv">4</span><span class="sc">*</span>x)))</span>
<span id="cb36-89"><a href="#cb36-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-90"><a href="#cb36-90" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">xlab =</span> <span class="st">"X"</span>, <span class="at">ylab =</span> <span class="fu">expression</span>(pi[i]))</span>
<span id="cb36-91"><a href="#cb36-91" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-92"><a href="#cb36-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-93"><a href="#cb36-93" aria-hidden="true" tabindex="-1"></a>The non-linear "S"-shaped model has many attractive features. First, the predicted proportions ($\pi_i$) are bounded between 0 and 1. Furthermore, as *X* gets smaller, $\pi_i$ approaches 0 at a slower rate. Similarly, as *X* gets larger, $\pi_i$ approaches 1 at a slower rate. Lastly, this model curve is monotonic; smaller values of *X* are associated with smaller predicted proportions and  larger values of *X* are associated with larger predicted proportions. (Or, if the "S" were backwards, smaller values of *X* are associated with larger predicted proportions and larger values of *X* would be associated with smaller predicted proportions). The key is that there are no bends in the curve; it is always growing or always decreasing.</span>
<span id="cb36-94"><a href="#cb36-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-95"><a href="#cb36-95" aria-hidden="true" tabindex="-1"></a>In our student example, the empirical data maps well to this curve. Higher ACT scores are associated with a higher proportion of students who obtain a degree (monotonic). The effect of ACT, however, is not constant, and seems to diminish at higher ACT scores. Lastly, we want to bound the proportion who obtain a degree at every ACT score to lie between 0 and 1.</span>
<span id="cb36-96"><a href="#cb36-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-97"><a href="#cb36-97" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-98"><a href="#cb36-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-99"><a href="#cb36-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-100"><a href="#cb36-100" aria-hidden="true" tabindex="-1"></a><span class="fu">### A Transformation to Fit the "S"-shaped Curve</span></span>
<span id="cb36-101"><a href="#cb36-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-102"><a href="#cb36-102" aria-hidden="true" tabindex="-1"></a>We need to identify a mathematical function that relates *X* to *Y* in such a way that we produce this "S"-shaped curve. To do this we apply a transformation function, call it $\Lambda$ (Lambda), that fits the criteria for such a function (monotonic, nonlinear, maps to $[0,~1]$ space). There are several mathematical functions that do this. One commonly used function that meets these specifications is the **logistic function**. Mathematically, the logistic function is:</span>
<span id="cb36-103"><a href="#cb36-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-104"><a href="#cb36-104" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-105"><a href="#cb36-105" aria-hidden="true" tabindex="-1"></a>\Lambda(x) = \frac{1}{1 + e^{-x}}</span>
<span id="cb36-106"><a href="#cb36-106" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-107"><a href="#cb36-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-108"><a href="#cb36-108" aria-hidden="true" tabindex="-1"></a>where *x* is the value fed into the logistic function. For example, to logistically transform $x=3$, we use</span>
<span id="cb36-109"><a href="#cb36-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-110"><a href="#cb36-110" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-111"><a href="#cb36-111" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb36-112"><a href="#cb36-112" aria-hidden="true" tabindex="-1"></a>\Lambda(3) &amp;= \frac{1}{1 + e^{-3}} <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb36-113"><a href="#cb36-113" aria-hidden="true" tabindex="-1"></a>&amp;= 0.953</span>
<span id="cb36-114"><a href="#cb36-114" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb36-115"><a href="#cb36-115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-116"><a href="#cb36-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-117"><a href="#cb36-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-118"><a href="#cb36-118" aria-hidden="true" tabindex="-1"></a>Below we show how to transform many such values using R.</span>
<span id="cb36-119"><a href="#cb36-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-122"><a href="#cb36-122" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-123"><a href="#cb36-123" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-logistic</span></span>
<span id="cb36-124"><a href="#cb36-124" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Plot of the logistically transformed values for a sequence of values from -4 to 4."</span></span>
<span id="cb36-125"><a href="#cb36-125" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Plot of the logistically transformed values for a sequence of values from -4 to 4."</span></span>
<span id="cb36-126"><a href="#cb36-126" aria-hidden="true" tabindex="-1"></a><span class="co"># Create w values and transformed values</span></span>
<span id="cb36-127"><a href="#cb36-127" aria-hidden="true" tabindex="-1"></a>example <span class="ot">=</span> <span class="fu">tibble</span>(</span>
<span id="cb36-128"><a href="#cb36-128" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">4</span>, <span class="at">to =</span> <span class="dv">4</span>, <span class="at">by =</span> <span class="fl">0.01</span>)  <span class="co"># Set up values</span></span>
<span id="cb36-129"><a href="#cb36-129" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb36-130"><a href="#cb36-130" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb36-131"><a href="#cb36-131" aria-hidden="true" tabindex="-1"></a>    <span class="at">Lambda =</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>x))  <span class="co"># Transform using logistic function</span></span>
<span id="cb36-132"><a href="#cb36-132" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb36-133"><a href="#cb36-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-134"><a href="#cb36-134" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb36-135"><a href="#cb36-135" aria-hidden="true" tabindex="-1"></a>example</span>
<span id="cb36-136"><a href="#cb36-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-137"><a href="#cb36-137" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb36-138"><a href="#cb36-138" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> example, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> Lambda)) <span class="sc">+</span></span>
<span id="cb36-139"><a href="#cb36-139" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb36-140"><a href="#cb36-140" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span>
<span id="cb36-141"><a href="#cb36-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-142"><a href="#cb36-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-143"><a href="#cb36-143" aria-hidden="true" tabindex="-1"></a>You can see that by using this transformation we get a monotonic "S"-shaped curve. Now try substituting a really large value of *x* into the function. This gives an asymptote at 1. Also substitute a really "large"" negative value in for *x*. This gives an asymptote at 0. So this function also bounds the output between 0 and 1.</span>
<span id="cb36-144"><a href="#cb36-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-145"><a href="#cb36-145" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-146"><a href="#cb36-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-147"><a href="#cb36-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-148"><a href="#cb36-148" aria-hidden="true" tabindex="-1"></a><span class="fu">## Using the Logistic Function in Regression</span></span>
<span id="cb36-149"><a href="#cb36-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-150"><a href="#cb36-150" aria-hidden="true" tabindex="-1"></a>How does this work in a regression? There, we are relating the *predicted values*, that is, the $\beta_0 + \beta_1(X_i)$ values, to the probability of *Y*. So we need to apply the "S"-shaped logistic transformation to convert those predicted values:</span>
<span id="cb36-151"><a href="#cb36-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-152"><a href="#cb36-152" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-153"><a href="#cb36-153" aria-hidden="true" tabindex="-1"></a>\pi_i = \Lambda\bigg<span class="co">[</span><span class="ot">\beta_0 + \beta_1(X_i)\bigg</span><span class="co">]</span></span>
<span id="cb36-154"><a href="#cb36-154" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-155"><a href="#cb36-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-156"><a href="#cb36-156" aria-hidden="true" tabindex="-1"></a>Substituting the predicted equation into the logistic transformation, we get:</span>
<span id="cb36-157"><a href="#cb36-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-158"><a href="#cb36-158" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-159"><a href="#cb36-159" aria-hidden="true" tabindex="-1"></a>\pi_i = \frac{1}{1 + e^{-\big<span class="co">[</span><span class="ot">\beta_0 + \beta_1(X_i)\big</span><span class="co">]</span>}}</span>
<span id="cb36-160"><a href="#cb36-160" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-161"><a href="#cb36-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-162"><a href="#cb36-162" aria-hidden="true" tabindex="-1"></a>Since we took a linear model ($\beta_0 + \beta_1(X_i)$) and applied a logistic transformation, we refer to the resulting model as the **linear logistic model** or more simply, the **logistic model**.</span>
<span id="cb36-163"><a href="#cb36-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-164"><a href="#cb36-164" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-165"><a href="#cb36-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-166"><a href="#cb36-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-167"><a href="#cb36-167" aria-hidden="true" tabindex="-1"></a><span class="fu">### Re-Expressing a Logistic Transformation</span></span>
<span id="cb36-168"><a href="#cb36-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-169"><a href="#cb36-169" aria-hidden="true" tabindex="-1"></a>The logistic model expresses the proportion of 1s ($\pi_i$) as a function of the predictor $X$. It can be mathematically expressed as:</span>
<span id="cb36-170"><a href="#cb36-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-171"><a href="#cb36-171" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-172"><a href="#cb36-172" aria-hidden="true" tabindex="-1"></a>\pi_i = \frac{1}{1 + e^{-\big<span class="co">[</span><span class="ot">\beta_0 + \beta_1(X_i)\big</span><span class="co">]</span>}}</span>
<span id="cb36-173"><a href="#cb36-173" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-174"><a href="#cb36-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-175"><a href="#cb36-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-176"><a href="#cb36-176" aria-hidden="true" tabindex="-1"></a>We can re-express this using algebra and rules of logarithms.</span>
<span id="cb36-177"><a href="#cb36-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-178"><a href="#cb36-178" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-179"><a href="#cb36-179" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb36-180"><a href="#cb36-180" aria-hidden="true" tabindex="-1"></a>\pi_i &amp;= \frac{1}{1 + e^{-\big<span class="co">[</span><span class="ot">\beta_0 + \beta_1(X_i)\big</span><span class="co">]</span>}} <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb36-181"><a href="#cb36-181" aria-hidden="true" tabindex="-1"></a>\pi_i \times (1 + e^{-\big<span class="co">[</span><span class="ot">\beta_0 + \beta_1(X_i)\big</span><span class="co">]</span>} ) &amp;= 1 <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb36-182"><a href="#cb36-182" aria-hidden="true" tabindex="-1"></a>\pi_i + \pi_i(e^{-\big<span class="co">[</span><span class="ot">\beta_0 + \beta_1(X_i)\big</span><span class="co">]</span>}) &amp;= 1 <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb36-183"><a href="#cb36-183" aria-hidden="true" tabindex="-1"></a>\pi_i(e^{-\big<span class="co">[</span><span class="ot">\beta_0 + \beta_1(X_i)\big</span><span class="co">]</span>}) &amp;= 1 - \pi_i <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb36-184"><a href="#cb36-184" aria-hidden="true" tabindex="-1"></a>e^{-\big<span class="co">[</span><span class="ot">\beta_0 + \beta_1(X_i)\big</span><span class="co">]</span>} &amp;= \frac{1 - \pi_i}{\pi_i} <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb36-185"><a href="#cb36-185" aria-hidden="true" tabindex="-1"></a>e^{\big<span class="co">[</span><span class="ot">\beta_0 + \beta_1(X_i)\big</span><span class="co">]</span>} &amp;= \frac{\pi_i}{1 - \pi_i} <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb36-186"><a href="#cb36-186" aria-hidden="true" tabindex="-1"></a>\ln \bigg(e^{\big<span class="co">[</span><span class="ot">\beta_0 + \beta_1(X_i)\big</span><span class="co">]</span>}\bigg) &amp;= \ln \bigg( \frac{\pi_i}{1 - \pi_i} \bigg) <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb36-187"><a href="#cb36-187" aria-hidden="true" tabindex="-1"></a>\beta_0 + \beta_1(X_i) &amp;= \ln \bigg( \frac{\pi_i}{1 - \pi_i}\bigg)</span>
<span id="cb36-188"><a href="#cb36-188" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb36-189"><a href="#cb36-189" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-190"><a href="#cb36-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-191"><a href="#cb36-191" aria-hidden="true" tabindex="-1"></a>Or,</span>
<span id="cb36-192"><a href="#cb36-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-193"><a href="#cb36-193" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-194"><a href="#cb36-194" aria-hidden="true" tabindex="-1"></a>\ln \bigg( \frac{\pi_i}{1 - \pi_i}\bigg) = \beta_0 + \beta_1(X_i)</span>
<span id="cb36-195"><a href="#cb36-195" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-196"><a href="#cb36-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-197"><a href="#cb36-197" aria-hidden="true" tabindex="-1"></a>:::fyi</span>
<span id="cb36-198"><a href="#cb36-198" aria-hidden="true" tabindex="-1"></a>**FYI**</span>
<span id="cb36-199"><a href="#cb36-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-200"><a href="#cb36-200" aria-hidden="true" tabindex="-1"></a>The logistic model expresses the natural logarithm of $\frac{\pi_i}{1 - \pi_i}$ as a linear function of *X*. Note that there is no error term on this model. This is because the model is for the mean structure only (the proportions), we are not modeling the actual $Y_i$ values (i.e., the 0s and 1s) with the logistic regression model.</span>
<span id="cb36-201"><a href="#cb36-201" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb36-202"><a href="#cb36-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-203"><a href="#cb36-203" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-204"><a href="#cb36-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-205"><a href="#cb36-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-206"><a href="#cb36-206" aria-hidden="true" tabindex="-1"></a><span class="fu">## Odds: A Ratio of Probabilities</span></span>
<span id="cb36-207"><a href="#cb36-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-208"><a href="#cb36-208" aria-hidden="true" tabindex="-1"></a>The ratio that we are taking the logarithm of, $\frac{\pi_i}{1 - \pi_i}$, is referred to as *odds*. Odds are the ratio of two probabilities. Namely the chance an event occurs ($\pi_i$) versus the chance that same event does not occur ($1 - \pi_i$). As such, it gives the *relative probability* of that event occurring. To understand this better, we will look at a couple examples.</span>
<span id="cb36-209"><a href="#cb36-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-210"><a href="#cb36-210" aria-hidden="true" tabindex="-1"></a>Let's assume that the probability of getting an "A" in a course is 0.7. Then we know the probability of NOT getting an "A" in that course is 0.3. The odds of getting an "A" are then</span>
<span id="cb36-211"><a href="#cb36-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-212"><a href="#cb36-212" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-213"><a href="#cb36-213" aria-hidden="true" tabindex="-1"></a>\mathrm{Odds} = \frac{0.7}{0.3} = 2.33</span>
<span id="cb36-214"><a href="#cb36-214" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-215"><a href="#cb36-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-216"><a href="#cb36-216" aria-hidden="true" tabindex="-1"></a>The relative probability of getting an "A" is 2.33. That is, the probability of getting an "A" in the class is 2.33 times more likely than NOT getting an "A" in the class.</span>
<span id="cb36-217"><a href="#cb36-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-218"><a href="#cb36-218" aria-hidden="true" tabindex="-1"></a>As another example, Fivethirtyeight.com predicted on March 08, 2022 that the <span class="co">[</span><span class="ot">probability the Minnesota Wild would win the Stanley Cup was 0.02</span><span class="co">](https://projects.fivethirtyeight.com/2022-nhl-predictions/)</span>. The odds of the Minnesota Wild winning the Stanley Cup is then:</span>
<span id="cb36-219"><a href="#cb36-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-220"><a href="#cb36-220" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-221"><a href="#cb36-221" aria-hidden="true" tabindex="-1"></a>\mathrm{Odds} = \frac{0.02}{0.98} = 0.0204</span>
<span id="cb36-222"><a href="#cb36-222" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-223"><a href="#cb36-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-224"><a href="#cb36-224" aria-hidden="true" tabindex="-1"></a>The probability that the Minnesota Wild win the Stanley Cup is 0.0204 times as likely them NOT winning the Stanley Cup. (Odds less than 1 indicate that is is more likely for an event NOT to occur than to occur. Invert the fraction to compute how much more like the event is not to occur.)</span>
<span id="cb36-225"><a href="#cb36-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-226"><a href="#cb36-226" aria-hidden="true" tabindex="-1"></a>:::fyi</span>
<span id="cb36-227"><a href="#cb36-227" aria-hidden="true" tabindex="-1"></a>**FYI**</span>
<span id="cb36-228"><a href="#cb36-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-229"><a href="#cb36-229" aria-hidden="true" tabindex="-1"></a>In the logistic model, we are predicting the log-odds (also referred to as the *logit*. When we get these values, we typically transform the logits to odds by inverting the log-transformation (take *e* to that power.)</span>
<span id="cb36-230"><a href="#cb36-230" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb36-231"><a href="#cb36-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-232"><a href="#cb36-232" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-233"><a href="#cb36-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-234"><a href="#cb36-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-235"><a href="#cb36-235" aria-hidden="true" tabindex="-1"></a><span class="fu">## Relationship between X and Different Transformations</span></span>
<span id="cb36-236"><a href="#cb36-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-237"><a href="#cb36-237" aria-hidden="true" tabindex="-1"></a>Odds are a re-expression of the probabilities, and similarly log-odds (or logits) is a transformation of the odds onto the log scale. While the logistic regression is performed on the logits of Y, like any model where we have transformed variables to work in the model, we can back-transform when we present the results. In logistic regression we can present our results in logits, odds, or probabilities. Because of the transformations, each of these will have a different relationship with the predictor.</span>
<span id="cb36-238"><a href="#cb36-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-239"><a href="#cb36-239" aria-hidden="true" tabindex="-1"></a>For example, let's re-examine the plot of the "S"-shaped example data. This depicted the relationship between a predictor *X* and the probability of *Y*. We could also depict the relationship between *X* and the odds of *Y*, or the relationship between *X* and the log-odds of *Y*.</span>
<span id="cb36-240"><a href="#cb36-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-243"><a href="#cb36-243" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-244"><a href="#cb36-244" aria-hidden="true" tabindex="-1"></a><span class="co"># Create odds and logit values</span></span>
<span id="cb36-245"><a href="#cb36-245" aria-hidden="true" tabindex="-1"></a>example <span class="ot">=</span> example <span class="sc">|&gt;</span></span>
<span id="cb36-246"><a href="#cb36-246" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb36-247"><a href="#cb36-247" aria-hidden="true" tabindex="-1"></a>    <span class="at">Odds =</span> Lambda <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> Lambda),  <span class="co"># Transform to odds</span></span>
<span id="cb36-248"><a href="#cb36-248" aria-hidden="true" tabindex="-1"></a>    <span class="at">Logits =</span> <span class="fu">log</span>(Odds)</span>
<span id="cb36-249"><a href="#cb36-249" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb36-250"><a href="#cb36-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-251"><a href="#cb36-251" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb36-252"><a href="#cb36-252" aria-hidden="true" tabindex="-1"></a>example</span>
<span id="cb36-253"><a href="#cb36-253" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-254"><a href="#cb36-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-257"><a href="#cb36-257" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-258"><a href="#cb36-258" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-prob-odds-logits</span></span>
<span id="cb36-259"><a href="#cb36-259" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Plot showing the relationship between the probability of *Y* versus *X* (LEFT), the odds of *Y* versus *X* (CENTER), and the log-odds of *Y* versus *X* (RIGHT)."</span></span>
<span id="cb36-260"><a href="#cb36-260" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Plot showing the relationship between the probability of *Y* versus *X* (LEFT), the odds of *Y* versus *X* (CENTER), and the log-odds of *Y* versus *X* (RIGHT)."</span></span>
<span id="cb36-261"><a href="#cb36-261" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 12</span></span>
<span id="cb36-262"><a href="#cb36-262" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb36-263"><a href="#cb36-263" aria-hidden="true" tabindex="-1"></a><span class="co">#| out-width: "90%"</span></span>
<span id="cb36-264"><a href="#cb36-264" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb36-265"><a href="#cb36-265" aria-hidden="true" tabindex="-1"></a><span class="co"># S-shaped curve (probabilities)</span></span>
<span id="cb36-266"><a href="#cb36-266" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">=</span> <span class="fu">ggplot</span>(<span class="at">data =</span> example, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> Lambda)) <span class="sc">+</span></span>
<span id="cb36-267"><a href="#cb36-267" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb36-268"><a href="#cb36-268" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb36-269"><a href="#cb36-269" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Probabilities"</span>)</span>
<span id="cb36-270"><a href="#cb36-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-271"><a href="#cb36-271" aria-hidden="true" tabindex="-1"></a><span class="co"># Exponential growth curve (odds)</span></span>
<span id="cb36-272"><a href="#cb36-272" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">=</span> <span class="fu">ggplot</span>(<span class="at">data =</span> example, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> Odds)) <span class="sc">+</span></span>
<span id="cb36-273"><a href="#cb36-273" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb36-274"><a href="#cb36-274" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb36-275"><a href="#cb36-275" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Odds"</span>)</span>
<span id="cb36-276"><a href="#cb36-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-277"><a href="#cb36-277" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear (log-odds)</span></span>
<span id="cb36-278"><a href="#cb36-278" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">=</span> <span class="fu">ggplot</span>(<span class="at">data =</span> example, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> Logits)) <span class="sc">+</span></span>
<span id="cb36-279"><a href="#cb36-279" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb36-280"><a href="#cb36-280" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb36-281"><a href="#cb36-281" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Logits"</span>)</span>
<span id="cb36-282"><a href="#cb36-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-283"><a href="#cb36-283" aria-hidden="true" tabindex="-1"></a><span class="co"># Output plots</span></span>
<span id="cb36-284"><a href="#cb36-284" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">|</span> p2 <span class="sc">|</span> p3</span>
<span id="cb36-285"><a href="#cb36-285" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-286"><a href="#cb36-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-287"><a href="#cb36-287" aria-hidden="true" tabindex="-1"></a>Note that by transforming the probabilities into odds, we have changed the "S"-shaped curve into a classic exponential growth curve. (The Rule-of-the-Bulge suggests we can "fix" this by applying a downward power transformation on *Y*.) Then, by log-transforming the *Y*-values (the odds in this case), the resulting relationship is now linear. Thus an "S"-shaped curve can be "linearized" by transforming probabilities to logits (log-odds). Mathematically, this is equivalent to applying a logistic transformation to the predicted values.</span>
<span id="cb36-288"><a href="#cb36-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-289"><a href="#cb36-289" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-290"><a href="#cb36-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-291"><a href="#cb36-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-292"><a href="#cb36-292" aria-hidden="true" tabindex="-1"></a><span class="fu">## Binomially Distributed Errors</span></span>
<span id="cb36-293"><a href="#cb36-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-294"><a href="#cb36-294" aria-hidden="true" tabindex="-1"></a>The logistic transformation fixed two problems: (1) the non-linearity in the conditional mean function, and (2) bounding any predicted values between 0 and 1. However, just fitting this transformation does not fix the problem of non-normality. Remember from the previous notes we learned that at each $X_i$ there were only two potential values for $Y_i$; 0 or 1. Rather than use a normal (or Gaussian) distribution to model the conditional distribution of $Y_i$, we will use the *binomial distribution*.</span>
<span id="cb36-295"><a href="#cb36-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-296"><a href="#cb36-296" aria-hidden="true" tabindex="-1"></a>The binomial distribution is a discrete probability distribution that gives the probability of obtaining exactly *k* successes out of *n* Bernoulli trials (where the result of each Bernoulli trial is true with probability $\pi$ and false with probability $1-\pi$). This is appropriate since at each ACT value of there are $n_i$ students, *k* of which obtained their degree ($Y=1$).</span>
<span id="cb36-297"><a href="#cb36-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-298"><a href="#cb36-298" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-299"><a href="#cb36-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-300"><a href="#cb36-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-301"><a href="#cb36-301" aria-hidden="true" tabindex="-1"></a><span class="fu">## Fitting the Binomial Logistic Model in R</span></span>
<span id="cb36-302"><a href="#cb36-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-303"><a href="#cb36-303" aria-hidden="true" tabindex="-1"></a>To fit a logistic regression model with binomial errors, we use the <span class="in">`glm()`</span> function.^<span class="co">[</span><span class="ot">The logistic regression model is from a family of models referred to as *Generalized Linear Regression* models. The General Linear Model (i.e., fixed-effects regression model) is also a member of the Generalized Linear Model family.</span><span class="co">]</span> The syntax to fit the logistic model using <span class="in">`glm()`</span> is:</span>
<span id="cb36-304"><a href="#cb36-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-305"><a href="#cb36-305" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-306"><a href="#cb36-306" aria-hidden="true" tabindex="-1"></a>\mathtt{glm(} \mathrm{y} \sim \mathrm{1~+~x,~}\mathtt{data=}~\mathrm{dataframe,~}\mathtt{family~=~binomial(link~=~"logit")}</span>
<span id="cb36-307"><a href="#cb36-307" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-308"><a href="#cb36-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-309"><a href="#cb36-309" aria-hidden="true" tabindex="-1"></a>The formula depicting the model and the <span class="in">`data=`</span> arguments are specified in the same manner as in the <span class="in">`lm()`</span> function. We also need to specify the distribution for the conditional $Y_i$ values (binomial) and the link function (logit) via the <span class="in">`family=`</span> argument.</span>
<span id="cb36-310"><a href="#cb36-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-311"><a href="#cb36-311" aria-hidden="true" tabindex="-1"></a>For our example,</span>
<span id="cb36-312"><a href="#cb36-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-315"><a href="#cb36-315" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-316"><a href="#cb36-316" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit logistic model</span></span>
<span id="cb36-317"><a href="#cb36-317" aria-hidden="true" tabindex="-1"></a>glm<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">glm</span>(got_degree <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> act, <span class="at">data =</span> grad, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>))</span>
<span id="cb36-318"><a href="#cb36-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-319"><a href="#cb36-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-320"><a href="#cb36-320" aria-hidden="true" tabindex="-1"></a>The coefficients of the model can be printed using <span class="in">`coef()`</span>.</span>
<span id="cb36-321"><a href="#cb36-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-324"><a href="#cb36-324" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-325"><a href="#cb36-325" aria-hidden="true" tabindex="-1"></a><span class="co"># Get coefficients</span></span>
<span id="cb36-326"><a href="#cb36-326" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(glm<span class="fl">.1</span>)</span>
<span id="cb36-327"><a href="#cb36-327" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-328"><a href="#cb36-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-329"><a href="#cb36-329" aria-hidden="true" tabindex="-1"></a>Based on this output, the fitted equation for the model is:</span>
<span id="cb36-330"><a href="#cb36-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-331"><a href="#cb36-331" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-332"><a href="#cb36-332" aria-hidden="true" tabindex="-1"></a>\ln \bigg( \frac{\hat\pi_i}{1 - \hat\pi_i}\bigg) = -1.61 + 0.11(\mathrm{ACT~Score}_i)</span>
<span id="cb36-333"><a href="#cb36-333" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-334"><a href="#cb36-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-335"><a href="#cb36-335" aria-hidden="true" tabindex="-1"></a>:::interpret</span>
<span id="cb36-336"><a href="#cb36-336" aria-hidden="true" tabindex="-1"></a>**INTERPRETATION**</span>
<span id="cb36-337"><a href="#cb36-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-338"><a href="#cb36-338" aria-hidden="true" tabindex="-1"></a>We interpret the coefficients in the same manner as we interpret coefficients from a linear model, with the caveat that the outcome is now in log-odds (or logits):</span>
<span id="cb36-339"><a href="#cb36-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-340"><a href="#cb36-340" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The predicted log-odds of obtaining a degree for students with an ACT score of 0 are $-1.61$.</span>
<span id="cb36-341"><a href="#cb36-341" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Each one-point difference in ACT score is associated with a difference of 0.11 in the predicted log-odds of obtaining a degree, on average.</span>
<span id="cb36-342"><a href="#cb36-342" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb36-343"><a href="#cb36-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-344"><a href="#cb36-344" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-345"><a href="#cb36-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-346"><a href="#cb36-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-347"><a href="#cb36-347" aria-hidden="true" tabindex="-1"></a><span class="fu">### Back-Transforming to Odds</span></span>
<span id="cb36-348"><a href="#cb36-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-349"><a href="#cb36-349" aria-hidden="true" tabindex="-1"></a>For better interpretations, we can back-transform log-odds to odds. This is typically a better metric for interpretation of the coefficients. To back-transform to odds, we exponentiate both sides of the fitted equation and use the rules of exponents to simplify:</span>
<span id="cb36-350"><a href="#cb36-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-351"><a href="#cb36-351" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-352"><a href="#cb36-352" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb36-353"><a href="#cb36-353" aria-hidden="true" tabindex="-1"></a>\ln \bigg( \frac{\hat\pi_i}{1 - \hat\pi_i}\bigg) &amp;= -1.61 + 0.11(\mathrm{ACT~Score}_i) <span class="sc">\\</span><span class="co">[</span><span class="ot">4ex</span><span class="co">]</span></span>
<span id="cb36-354"><a href="#cb36-354" aria-hidden="true" tabindex="-1"></a>e^{\ln \bigg( \frac{\hat\pi_i}{1 - \hat\pi_i}\bigg)} &amp;= e^{-1.61 + 0.11(\mathrm{ACT~Score}_i)} <span class="sc">\\</span><span class="co">[</span><span class="ot">2ex</span><span class="co">]</span></span>
<span id="cb36-355"><a href="#cb36-355" aria-hidden="true" tabindex="-1"></a>\frac{\hat\pi_i}{1 - \hat\pi_i} &amp;= e^{-1.61} \times e^{0.11(\mathrm{ACT~Score}_i)}</span>
<span id="cb36-356"><a href="#cb36-356" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb36-357"><a href="#cb36-357" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-358"><a href="#cb36-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-359"><a href="#cb36-359" aria-hidden="true" tabindex="-1"></a>When ACT score = 0, the *predicted odds of obtaining a degree* are</span>
<span id="cb36-360"><a href="#cb36-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-361"><a href="#cb36-361" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-362"><a href="#cb36-362" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb36-363"><a href="#cb36-363" aria-hidden="true" tabindex="-1"></a>\frac{\hat\pi_i}{1 - \hat\pi_i} &amp;= e^{-1.61} \times e^{0.11(0)} <span class="sc">\\</span></span>
<span id="cb36-364"><a href="#cb36-364" aria-hidden="true" tabindex="-1"></a>&amp;= e^{-1.61} \times 1 <span class="sc">\\</span></span>
<span id="cb36-365"><a href="#cb36-365" aria-hidden="true" tabindex="-1"></a>&amp;= e^{-1.61} <span class="sc">\\</span></span>
<span id="cb36-366"><a href="#cb36-366" aria-hidden="true" tabindex="-1"></a>&amp;= 0.2</span>
<span id="cb36-367"><a href="#cb36-367" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb36-368"><a href="#cb36-368" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-369"><a href="#cb36-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-370"><a href="#cb36-370" aria-hidden="true" tabindex="-1"></a>The odds of obtaining a degree for students with an ACT score of 0 are 0.2. That is, for these students, the probability of obtaining a degree is 0.2 times that of not obtaining a degree (Although it is extrapolating, it is far more likely these students will not obtain their degree!)</span>
<span id="cb36-371"><a href="#cb36-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-372"><a href="#cb36-372" aria-hidden="true" tabindex="-1"></a>To interpret the effect of ACT on the odds of obtaining a degree, we will compare the odds of obtaining a degree for students that have ACT score that differ by one point. Say ACT = 0 and ACT = 1.</span>
<span id="cb36-373"><a href="#cb36-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-374"><a href="#cb36-374" aria-hidden="true" tabindex="-1"></a>We already know the predicted odds for students with ACT = 0, namely $e^{-1.61}$. For students with an ACT of 1, their predicted odds of obtaining a degree are:</span>
<span id="cb36-375"><a href="#cb36-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-376"><a href="#cb36-376" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-377"><a href="#cb36-377" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb36-378"><a href="#cb36-378" aria-hidden="true" tabindex="-1"></a>\frac{\hat\pi_i}{1 - \hat\pi_i} &amp;= e^{-1.61} \times e^{0.11(1)} <span class="sc">\\</span></span>
<span id="cb36-379"><a href="#cb36-379" aria-hidden="true" tabindex="-1"></a>&amp;= e^{-1.61} \times e^{0.11} <span class="sc">\\</span></span>
<span id="cb36-380"><a href="#cb36-380" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb36-381"><a href="#cb36-381" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-382"><a href="#cb36-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-383"><a href="#cb36-383" aria-hidden="true" tabindex="-1"></a>These students odds of obtaining a degree are $e^{0.11}$ times greater than students with an ACT score of 0. Moreover, this increase in the odds, on average, is the case for every one-point difference in ACT score. In general,</span>
<span id="cb36-384"><a href="#cb36-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-385"><a href="#cb36-385" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The predicted odds for $X=0$ are $e^{\hat\beta_0}$.</span>
<span id="cb36-386"><a href="#cb36-386" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Each one-unit difference in $X$ is associated with a $e^{\hat\beta_1}$ times increase (decrease) in the odds.</span>
<span id="cb36-387"><a href="#cb36-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-388"><a href="#cb36-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-389"><a href="#cb36-389" aria-hidden="true" tabindex="-1"></a>We can obtain these values in R by using the <span class="in">`coef()`</span> function to obtain the fitted model's coefficients and then exponentiating them using the <span class="in">`exp()`</span> function.</span>
<span id="cb36-390"><a href="#cb36-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-393"><a href="#cb36-393" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-394"><a href="#cb36-394" aria-hidden="true" tabindex="-1"></a><span class="co"># Exponentiate the coefficients</span></span>
<span id="cb36-395"><a href="#cb36-395" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">coef</span>(glm<span class="fl">.1</span>))</span>
<span id="cb36-396"><a href="#cb36-396" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-397"><a href="#cb36-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-398"><a href="#cb36-398" aria-hidden="true" tabindex="-1"></a>:::interpret</span>
<span id="cb36-399"><a href="#cb36-399" aria-hidden="true" tabindex="-1"></a>**INTERPRETATION**</span>
<span id="cb36-400"><a href="#cb36-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-401"><a href="#cb36-401" aria-hidden="true" tabindex="-1"></a>From these values, we interpret the coefficients in the odds metric as:</span>
<span id="cb36-402"><a href="#cb36-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-403"><a href="#cb36-403" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The predicted odds of obtaining a degree for students with an ACT score of 0 are 0.20.</span>
<span id="cb36-404"><a href="#cb36-404" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Each one-point difference in ACT score is associated with 1.11 times greater odds of obtaining a degree.</span>
<span id="cb36-405"><a href="#cb36-405" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb36-406"><a href="#cb36-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-407"><a href="#cb36-407" aria-hidden="true" tabindex="-1"></a>To even further understand and interpret the fitted model, we can plot the predicted odds of obtaining a degree for a range of ACT scores. Recall, the general fitted equation for the logistic regression model is written as:</span>
<span id="cb36-408"><a href="#cb36-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-409"><a href="#cb36-409" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-410"><a href="#cb36-410" aria-hidden="true" tabindex="-1"></a>\ln\bigg<span class="co">[</span><span class="ot">\frac{\hat\pi_i}{1 - \hat\pi_i}\bigg</span><span class="co">]</span> = \hat\beta_0 + \hat\beta_1(x_i)</span>
<span id="cb36-411"><a href="#cb36-411" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-412"><a href="#cb36-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-413"><a href="#cb36-413" aria-hidden="true" tabindex="-1"></a>We need to predict odds rather than log-odds on the left-hand side of the equation. To do this we exponentiate both sides of the equation:</span>
<span id="cb36-414"><a href="#cb36-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-415"><a href="#cb36-415" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-416"><a href="#cb36-416" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb36-417"><a href="#cb36-417" aria-hidden="true" tabindex="-1"></a>e^{\ln\bigg<span class="co">[</span><span class="ot">\frac{\hat\pi_i}{1 - \hat\pi_i}\bigg</span><span class="co">]</span>} &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb36-418"><a href="#cb36-418" aria-hidden="true" tabindex="-1"></a>\frac{\hat\pi_i}{1 - \hat\pi_i} &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)}</span>
<span id="cb36-419"><a href="#cb36-419" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb36-420"><a href="#cb36-420" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-421"><a href="#cb36-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-422"><a href="#cb36-422" aria-hidden="true" tabindex="-1"></a>We include the right-side of this in the argument <span class="in">`fun=`</span> of the <span class="in">`geom_function()`</span> layer, substituting in the values for $\hat\beta_0$ and $\hat\beta_1$. Below we plot the results from our fitted logistic model.</span>
<span id="cb36-423"><a href="#cb36-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-426"><a href="#cb36-426" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-427"><a href="#cb36-427" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-predicted-odds</span></span>
<span id="cb36-428"><a href="#cb36-428" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Predicted odds of obtaining a degree as a function of ACT score."</span></span>
<span id="cb36-429"><a href="#cb36-429" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Predicted odds of obtaining a degree as a function of ACT score."</span></span>
<span id="cb36-430"><a href="#cb36-430" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the fitted equation</span></span>
<span id="cb36-431"><a href="#cb36-431" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> grad, <span class="fu">aes</span>(<span class="at">x =</span> act, <span class="at">y =</span> got_degree)) <span class="sc">+</span></span>
<span id="cb36-432"><a href="#cb36-432" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb36-433"><a href="#cb36-433" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(</span>
<span id="cb36-434"><a href="#cb36-434" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> <span class="cf">function</span>(x) {<span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.611</span> <span class="sc">+</span> <span class="fl">0.108</span><span class="sc">*</span>x)}</span>
<span id="cb36-435"><a href="#cb36-435" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb36-436"><a href="#cb36-436" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb36-437"><a href="#cb36-437" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"ACT score"</span>) <span class="sc">+</span></span>
<span id="cb36-438"><a href="#cb36-438" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted odds of obtaining a degree"</span>)</span>
<span id="cb36-439"><a href="#cb36-439" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-440"><a href="#cb36-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-441"><a href="#cb36-441" aria-hidden="true" tabindex="-1"></a>The monotonic increase in the curve indicates the positive effect of ACT score on the odds of obtaining a degree. The exponential growth curve indicates that students with higher ACT scores have increasingly higher odds of obtaining a degree.</span>
<span id="cb36-442"><a href="#cb36-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-443"><a href="#cb36-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-444"><a href="#cb36-444" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-445"><a href="#cb36-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-446"><a href="#cb36-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-447"><a href="#cb36-447" aria-hidden="true" tabindex="-1"></a><span class="fu">### Back-Transforming to Probability</span></span>
<span id="cb36-448"><a href="#cb36-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-449"><a href="#cb36-449" aria-hidden="true" tabindex="-1"></a>We can also back-transform from odds to probability. To do this, we will again start with the logistic fitted equation and use algebra to isolate the probability of obtaining a degree ($\pi_i$) on the left-hand side of the equation.</span>
<span id="cb36-450"><a href="#cb36-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-451"><a href="#cb36-451" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-452"><a href="#cb36-452" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb36-453"><a href="#cb36-453" aria-hidden="true" tabindex="-1"></a>\ln\bigg<span class="co">[</span><span class="ot">\frac{\hat\pi_i}{1 - \hat\pi_i}\bigg</span><span class="co">]</span> &amp;= \hat\beta_0 + \hat\beta_1(x_i) <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb36-454"><a href="#cb36-454" aria-hidden="true" tabindex="-1"></a>\frac{\hat\pi_i}{1 - \hat\pi_i} &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb36-455"><a href="#cb36-455" aria-hidden="true" tabindex="-1"></a>\hat\pi_i &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} (1 - \hat\pi_i) <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb36-456"><a href="#cb36-456" aria-hidden="true" tabindex="-1"></a>\hat\pi_i &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} - e^{\hat\beta_0 + \hat\beta_1(x_i)}(\hat\pi_i) <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb36-457"><a href="#cb36-457" aria-hidden="true" tabindex="-1"></a>\hat\pi_i + e^{\hat\beta_0 + \hat\beta_1(x_i)}(\hat\pi_i) &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb36-458"><a href="#cb36-458" aria-hidden="true" tabindex="-1"></a>\hat\pi_i(1 + e^{\hat\beta_0 + \hat\beta_1(x_i)}) &amp;= e^{\hat\beta_0 + \hat\beta_1(x_i)} <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb36-459"><a href="#cb36-459" aria-hidden="true" tabindex="-1"></a>\hat\pi_i &amp;= \frac{e^{\hat\beta_0 + \hat\beta_1(x_i)}}{1 + e^{\hat\beta_0 + \hat\beta_1(x_i)}} <span class="sc">\\</span><span class="co">[</span><span class="ot">1em</span><span class="co">]</span></span>
<span id="cb36-460"><a href="#cb36-460" aria-hidden="true" tabindex="-1"></a>\hat\pi_i &amp;= \frac{e^{\hat Y_i}}{1 + e^{\hat Y_i}}</span>
<span id="cb36-461"><a href="#cb36-461" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb36-462"><a href="#cb36-462" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-463"><a href="#cb36-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-464"><a href="#cb36-464" aria-hidden="true" tabindex="-1"></a>That is, to obtain the probability of obtaining a degree, we can transform the fitted values (i.e., the predicted log-odds) from the logistic model. For example, the intercept from the logistic fitted equation, $-1.61$ was the predicted log-odds of obtaining a degree for students with an ACT of 0. To obtain the predicted probability of obtaining a degree for students with an ACT of 0:</span>
<span id="cb36-465"><a href="#cb36-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-468"><a href="#cb36-468" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-469"><a href="#cb36-469" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted probability of obtaining a degree; ACT=0</span></span>
<span id="cb36-470"><a href="#cb36-470" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.61</span>) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.61</span>))</span>
<span id="cb36-471"><a href="#cb36-471" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-472"><a href="#cb36-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-473"><a href="#cb36-473" aria-hidden="true" tabindex="-1"></a>For students with ACT of 0, the predicted probability of obtaining a degree is 0.17.</span>
<span id="cb36-474"><a href="#cb36-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-475"><a href="#cb36-475" aria-hidden="true" tabindex="-1"></a>This transformation from log-odds to probability, is non-linear, which means that there is not a clean interpretation of the effects of ACT (i.e., the slope) on the probability of obtaining a degree To understand this effect we can plot the probability of obtaining a degree across the range of ACT scores. To do this, we use <span class="in">`geom_function()`</span> and input the transformation to probability with the fitted equation:</span>
<span id="cb36-476"><a href="#cb36-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-477"><a href="#cb36-477" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-478"><a href="#cb36-478" aria-hidden="true" tabindex="-1"></a>\hat\pi_i = \frac{e^{\hat\beta_0 + \hat\beta_1(x_i)}}{1 + e^{\hat\beta_0 + \hat\beta_1(x_i)}}</span>
<span id="cb36-479"><a href="#cb36-479" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-480"><a href="#cb36-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-483"><a href="#cb36-483" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-484"><a href="#cb36-484" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-predicted-probability</span></span>
<span id="cb36-485"><a href="#cb36-485" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Predicted probability of obtaining a degree as a function of ACT score."</span></span>
<span id="cb36-486"><a href="#cb36-486" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Predicted probability of obtaining a degree as a function of ACT score."</span></span>
<span id="cb36-487"><a href="#cb36-487" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the fitted equation</span></span>
<span id="cb36-488"><a href="#cb36-488" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> grad, <span class="fu">aes</span>(<span class="at">x =</span> act, <span class="at">y =</span> got_degree)) <span class="sc">+</span></span>
<span id="cb36-489"><a href="#cb36-489" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb36-490"><a href="#cb36-490" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(</span>
<span id="cb36-491"><a href="#cb36-491" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> <span class="cf">function</span>(x) {<span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.611</span> <span class="sc">+</span> <span class="fl">0.108</span><span class="sc">*</span>x) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.611</span> <span class="sc">+</span> <span class="fl">0.108</span><span class="sc">*</span>x))}</span>
<span id="cb36-492"><a href="#cb36-492" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb36-493"><a href="#cb36-493" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb36-494"><a href="#cb36-494" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"ACT score"</span>) <span class="sc">+</span></span>
<span id="cb36-495"><a href="#cb36-495" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted probability of obtaining a degree"</span>) <span class="sc">+</span></span>
<span id="cb36-496"><a href="#cb36-496" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb36-497"><a href="#cb36-497" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-498"><a href="#cb36-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-499"><a href="#cb36-499" aria-hidden="true" tabindex="-1"></a>The effect of ACT on the probability of obtaining a degree follows a monotonic increasing "S"-curve.  While there is always an increasing effect of ACT on the probability of obtaining a degree, the magnitude of this effect depends on ACT score. For lower ACT scores there is a larger effect of ACT score on the probability of obtaining a degree than for higher ACT scores.</span>
<span id="cb36-500"><a href="#cb36-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-501"><a href="#cb36-501" aria-hidden="true" tabindex="-1"></a>One interesting point on the plot is the ACT score where the probability of obtaining a degree is 0.5. In our example, this is at an ACT score of approximately 15. This implies that students who score less than 15 are more likely to not obtain a degree than to obtain a degree (on average), and those that score higher than 15 are more likely to obtain a degree than not (on average).</span>
<span id="cb36-502"><a href="#cb36-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-503"><a href="#cb36-503" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-504"><a href="#cb36-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-505"><a href="#cb36-505" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Rough Interpretation of the Slope</span></span>
<span id="cb36-506"><a href="#cb36-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-507"><a href="#cb36-507" aria-hidden="true" tabindex="-1"></a>One rough interpretation that is often used is to divide the slope coefficient by 4 to get an upper bound of the predictive difference in probability of *Y* per unit increase in *X*. In our example, each one-point difference in ACT score is associated with, at most, a $0.108/4=.027$ difference in the probability of obtaining a degree, on average.</span>
<span id="cb36-508"><a href="#cb36-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-509"><a href="#cb36-509" aria-hidden="true" tabindex="-1"></a>:::mathnote</span>
<span id="cb36-510"><a href="#cb36-510" aria-hidden="true" tabindex="-1"></a>The mathematics behind this rough interpretation is based on maximizing the rate-of-change, which is based on setting the first derivative of the logistic function to zero and solving. Recall that the logistic function relates the probabilities to the fitted equation as:</span>
<span id="cb36-511"><a href="#cb36-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-512"><a href="#cb36-512" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-513"><a href="#cb36-513" aria-hidden="true" tabindex="-1"></a>\hat\pi_i = \frac{e^{\hat\beta_0 + \hat\beta_1(x_i)}}{1 + e^{\hat\beta_0 + \hat\beta_1(x_i)}}</span>
<span id="cb36-514"><a href="#cb36-514" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-515"><a href="#cb36-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-516"><a href="#cb36-516" aria-hidden="true" tabindex="-1"></a>The first derivative, with respect to *x* is:</span>
<span id="cb36-517"><a href="#cb36-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-518"><a href="#cb36-518" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-519"><a href="#cb36-519" aria-hidden="true" tabindex="-1"></a>\frac{\hat\beta_1e^{\hat\beta_0 + \hat\beta_1(x_i)}}{\bigg<span class="co">[</span><span class="ot">e^{\hat\beta_0 + \hat\beta_1(x_i)} + 1\bigg</span><span class="co">]</span>^2}</span>
<span id="cb36-520"><a href="#cb36-520" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-521"><a href="#cb36-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-522"><a href="#cb36-522" aria-hidden="true" tabindex="-1"></a>This is maximized when $\hat\beta_0 + \hat\beta_1(x_i)=0$, which means we can substitute 0 into the derivative to determine the maximum rate-of-change:</span>
<span id="cb36-523"><a href="#cb36-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-524"><a href="#cb36-524" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-525"><a href="#cb36-525" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb36-526"><a href="#cb36-526" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{\hat\beta_1e^{0}}{\bigg<span class="co">[</span><span class="ot">e^{0} + 1\bigg</span><span class="co">]</span>^2} <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb36-527"><a href="#cb36-527" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{\hat\beta_1}{\bigg<span class="co">[</span><span class="ot">1 + 1\bigg</span><span class="co">]</span>^2} <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb36-528"><a href="#cb36-528" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{\hat\beta_1}{4} <span class="sc">\\</span><span class="co">[</span><span class="ot">1ex</span><span class="co">]</span></span>
<span id="cb36-529"><a href="#cb36-529" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb36-530"><a href="#cb36-530" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-531"><a href="#cb36-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-532"><a href="#cb36-532" aria-hidden="true" tabindex="-1"></a>Thus the maximum rate-of-change is the based on the slope coefficient divided by four.</span>
<span id="cb36-533"><a href="#cb36-533" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb36-534"><a href="#cb36-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-535"><a href="#cb36-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-536"><a href="#cb36-536" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-537"><a href="#cb36-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-538"><a href="#cb36-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-539"><a href="#cb36-539" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model-Level Summaries</span></span>
<span id="cb36-540"><a href="#cb36-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-541"><a href="#cb36-541" aria-hidden="true" tabindex="-1"></a>The <span class="in">`glance()`</span> output for the GLM model also included model-level information. For the model we fitted, the model-level output was:</span>
<span id="cb36-542"><a href="#cb36-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-545"><a href="#cb36-545" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-546"><a href="#cb36-546" aria-hidden="true" tabindex="-1"></a><span class="co"># Model-level output</span></span>
<span id="cb36-547"><a href="#cb36-547" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(glm<span class="fl">.1</span>) <span class="sc">|&gt;</span></span>
<span id="cb36-548"><a href="#cb36-548" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="at">width =</span> <span class="cn">Inf</span>)</span>
<span id="cb36-549"><a href="#cb36-549" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-550"><a href="#cb36-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-551"><a href="#cb36-551" aria-hidden="true" tabindex="-1"></a>The metric of measuring residual fit is the deviance (remember the deviance was $-2 \times$ log-likelihood). The value in the <span class="in">`null.deviance`</span> column is the residual deviance from fitting the intercept-only model. It acts as a baseline to compare other models.</span>
<span id="cb36-552"><a href="#cb36-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-555"><a href="#cb36-555" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-556"><a href="#cb36-556" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit intercept-only model</span></span>
<span id="cb36-557"><a href="#cb36-557" aria-hidden="true" tabindex="-1"></a>glm<span class="fl">.0</span> <span class="ot">=</span> <span class="fu">glm</span>(got_degree <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> grad, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>))</span>
<span id="cb36-558"><a href="#cb36-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-559"><a href="#cb36-559" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute deviance</span></span>
<span id="cb36-560"><a href="#cb36-560" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(glm<span class="fl">.0</span>)[[<span class="dv">1</span>]]</span>
<span id="cb36-561"><a href="#cb36-561" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-562"><a href="#cb36-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-563"><a href="#cb36-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-564"><a href="#cb36-564" aria-hidden="true" tabindex="-1"></a>The value in the <span class="in">`deviance`</span> column is the residual deviance from fitting whichever model was fitted, in our case the model that used ACT score as a predictor.</span>
<span id="cb36-565"><a href="#cb36-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-568"><a href="#cb36-568" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-569"><a href="#cb36-569" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute deviance for glm.1</span></span>
<span id="cb36-570"><a href="#cb36-570" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(glm<span class="fl">.1</span>)[[<span class="dv">1</span>]]</span>
<span id="cb36-571"><a href="#cb36-571" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-572"><a href="#cb36-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-573"><a href="#cb36-573" aria-hidden="true" tabindex="-1"></a>Recall that deviance is akin to the sum of squared residuals (SSE) in conventional linear regression; smaller values indicate less error. In our case, the model that includes ACT score as a predictor has less error than the intercept only model; its deviance is 90 less than the intercept-only model.</span>
<span id="cb36-574"><a href="#cb36-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-575"><a href="#cb36-575" aria-hidden="true" tabindex="-1"></a>The deviance values or log-likelihoods are often reported in a table of regression results. They are also used to compute differenct information criteria.</span>
<span id="cb36-576"><a href="#cb36-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-577"><a href="#cb36-577" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-578"><a href="#cb36-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-579"><a href="#cb36-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-580"><a href="#cb36-580" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluating the Effect of ACT Acore</span></span>
<span id="cb36-581"><a href="#cb36-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-582"><a href="#cb36-582" aria-hidden="true" tabindex="-1"></a>To evaluate the effect of ACT we compute the AICc values and other metrics in out table of model evidence.</span>
<span id="cb36-583"><a href="#cb36-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-586"><a href="#cb36-586" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-587"><a href="#cb36-587" aria-hidden="true" tabindex="-1"></a><span class="fu">aictab</span>(</span>
<span id="cb36-588"><a href="#cb36-588" aria-hidden="true" tabindex="-1"></a>  <span class="at">cand.set =</span> <span class="fu">list</span>(glm<span class="fl">.0</span>, glm<span class="fl">.1</span>),</span>
<span id="cb36-589"><a href="#cb36-589" aria-hidden="true" tabindex="-1"></a>  <span class="at">modnames =</span> <span class="fu">c</span>(<span class="st">"Intercept-Only"</span>, <span class="st">"Effect of ACT"</span>)</span>
<span id="cb36-590"><a href="#cb36-590" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb36-591"><a href="#cb36-591" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-592"><a href="#cb36-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-593"><a href="#cb36-593" aria-hidden="true" tabindex="-1"></a>Here, given the data and the candidate set of models, there is overwhelming empirical support to adopt the model that includes ACT score.</span>
<span id="cb36-594"><a href="#cb36-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-595"><a href="#cb36-595" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-596"><a href="#cb36-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-597"><a href="#cb36-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-598"><a href="#cb36-598" aria-hidden="true" tabindex="-1"></a>:::fyi</span>
<span id="cb36-599"><a href="#cb36-599" aria-hidden="true" tabindex="-1"></a><span class="fu">### Assessing Statistical Significance of the Predictor 🤮</span></span>
<span id="cb36-600"><a href="#cb36-600" aria-hidden="true" tabindex="-1"></a>We can obtain *p*-values to evaluate statistical significance of predictors. Similar to the regression model, we can obtain *p*-values under the classical framework and under the likelihood framework for inference. Under the classical framework we use `tidy()`. The *z*-values and *p*-values from `tidy()` are sometimes referred to as *Wald statistics* and *Wald p-values*.</span>
<span id="cb36-601"><a href="#cb36-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-604"><a href="#cb36-604" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-605"><a href="#cb36-605" aria-hidden="true" tabindex="-1"></a><span class="co"># Classical framework for inference</span></span>
<span id="cb36-606"><a href="#cb36-606" aria-hidden="true" tabindex="-1"></a><span class="co"># Wald values</span></span>
<span id="cb36-607"><a href="#cb36-607" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(glm<span class="fl">.1</span>)</span>
<span id="cb36-608"><a href="#cb36-608" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-609"><a href="#cb36-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-610"><a href="#cb36-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-611"><a href="#cb36-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-612"><a href="#cb36-612" aria-hidden="true" tabindex="-1"></a>We can also use the log-likelihood values to carry out a likelihood ratio test to test the improvement in deviance from the baseline model (using the likelihood framework). Since the intercept-only model is nested in the model that includes ACT as a predictor, we can use a Likelihood Ratio Test to examine this. To do so, we use the <span class="in">`anova()`</span> function with the added argument <span class="in">`test="LRT"`</span>.</span>
<span id="cb36-613"><a href="#cb36-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-616"><a href="#cb36-616" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-617"><a href="#cb36-617" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood framework for inference</span></span>
<span id="cb36-618"><a href="#cb36-618" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(glm<span class="fl">.0</span>, glm<span class="fl">.1</span>, <span class="at">test =</span> <span class="st">"LRT"</span>)</span>
<span id="cb36-619"><a href="#cb36-619" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-620"><a href="#cb36-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-621"><a href="#cb36-621" aria-hidden="true" tabindex="-1"></a>The null hypothesis of this test is that there is NO improvement in the deviance. The results of this test, $\chi^2(1)=89.3$, $p&lt;.001$, indicate that the observed difference of 89.3 is more than we would expect if the null hypothesis was true. In practice, this implies that the more complex model has significantly less error than the intercept-only model and should be adopted.</span>
<span id="cb36-622"><a href="#cb36-622" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb36-623"><a href="#cb36-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-624"><a href="#cb36-624" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-625"><a href="#cb36-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-626"><a href="#cb36-626" aria-hidden="true" tabindex="-1"></a><span class="fu">## Pseudo R-Squared Values</span></span>
<span id="cb36-627"><a href="#cb36-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-628"><a href="#cb36-628" aria-hidden="true" tabindex="-1"></a>When we fitted linear regression models, we computed an $R^2$ value for the model as a summary measure of the model. This value quantified the amount of variation in the outcome that was explainable by the predictors included in the model. To compute this, we computed:</span>
<span id="cb36-629"><a href="#cb36-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-630"><a href="#cb36-630" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-631"><a href="#cb36-631" aria-hidden="true" tabindex="-1"></a>R^2 = \frac{\mathrm{SSE}_{\mathrm{Baseline}} - \mathrm{SSE}_{\mathrm{Model}}}{\mathrm{SSE}_{\mathrm{Baseline}}}</span>
<span id="cb36-632"><a href="#cb36-632" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-633"><a href="#cb36-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-634"><a href="#cb36-634" aria-hidden="true" tabindex="-1"></a>where the baseline model was the intercept-only model. This measured the proportion of reduction in the residuals from the baseline to the fitted model.</span>
<span id="cb36-635"><a href="#cb36-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-636"><a href="#cb36-636" aria-hidden="true" tabindex="-1"></a>With logistic models, there is no sum of squared error, so we cannot compute an $R^2$ value. However, the residual deviance is a similar measure to the sum of squared error. We can substitute the deviance in for SSE in our computation,</span>
<span id="cb36-637"><a href="#cb36-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-638"><a href="#cb36-638" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-639"><a href="#cb36-639" aria-hidden="true" tabindex="-1"></a>\mathrm{Pseudo}\mbox{-}R^2 = \frac{\mathrm{Deviance}_{\mathrm{Baseline}} - \mathrm{Deviance}_{\mathrm{Model}}}{\mathrm{Deviance}_{\mathrm{Baseline}}}</span>
<span id="cb36-640"><a href="#cb36-640" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb36-641"><a href="#cb36-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-642"><a href="#cb36-642" aria-hidden="true" tabindex="-1"></a>This measure is referred to as a pseudo-$R^2$ value. To compute this measure for our example:</span>
<span id="cb36-643"><a href="#cb36-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-646"><a href="#cb36-646" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-647"><a href="#cb36-647" aria-hidden="true" tabindex="-1"></a><span class="co"># Baseline residual deviance: 2722.6</span></span>
<span id="cb36-648"><a href="#cb36-648" aria-hidden="true" tabindex="-1"></a><span class="co"># Model residual deviance: 2633.2</span></span>
<span id="cb36-649"><a href="#cb36-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-650"><a href="#cb36-650" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute pseudo R-squared</span></span>
<span id="cb36-651"><a href="#cb36-651" aria-hidden="true" tabindex="-1"></a>(<span class="fl">2722.6</span> <span class="sc">-</span> <span class="fl">2633.2</span>) <span class="sc">/</span> <span class="fl">2722.6</span></span>
<span id="cb36-652"><a href="#cb36-652" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-653"><a href="#cb36-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-654"><a href="#cb36-654" aria-hidden="true" tabindex="-1"></a>Interpreting pseudo $R^2$ values are somewhat problematic. A naive interpretation is that differences in ACT scores explains 3.28% of the variation in graduation status. However, this interpretation is a bit sketchy. Pseudo $R^2$ values mimic $R^2$ values in that they are generally on a similar scale, ranging from 0 to 1 (though remember pseudo $R^2$ values can be negative). Moreover, higher pseudo $R^2$ values, like $R^2$ values, indicate better model fit. So while I wouldn't offer the earlier interpretation of the value of 0.0328 in a paper, the value close to 0 does suggest that ACT scores are not perhaps incredibly predictive of the log-odds (or odds or probability) of obtaining a degree.</span>
<span id="cb36-655"><a href="#cb36-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-656"><a href="#cb36-656" aria-hidden="true" tabindex="-1"></a>:::fyi</span>
<span id="cb36-657"><a href="#cb36-657" aria-hidden="true" tabindex="-1"></a>**FYI**</span>
<span id="cb36-658"><a href="#cb36-658" aria-hidden="true" tabindex="-1"></a>In logistic regression, several other pseudo $R^2$ values have also been proposed. See https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/ for more information.</span>
<span id="cb36-659"><a href="#cb36-659" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb36-660"><a href="#cb36-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-661"><a href="#cb36-661" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-662"><a href="#cb36-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-663"><a href="#cb36-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-664"><a href="#cb36-664" aria-hidden="true" tabindex="-1"></a><span class="fu">## Assumptions of the Logistic Model</span></span>
<span id="cb36-665"><a href="#cb36-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-666"><a href="#cb36-666" aria-hidden="true" tabindex="-1"></a>The assumptions for the logistic model are quite different than those for the linear model. The three major assumptions are:</span>
<span id="cb36-667"><a href="#cb36-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-668"><a href="#cb36-668" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>The outcome is binary (only two possible outcomes).</span>
<span id="cb36-669"><a href="#cb36-669" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The observations (or residuals) are independent.</span>
<span id="cb36-670"><a href="#cb36-670" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>There is a linear relationship between the predictors and the logit of the outcome. (Or that the average residual from the fitted logistic model is 0 for all fitted values.)</span>
<span id="cb36-671"><a href="#cb36-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-672"><a href="#cb36-672" aria-hidden="true" tabindex="-1"></a>Unlike with linear regression, we have no assumption that the residuals are normally distributed, nor that there is homoskedasticity. In our example, Assumption 1 is met since the only two values of the outcome were "obtained a degree" or "did not obtain a degree". We need to use the same logic we used in linear regression to verify the independence assumption. Here it seems tenable, since knowing whether one student obtained a degree, does not give us information about whether another student obtains a degree.</span>
<span id="cb36-673"><a href="#cb36-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-674"><a href="#cb36-674" aria-hidden="true" tabindex="-1"></a>To evaluate the third assumption, we will again plot the residuals versus the fitted values and again look to ensure the $Y=0$ line is encompassed in the confidence envelope for the loess smoother. However, as we saw earlier, plots of the raw and standardized residuals from a logistic regression are not that useful. Instead we will create a **binned residual plot**. Binned residuals are obtained by ordering all the observations by the fitted values, separating them into *g* roughly equal bins, and calculating the average residual value in each bin. The binned residual plot is then created by plotting the average residuals in each bin versus the average fitted value in each bin.</span>
<span id="cb36-675"><a href="#cb36-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-676"><a href="#cb36-676" aria-hidden="true" tabindex="-1"></a>To obtain the average fitted values and average residuals in each bin, we will use the <span class="in">`binned_residuals()`</span> function from the <span class="in">`{performance}`</span> package. The <span class="in">`print()`</span> function will then be used to create the binned residual plot.</span>
<span id="cb36-677"><a href="#cb36-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-680"><a href="#cb36-680" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-681"><a href="#cb36-681" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain average fitted values and average residuals</span></span>
<span id="cb36-682"><a href="#cb36-682" aria-hidden="true" tabindex="-1"></a>out<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">binned_residuals</span>(glm<span class="fl">.1</span>)</span>
<span id="cb36-683"><a href="#cb36-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-684"><a href="#cb36-684" aria-hidden="true" tabindex="-1"></a><span class="co"># View binned residuals</span></span>
<span id="cb36-685"><a href="#cb36-685" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(out<span class="fl">.1</span>)</span>
<span id="cb36-686"><a href="#cb36-686" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-687"><a href="#cb36-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-690"><a href="#cb36-690" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-691"><a href="#cb36-691" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-resid</span></span>
<span id="cb36-692"><a href="#cb36-692" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Binned residuals versus the binned fitted values for the model that includes the linear effect of ACT to predict the log-odds of obtaining a degree."</span></span>
<span id="cb36-693"><a href="#cb36-693" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Binned residuals versus the binned fitted values for the model that includes the linear effect of ACT to predict the log-odds of obtaining a degree."</span></span>
<span id="cb36-694"><a href="#cb36-694" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 10</span></span>
<span id="cb36-695"><a href="#cb36-695" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 6</span></span>
<span id="cb36-696"><a href="#cb36-696" aria-hidden="true" tabindex="-1"></a><span class="co">#| out-width: "80%"</span></span>
<span id="cb36-697"><a href="#cb36-697" aria-hidden="true" tabindex="-1"></a><span class="co"># Residual plot</span></span>
<span id="cb36-698"><a href="#cb36-698" aria-hidden="true" tabindex="-1"></a><span class="co"># This will also require you to install the {see} package</span></span>
<span id="cb36-699"><a href="#cb36-699" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(out<span class="fl">.1</span>)</span>
<span id="cb36-700"><a href="#cb36-700" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-701"><a href="#cb36-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-702"><a href="#cb36-702" aria-hidden="true" tabindex="-1"></a>Good fit to the assumption of linearity is indicated by most of the residuals being encompassed within the error bounds of the $Y=0$ line. We can see some misfit in the binned residual plot. The warning message produced from the <span class="in">`binned_residuals()`</span> function also indicates that we may have some misfits given that only 89% of the residuals are within the error bounds.</span>
<span id="cb36-703"><a href="#cb36-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-704"><a href="#cb36-704" aria-hidden="true" tabindex="-1"></a>It is unclear from this plot what the misfit is due to. It may be because the relationship between ACT and the log-odds of obtaining a degree is non-linear. It may be because there are other predictors (main effects or interactions) that we are missing. (We will explore this in the next set of notes.)</span>
<span id="cb36-705"><a href="#cb36-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-706"><a href="#cb36-706" aria-hidden="true" tabindex="-1"></a>&lt;br /&gt;</span>
<span id="cb36-707"><a href="#cb36-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-708"><a href="#cb36-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-709"><a href="#cb36-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-710"><a href="#cb36-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-711"><a href="#cb36-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-712"><a href="#cb36-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-713"><a href="#cb36-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-714"><a href="#cb36-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-715"><a href="#cb36-715" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>